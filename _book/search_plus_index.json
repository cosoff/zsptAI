{"./":{"url":"./","title":"前言","keywords":"","body":"简介 更多信息请移步 zspt.edu.cn. 更多信息请移步 smartyg.com. 关于本文档 中山职业技术学院 & 广州云歌信息科技有限公司 图像处理 图像识别 人脸识别 语音识别 自然语言处理 关于本书的互动性     我们提供了一个Jupyter-Lab环境供大家一边看书一边实验,实验与文档无缝衔接。但由于是公用的，请大家不要修改其中的代码。当发现程序运行不起来的时候，尝试停止kernel。密码：123456 说明 本书的开发环境使用JupterLab 请不要删除代码 可以新建文件夹来编写自己的代码 开发环境中的代码与实际代码有些许不同，是为了在JupyterLab中获得更好的体验，本地运行代码以书中为准 本书中的一些项目由于需要本地摄像头、麦克风、GPU加速等，所以某些项目只提供代码，可以将示例代码下载到本地运行即可！下载方式可参考如下： jupyter界面如下 关于我们 中山职业技术学院 zspt.edu.cn. 广州云歌信息科技有限公司 smartyg.com. AI 体验中心 ai.smartyg.com. AI 在线开发平台 aistudio.smartyg.com. 关注我们 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:58:03 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm1/xm.html":{"url":"part1/xm1/xm.html","title":"第一章 人工智能知识入门","keywords":"","body":"项目一 什么是人工智能 项目情景     2016年AlphaGo 战胜两代棋王，震惊世界。从无人工厂到无人驾驶，从智慧城市到智能娱乐，能跳舞又能送盒饭的机器牛到手机里人人都用的“今日头条”和“美图秀秀”等，人工智能已经从象牙塔，飞入了寻常百姓家，推进生产便捷生活。我国国务院于 2017年7月印发了《新一代人工智能发展规划》，指导人工智能学科的发展，以求成为世界的人工智能研究中心，引领人工智能的发展。其它国家如美国、英国、德国和日本等都提出了自己雄心勃勃的人工智能发展战略。2019年 2月美国总统特朗普签署行政命令启动\"美国人工智能计划\"，更是推动了国家层面上人工智能技术的竞争。那人工智能是什么？我们一起来探索吧。 项目导览 项目目标 了解古代智能观和古代“人工智能”技术 理解现代人工智能及分类 项目规划     智能是研究人的认知与思维过程并将其机械化，使计算机可以模拟人的思考过程，即机械化推理又或形式推理。阅读材料、搜素网络资源、查找书籍，了解中西方智能思想起源和智能技术起源。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 02:01:03 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm1/rw1.html":{"url":"part1/xm1/rw1.html","title":"任务一 古代的智能观：哲学起源","keywords":"","body":"任务一 古代的智能观：哲学起源 【任务描述】     人类是地球上最可宝贵的“万物之灵”，高高雄踞于自然 界一切生物之上。人类依靠自己的力量不断去认识世界、改造世界，创造了人类所特有的科学文化，不断揭示着物质世界的奥秘，开辟着一个又一个新的认识领域和行动领域。人类靠什么去认识和改造客观世界，同时也改造和调节自己的主观活 动和复杂的社会生活，成为自然界发展的最高产物呢？靠的主要是不断发展着的人类自己的智能。 【任务实施】 1.1 西方的“智能”观 （1）休谟之问     休谟在《人性论》中提出的一个著名问题--休谟之问，即所谓从“是”能否推出“应该”，也即“事实”命题能否推导出“价值”命题。严格说来，休谟问题并非指事实与价值的关系问题，而是指事实命题与价值命题的关系问题，由于事实命题一般以“is”为系词，而价值命题一般以“ought”为系词，所以休谟问题又称“实然与应然问题”。 （2）符号逻辑     十七世纪德国数学家和哲学家莱布尼兹认为一切现实事件都可以通过物理符号将其逻辑化并进行推理，即‘万能符号’理论，这为数理逻辑发展奠定了基础，也是第一阶段人工智能思想的萌芽。 （3）语言和规则     维特根斯坦在《哲学研究》（Philosophical Investigation）中提出一种观点—“理解一个语句意味着理解一种语言”，即一个系统可以解析语词并将它们作为一个语句加以处理。但它不会将这个语句真正作为人类语言的一部分去理解，因为人类会利用语言游戏来表达不同的意图，人类对话是一种智能的过程，它通过操纵社会语境来实现说话人的意图。比维特根斯坦稍年轻一些的哲学家约翰·希尔勒（John Searle）遵循前者全新建立的以语言为中心的传统，他利用如今著名的“中文房间”（Chinese Room）思想实验证明，尽管人工智能能够遵循规则，但它无法认识规则。 1.2我国的“智能观” （1）孟子的智能观     孟子写过“智者是非之心也”，是非之心就是“智”，你可以有意识，但不一定有智慧，意识是无关乎是非的，而智慧是要知道是非的，明白伦理的。 （2）王充的智能观     汉代王充在《论衡·实知》写到“故智能之士，不学不成，不问不知。”即使有智能的人，不学就没有成就，不请教别人就不会知道。 （4）荀子的智能观     荀子在《正名》说：“知之在人者谓之知”，这里的知就是咨询的意思。人有视觉、听觉、触觉、味觉和压力这些感知能力，我们会对身体所处的环境进行多通道、多模态的感知。“知有所合者谓之智”，而感知得到的不同通道的多种类型的大数据，在大脑中形成概念，形成对象，就产生了智慧。这种智慧的来源，是我们人对大数据一种综合的思考得到的一种结果。“人知在人者谓之能”，这里讲的是人的一些本能。例如，在路上你碰到前面一辆疾驶而来的汽车，你马上就能感知出来并认知出来这是一辆汽车，而且快速向你冲过来，如果你不做避让的话，就可能吾命不久矣。那这个时候人们就会开始趋利避害。人类有一些本能，可以做到对感知或者认知的结果快速地做出处理。“人有所合者谓之本正”，就可以被理解为是现在我们说的人工智能。就是要把所有从前端感知得到的数据，激发出智慧，再形成与之相关的行动或者决策。这样来看，整个人工智能脉络就已经被清晰得勾勒出来了。 1.3古代的人工智能技术 （1）能歌善舞的“机器人”     早在3000多年前的商周时期我国就出现了“机器人”，在《列子·汤问》中曾有记载，一个叫偃师的巧匠曾经为周穆王进贡过一个能歌善舞的木偶“机器人”。这个木偶不仅长相精致仿真，并且走路带风，行动自如。在偃师的操作下，它唱歌符合音律，尬舞起来丝毫没有僵硬感，“颔其颐，则歌合律；捧其手，则舞应节”。 （2）能记路程的“机器人”     记里鼓车又有“记里车”、“司里车”、“大章车”等别名。有关它的文字记载最早见于《晋书·舆服志》：“记里鼓车，驾四。形制如司南。其中有木人执槌向鼓，行一里则打一槌。”晋人崔豹所著的《古今注》中亦有类似的记述。据此可推断记里鼓车在晋或晋以前即已发明了。这个车上的木偶，每走过一里路都会敲一下鼓，行程达到十公里的时候则会敲一下镯能让车上的木偶动起来，车中有一套减速齿轮系，一直和车轮保持同时转动的趋势，最末的一只齿轮轴在行程一公里的时候刚好转完一周，车上的木偶因为受到凹轮的牵系，被绳索拉起的右臂击鼓一次，表明达到了一公里。 （3）能载货运输的“机器人”     《南齐书·祖冲之传》如是记载：“以诸葛亮有木牛流马，乃造一器，不因风水，施机自运，不劳人力。”这种“机器人”，载重量达到四百斤以上，每日可以达到“特行者数十里，群行三十里”，日夜不休。 （4）能飞行的“机器人”     飞行木鸢是一种会飞的机器鸟，用木材做成，内设机关，能在空中飞行。战国时代，鲁班（或称公输般、公输子）与墨子都曾制造木鹊或木鸢。《墨子》记载：“公输子削竹木以为鹊，成而飞之，三日不下。”《鸿书》中也记载：“公输般为木鸢，以窥宋城。”鲁班制作木鸢以侦查战争的情况，不正如同现代无人飞机侦查敌人情报相似。而后到汉代，张衡也创造了飞行木鸟，然而木雕的飞行引擎机械结构到如今仍一直是个未解谜团。 （5）能端茶倒酒的“机器人”     明末姜准《岐海琐谈集》中，记载一个叫黄子复的能人，他制作了个木人，可以给客人端茶送酒，还刻有木犬会咬住客人的衣服，挽留客人。文中说到：“山人黄子复，擅巧思，制为木偶，运动以机，无异生人。尝刻美女，手捧茶橐（茶壶）。自能移步供客。客举觞啜茗，即立以待；橐返于觞，即转其身，仍内向而入。又刻为小者，置诸席上，以次传觞。其行止上视瓯之举否，周旋向背，不须人力。其制一同于犬。刻木为犬，冒以真皮，口自开合，牙端攒聚小针。衔人衣裔，挂齿不脱，无异于真。” （6）希腊古城的机器女仆     公元8世纪《荷马史诗》这本书中记载。希腊之神兼工匠之神赫菲斯托斯被赶出奥林匹克山之后，身边佣人空无一人，为了伺候他的衣食住行便制造了两个机器人女仆。（据说凡是被赶出奥林匹克山的众神，都是失去神力成为凡人），这个故事成为希腊文化的一部分。与此同时，拥有神奇能力的人形机器人概念便出现了。大约在800年后，古希腊工程师亚历山大得希罗，决定将这个梦想变成现实。他便设计出能够自行驱动上台的小机器，而这些小机器会完成一系列动作，比如点火、倒酒、走路等。而这或许是世上最早具有变革性的技术机器人了。 【任务拓展】 1、比较我国的智能观与西方的智能观，讨论他们之间的异同？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 04:00:23 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm1/rw2.html":{"url":"part1/xm1/rw2.html","title":"任务二 现代人工智能","keywords":"","body":"任务二 现代人工智能 【任务描述】 人工智能并不是一项新技术，人工智能概念诞生于1956年，已有半个多世纪的发展历程。作为现在最前沿的交叉学科，其实学界尚未有统一—致定义，大家对于人工智能的定义有着不同的理解。 【任务实施】 2.1人工智能定义 （1）字典里的“人工智能”     【新华词典在线版】计算机科学的一个分支。研究应用计算机来模拟人类的某些智力活动，从而代替人类的某些脑力劳动。是一门涉及数学、心理学、生物学、语言学、经济学、哲学和法律学等的综合性学科。主要研究模式识别、学习过程、探索过程、推理过程等。人工 : ①人为；人做的。与“自然”、“天然”相对：人工降雨｜人工取火｜根须茁壮，枝叶繁茂，岂是人工做得出来的。 ②人力；用人力做的工。与“机械力”相对：人工开成的渠｜拖拉机来不及运，还得用人工挑。 ③劳工；佣工：派人工进山砍伐｜贫居乏人工，灌木荒余宅。 ④量词。一个人工作一天的量：做一张书桌要用三个人工｜算一下打口井要多少人工。智能: 1.智谋与才能。 2.指智力。     【牛津字典】一种能够执行通常需要人类智能的任务的计算机系统理论和发展技术，如视觉感知、语音识别、决策和翻译。 （2）百科里的“人工智能”     维基百科中的定义：“人工智能就是机器展现出来的智能，所以只要机器有智能的特征和表现，就应该将其视为人工智能。”     百度百科中的定义：“人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术和应用系统的一门新的技术科学。”并认为人工智能是计算机科学的一个分支。现阶段，比较热门的研究方向包括机器人、语音识别、图像识别、自然语言处理等几个方面。 （3）《人工智能，一种现代方法》里的“人工智能”     人工智能是类人行为，类人思考，理性的思考，理性的行动。人工智能的基础是哲学，数学，经济学，神经科学，心理学，计算机工程，控制论，语言学。 （4）《人工智能标准化白皮书（2018年）》里的人工智能     人工智能是利用数字计算机或者由数字计算机控制的机器，模拟、延伸和扩展人类的智能，感知环境、获取知识并使用知识获得最佳结果的理论、方法、技术和应用系统。 （5）人工智能之父眼里的“人工智能”     人工智能之父约翰麦卡锡的说法，它是“制造智能机器的科学与工程，特别是智能计算机程序” （6）研究领域的“人工智能”     人工智能是研究、开发用于模拟、延伸和扩展人的智能理论、方法、技术及应用系统的一门新的技术学科，它是计算机科学的一个分支。 （7）应用领域的“人工智能”     人工智能是一门综合学科，主旨是研究和开发出智能实体，在这一点上它属于工程学。工程的一些基础学科自不用说，数学、逻辑学、归纳学、统计学、系统学、控制学、工程学、计算机科学，还包括对哲学、心理学、生物学、神经科学、认知科学、仿生学、经济学、语言学等其他学科的研究，可以说这是一个集数门学科精华的尖端学科中的尖端学科。 2.2人工智能的四大流派     将思考和行动组合起来就是四种情况，即机器是否能像人一样思考，机器是否可以合理的思考，机器是否能像人一样行动，机器是否可以合理的行动，这四种定义派生出了人工智能四个流派。 （1）像人一样思考派     像人一样思考派，代表就是图灵。1950年，艾伦·图灵(Alan Turing)介绍了一项测试，以检查机器是否能像人类一样思考，这项测试称为图灵测试。在这个测试中，图灵提出如果计算机可以在特定条件下模仿人类的反应，那么可以说计算机是智能的。图灵在其1950年的论文“计算机器和智能”中介绍了图灵测试，该论文提出了“机器能想到吗？”的问题。图灵测试基于派对游戏“模仿游戏”，并进行了一些修改。这个游戏涉及三个玩家，其中一个玩家是计算机，另一个玩家是人类响应者，第三个玩家是人类询问者，与其他两个玩家隔离，他的工作是找到哪个玩家是其中两个玩家。测试结果并不取决于每个正确答案，而只取决于其答案与人类答案的接近程度。允许计算机尽一切可能通过询问器强制进行错误识别。简单来说就是如果人类询问者在提出一些书面问题后不能区分是人还是计算机在回答，则该计算机通过图灵测试。 （2）像人一样行动派     将认知模型化方法，比较典型的是通用问题解决器GPS，核心是希望模拟人解决问题的过程。 （3）合理的思考     合理的思考是逻辑学、人工智能中的逻辑主义流派，鼻祖是亚里士多德，他提出了逻辑的方法期望通过逻辑的方法得到最合理的结论，期望通过形式化模型表达这个世界，借助严格的规则完成推理，但我们这个世界实在是太复杂，一个看上去很简单的问题的形式化描述也可能是一个极其困难的问题，需要经过大量的简化，并且很多知识并不是百分之百确定的，这是逻辑派遇到的主要困难。 （4）合理的行动     实现完美的合理性--即总做出正确的事情，融合了逻辑派和图灵派的优势，是目前人工智能研究和工程的主要方法。 2.3人工智能三种形态     人工智能可以分为弱人工智能、强人工智能、超人工智能三个级别，弱人工智能是三个分级当中最低级，目前弱人工智能应用非常广泛。 （1）弱人工智能     弱人工智能的英文单词就是Artificial Narrow Intelligence,简称为ANI,弱人工智能是擅长于单个方面的人工智能。比如有能战胜象棋世界冠军的人工智能阿尔法狗，但是它只会下象棋，如果我们问它其他的问题，它就不知道怎么回答了。只擅长单方面能力的人工智能就是弱人工智能。 （2）强人工智能     强人工智能的英文单词就是Artificial General Intelligence,简称AGI,这是一种类似于人类级别的人工智能。强人工智能融在各方面都能和人类比肩的人工智能，人类能干的脑力活它都能干。创造强人工智能比创造弱人工智能难得多，我们现在还做不到。强人工智能是一种宽泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念、快速学习和从经验中学习等操作。强人工智能在进行这些操作时应该和人类一样得心应手。 （3） 超人工智能     超人工智能的英文单词就是Artificial Superintelligence,简称ASI,科学家把超人工智能定义为在几乎所有领域都比最聪明的人类大脑都聪明很多，包括科学创新、通识和社交技能。超人工智能可以是各方面都比人类强一点，也可以是各方面都比人类强万亿倍的。 2.4 人工智能的三个方面     人工智能发展过程中，不同学科背景的人工智能学者对它有着不同的理解。综合起来，我们可以从“能力”和“学科”和“实用”三个方面对人工智能进行定义。从能力角度看，人工智能是指用人工的方法在机器上实现的智能；从学科的角度来看，人工智能是研究如何构造智能机器或智能系统，使它能模拟、延伸和扩展人类智能的学科；从实用的角度来看，人工智能是指用机器实现所有目前必须借助人类智慧才能实现的任务。 （1）计算智能     机器可以像人类一样存储、计算和传递信息，帮助人类存储和快速处理海量数据，有赖于算法的优化和硬件的技术进步。这一阶段是感知智能和认知智能的基础。 （2）感知智能     机器具有类似人的感知能力，如视觉、听觉等，不仅可以听懂、看懂，还可以基于此做出判断并做出反馈或采取行动，即“能听会说，能看会认”。目前研究较多、成果显著的包括图像识别、语音识别等技术，国内外人工智能技术发展均集中于这一阶段。 （3）认知智能     机器能够像人一样主动思考并采取行动，全面辅助或替代人类工作，是人工智能的最高级形态，也是行业未来的着力点。 【任务拓展】 1、讨论我国的算盘是人工智能吗？为什么？ 政策聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 04:04:27 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm2/xm.html":{"url":"part1/xm2/xm.html","title":"项目二 人工智能的发展历程","keywords":"","body":"项目二 人工智能的发展历程 项目情景     2020世界人工智能大会（WAIC）云端峰会在上海世博中心金厅拉开帷幕，大会以\"智联世界 共同家园\"为主题，首次呈现全球大型会议现场真人全息投影，内容丰富，精彩纷呈，数万名观众突破地域限制，通过\"屏对屏\"的互动交流在线观看了开幕式。值得注意的是，本届WAIC主题曲《智能家园》全球第一首由人工智能作曲并且合唱的歌曲，由微软小冰作曲，百度小度、小米小爱、B站泠鸢、微软小冰4位虚拟形象联合演唱。值得一提的是，凭借优秀的音乐创作才能，微软小冰在今年6月成为了上海音乐学院的首位非人类毕业生，并被授予音乐工程系2020届\"荣誉毕业生\"称号。在上海音乐学院音乐工程系学习期间，微软小冰接受了来自音工系主任于阳教授和陈世哲老师的\"指导\"，基于微软的人工智能音乐创作模型，与音工系的同学们互相\"学习\"，相互\"激发\"，训练数据不断提升，音乐的表达技巧更加丰富，可创作的音乐类型也得以扩展。小冰的音乐作品还参与到上海音乐学院在非物质文化遗产相关地区开展的儿童音乐教学中，帮助孩子们完成人生中第一次歌曲的创作，展现出人工智能在音乐创作领域的巨大潜力。斯坦福大学发布的《2030年全球人工智能的发展前景》报告认为，人工智能将广泛应用于各行各业，并形成一种“人工智能效应”，它“总会将一种新技术带入人们的生活，而一旦人们习惯了这种技术，它甚至不再被认为是人工智能”。把目光投向更远的未来，人工智能技术的应用前景令人兴奋。人工智能激发人类的灵感、创造力和生产力，一个人机协力创造的时代已呼之欲出。 项目导览 项目目标 了解人工智能发展历程 了解我国人工智能发展现状和战略规划 思考人工智能时代社会需求 项目规划     人工智能是一门极富发展潜力和挑战性的学科，和大多数事物发展规律一样，该学科也呈肯定-否定-否定之否定的螺旋上升发展趋势。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:14:54 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm2/rw1.html":{"url":"part1/xm2/rw1.html","title":"任务一 现代人工智能","keywords":"","body":"任务一 现代人工智能 【任务描述】     1956年达特茅斯会议被广泛认为是人工智能诞生的标志，经过60多年的蜿蜒前行，时至今日，人工智能发展日新月异，此刻AI已经走出实验室，离开棋盘，已通过智能客服、智能医生、智能家电等服务场景在诸多行业进行深入而广泛的应用。可以说，AI正在全面进入我们的日常生活，属于未来的力量正席卷而来。让我们来回顾下人工智能走过的曲折发展历程。 【任务实施】 1.1人工智能的第一次高峰     1950年，一位名叫马文·明斯基(后被人称为“人工智能之父”)的大四学生与他的同学邓恩·埃德蒙一起，建造了世界上第一台神经网络计算机，常常被认为是人工智能的一个起点。同年，被称为“计算机之父”的阿兰·图灵提出了一个举世瞩目的想法—图灵测试。图灵还大胆预言了真正具备智能机器的可行性。1956年，在由达特茅斯学院举办的一次会议上，计算机专家约翰·麦卡锡提出了“人工智能”一词。就在这次会议后不久，麦卡锡从达特茅斯搬到了MIT。同年，明斯基也搬到了这里，之后两人共同创建了世界上第一座人工智能实验室——MIT AI LAB实验室。茅斯会议正式确立了AI这一术语，并且开始从学术角度对AI展开了严肃而精专的研究。在那之后不久，最早的一批人工智能学者和技术开始涌现。在这段长达十余年的时间里，计算机被广泛应用于数学和自然语言领域，用来解决代数、几何和英语问题。这让很多研究学者看到了机器向人工智能发展的信心。甚至在当时，有很多学者认为：“二十年内，机器将能完成人能做到的一切。” 1.2人工智能第一次低谷     上个世纪70年代，人工智能进入了一段痛苦而艰难岁月。由于科研人员在人工智能的研究中对项目难度预估不足，不仅导致与美国国防高级研究计划署的合作计划失败，还让大家对人工智能的前景蒙上了一层阴影。与此同时，社会舆论的压力也开始慢慢压向人工智能这边,导致很多研究经费被转移到了其他项目上。在当时，人工智能面临三个技术瓶颈，一是计算机性能不足，导致早期很多程序无法在人工智能领域得到应用；二是问题的复杂性，早期人工智能程序主要是解决特定的问题，因为特定的问题对象少，复杂性低，可一旦问题上升维度，程序立马就不堪重负了；三是数据量严重不足，在当时不可能找到足够大的数据库来支撑程序进行深度学习，这很容易导致机器无法读取足够量的数据进行智能化。 1.3人工智能的崛起     1980年，卡内基梅隆大学为数字设备公司设计了一套名为XCON的“专家系统”。这是一种采用人工智能程序的系统，具有完整专业知识和经验的计算机智能系统，可以简单的理解为“知识库+推理机”的组合。这套系统在1986年之前能为公司每年节省下来超过四千美元经费。有了这种商业模式后，衍生出了像Symbolics、Lisp Machines等和IntelliCorp、Aion等这样的硬件，软件公司。在这个时期，仅专家系统产业的价值就高达5亿美元，人工智能应用进入繁荣期。 1.4人工智能第二次低谷     1987年，苹果和IBM公司生产的台式机性能都超过了Symbolics等厂商生产的专家系统通用计算机，从此，专家系统风光不再，曾经轰动一时的人工智能系统就宣告结束历史进程，人工智能应用进入低谷期。 1.5人工智能再次崛起     上世纪九十年代中期开始，随着AI技术尤其是神经网络技术的逐步发展，以及人们对AI开始抱有客观理性的认知，人工智能技术开始进入平稳发展时期。1997年5月11日，IBM的计算机系统“深蓝”战胜了国际象棋世界冠军卡斯帕罗夫，又一次在公众领域引发了现象级的AI话题讨论，成为人工智能发展的一个重要里程。2006年，Hinton在神经网络的深度学习领域取得突破，人类又一次看到机器赶超人类的希望,也是标志性的技术进步。人工智能技术已经掀起第四次商业革命，谷歌、微软、百度等互联网巨头以及众多的初创科技公司，纷纷加入人工智能产品的战场，掀起又一轮的智能化狂潮，随着技术的日趋成熟和大众的广泛接受，这一次狂潮也许会架起一座现代文明与未来文明的桥梁。 【任务拓展】 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:16:53 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm2/rw2.html":{"url":"part1/xm2/rw2.html","title":"任务二 我国人工智能的发展之路","keywords":"","body":"任务二 我国人工智能的发展之路 【任务描述】     与国际上人工智能的发展情况相比，我国人工智能研究不仅起步较晚，而且发展道路曲折坎坷，历经了质疑、批评甚至打压的十分艰难的发展历程，但是改革开放之后，我国人工智能开启了快速发展之路。我国人工智能经历了科研起步和产业快速发展，现在已经进入国家战略规范发展阶段。 【任务实施】 2.1 科研起步阶段     1978年3月，邓小平发表了“科学技术是生产力”的重要讲话，提出“向科学技术现代化进军”的战略决策，打开解放思想的先河，促进中国科学事业的发展，使中国科技事业迎来了科学的春天。广大科技人员出现了思想大解放，人工智能也在酝酿着进一步的解禁。吴文俊凭借几何定理的机器证明成果，获得1978年全国科学大会重大科技成果奖，成为国际自动推理界的领军人物，他所开创的数学机械化也在国际上被誉为\"吴方法。     20世纪70年代末至80年代前期，一些人工智能相关项目已被纳入国家科研计划。例如，在1978年召开的中国自动化学会年会上，报告了光学文字识别系统、手写体数字识别、生物控制论和模糊集合等研究成果，表明中国人工智能在生物控制和模式识别等方向的研究已开始起步。1986年起把智能计算机系统、智能机器人和智能信息处理等重大项目列入国家高技术研究发展计划(863计划)。人工智能研究已经成为国家重点支持的科研领域。 2.2 产业快速发展阶段     2003年西安电子科技大学雷达信号处理国家重点实验室和北京大学智能科学系共同提出成立智能科学与技术专业，智能科学与技术面向前沿高新技术的基础性本科专业，覆盖面很广。专业涉及机器人技术，以新一代网络计算为基础的智能系统，微机电系统（MEMS），与国民经济、工业生产及日常生活密切相关的各类智能技术与系统，新一代的人－机系统技术等。全国共有36所本科院校开设智能科学与技术专业的人才培养，为我国人工智能从科研实验进入产业应用提供了源源不断的智力支持，开始进入快速发展期。浪潮天梭在 2006 年8月以3胜5平2负击败柳大华等5位中国象棋大师组成的联盟。科大讯飞语音识别技术已经处于国际领先地位，其语音识别和理解的准确率均达到了世界第一，自 2006年首次参加国际权威的 BlizzardChallenge大赛以来，一直保持冠军地位。百度推出了度秘和自动驾驶汽车。腾讯推出了机器人记者 Dreamwriter 和图像识别产品腾讯优图。阿里巴巴推出了人工智能平台 DTPAI和机器人客服平台。清华大学研发成功的人脸识别系统以及智能问答技术都已经获得了应用。中科院自动化所研发成功了\"寒武纪\"芯片并建成了类脑智能研究平台。华为也推出了MoKA人工智能系统。 2.3 国家战略规划发展阶段     世界各国已经认识到人工智能是未来国家之间竞争的关键赛场，因而纷纷开始部署人工智能发展战略，以期占领新一轮科技革命的历史高点，我国也不例外。2017年3月，\"人工智能\"首次被写入政府工作报告。 2017年7月，国务院发布《新一代人工智能发展规划》。2017年10月，人工智能被写入十九大报告。 2018年3月，人工智能再度被写入政府工作报告。2018年12月的中央经济工作会议上，人工智能被列入“新基建”的核心板块。2019年3月，人工智能第三次出现在政府工作报告中，并升级为\"人工智能+\"。2020年3月，中共中央政治局常务委员会召开会议，提出要发力于科技端的基础设施建设，人工智能再次成为“新基建”七大版块中的重要一项。     新技术推动学科建设和催生新职业。2018年4月，教育部在研究制定《高等学校引领人工智能创新行动计划》确定设立人工智能专业，进一步完善中国高校人工智能学科体系，旨在培养中国人工智能产业的应用型人才，推动人工智能一级学科建设。2019年3月，全国共有35所高校获首批「人工智能」新专业建设资格。教育部确定2019年度增补人工智能技术服务专业，自2020年起执行，首批共有171所高职院校获批新专业人才培养资格。2019年4月，中华人民共和国人力资源保障部（以下简称人社部）等部门发布13个新职业，包括人工智能工程技术人员等。2020年2月，人社部再次向社会发布了未来紧需的16个新职业，人工智能训练师、智能制造工程技术人员等名列其中。 【任务拓展】     在人工智能领域，无论是从理论研究、技术研发方面，还是从产业基础方面来看，应该说我国的研究积累与发达国家相比差距不大，目前很多方面已经处于世界领先水平。你了解本地区的人工智能发展规划和政策吗？国家有关人工智能的发展战略规划和本地区的人工智能政策，结合自己的专业查阅行业资料，思考自己未来的就业规划，你计划从事的行业未来需要人工智能训练师吗？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:21:44 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm2/rw3.html":{"url":"part1/xm2/rw3.html","title":"任务三 人工智能发展史上的事件","keywords":"","body":"任务三 人工智能发展史上大事件 【任务描述】     “人工智能”会“取代”人类吗？相信对它有所了解的人都想过这个问题；对于人工智能可以取代人类工作这件事，已经在现实生活中显而易见了，比如：无人车间、指纹锁、脸部识别等，但是人工智能“取代”人类去思考、创作乃至学习成长，这真的可以吗？我们一起来看看人工智能近70年的发生的重大事件。 【任务实施】 3.1 “机器，能思考吗？”     1950年阿兰.图灵在他的论文《计算机器与智能》中，开篇的第一句话就是：“机器，能思考吗？”。如果一台机器能够与人类对话，而不被辨别出其机器的身份，那么这台机器就具备智能—这就是著名的“图灵测试”。自此以后，科学家开始不断思考这个问题，在不断摸索中，开始寻找“人工智能”的金钥匙。 3.2达特茅斯会议     1956年，美国汉诺弗小镇的达特茅斯学院中聚集了一群踌躇满志的天才，他们主要讨论机器如何来模仿智能的特征，比如像人类一样思考；使用语言；形成抽象概念；解决人类现存的问题。这次会议被命名为“人工智能夏季研讨会”，这也是人类历史上首次提出“人工智能”的概念；达特茅斯会议就这样拉开了“人工智能”的序幕。 3.3人机大战—“深蓝”     1997年，IBM的超级计算机“深蓝”挑战世界第一象棋冠军盖瑞•卡斯帕洛夫，人工智能又再次出现在人们的视野中。卡斯帕洛夫一分钟可以思考3步棋，而“深蓝”存储了一百年来几乎所有顶级大师的棋谱，一秒钟可以思考两亿步棋。在最后的决胜局中，卡斯帕洛夫仅仅走了十九步便失去了耐心离开现场，这场人机大战以机器完胜人类代表而结束，人工智能顿时声名大噪。 3.4智力问答——“沃森”     2011年，IBM人工智能系统“沃森”决定向北美热播的智力问答节目《危险边缘》宣战，能从节目中胜出的都是上知天文下知地理的学霸级人物，很多人并不看好“沃森”。“沃森”的大脑中虽然已经输入全套百科全书，数百万份的资料，强大的处理器由90台服务器和360个计算机芯片驱动，但是问题的难点并不是储存丰富知识和快速的检索，更重要的是需要让“沃森”理解出题者的问话，对！就是像人类一样“理解”；于是“沃森”像人一样疯狂的“训练”，通过155场模拟赛，8000次以上实验，“沃森”在挑战两位史上获得奖金最多的两位人类选手时，再一次完胜。 3.5世纪大战——“AIphaGo”     2016年3月，世界顶尖围棋高手李世石九段接受了谷歌人工智能“AlphaGo”的挑战；众所周知，围棋千古不同局，万千变化多达10的172次方。麻省理工学院大脑与认识科学系教授托马斯•波吉奥表示：围棋的走法比宇宙中的原子数还多，与“深蓝”不同的是，“AlphaGo”不能仅仅依靠“蛮力”的编程，也不可能将所有走法的可能性都存储起来，我们所应用的是允许机器被训练，并不断学习成长的算法，这个算法称之为：深度学习。在第二局37手“AlphaGo”走出了天马星空的一幕，让很多围观的人汗毛直立，这一步棋让李世石整整想了15分钟，但已经回天无力了，最终“AlphaGo”完胜人类代表李世石；我们在“AlphaGo”身上仿佛已经看到人类的很多特质，比如创造力、直觉和复杂的思考 3.6第一台聊天机器人Eliza     在 1964 年至 1966 年间，麻省理工学院人工智能实验室的德裔美国计算机科学家约瑟夫·维森鲍姆（Joseph Weizenbaum）开发了历史上第一个聊天机器人 — Eliza。Eliza 的名字源于爱尔兰剧作家萧伯纳的戏剧作品《卖花女》中的角色，剧中出身贫寒的卖花女 Eliza 通过学习与上流社会沟通的方式，变成大使馆舞会上人人艳羡的“匈牙利王家公主”。作为世界上第一个聊天机器人，Eliza 被其作者赋予了充满戏剧性的内涵。 3.7 第一例专家系统DENDRAL     1968年，美国斯坦福大学问研发成功专家系统DENDRAL，DENDRAL是世界上第一例成功的专家系统，它的出现标志着人工智能的一个新领域——专家系统的诞生。 3.8 CNN夺冠ImageNet     2012年，Hinton的学生Alex依靠8层深的卷积神经网络（Convolutional Neural Network，CNN）一举获得了ILSVRC 2012比赛的冠军，瞬间点燃了卷积神经网络研究的热潮。AlexNet成功应用了ReLU激活函数、Dropout、最大覆盖池化、LRN层、GPU加速等新技术，并启发了后续更多的技术创新。自AlexNet于2012年提出后，深度学习领域的研究发展极其迅速，基本上每年甚至每几个月都会出现新一代的技术。 3.9 DeepID算法人脸识别率首次超过人眼识别     2014年香港中文大学的汤晓鸥、王晓刚及其研究团队宣布，他们所研发的DeepID人脸识别技术比肉眼识别更精准，准确率超过99%，该计算机视觉研究组所研发的深度学习模型DeepID， 在LFW（Labeled Faces in the Wild）数据库上获得了99.15%的识别率，而LFW是人脸识别领域使用最广泛的测试基准。实验发现，如果仅给出人脸的中心区域，肉眼在LFW上的识别率97.52%。这也是计算机自动识别算法的识别率首次超过肉眼。 3.10谷歌发布 Cloud AutoML     2018年1月，谷歌 发布Cloud AutoML 系统，Cloud AutoML是基于监督学习，开发者只需要通过鼠标拖拽的方式上传一组图片、导入标签，随后谷歌系统就会自动生成一个定制化的机器学习模型，几乎不需要任何人为的干预。换句话说，即便你不懂机器学习的专业知识，也可以借此来从事一些人工智能领域的工作！ 【任务拓展】     人工智能作为新一轮产业革命的核心驱动力，将进一步释放历次科技革命和产业革命积蓄的巨大能量，创造新的强大引擎，重构生产、分配、交换、消费等经济活动各环节，形成从宏到微观各领域的智能化新需求，催生新技术、新产品、新产业、新业态、新模式，引发经济结构重大变革，深刻改变人生产方式和思维模式，实现社会生产力的整体跃升。人工智能会学习、会行动到能思考、能应变，两种不同的智能水平可能带来的人类工作、生活的巨大变化。结合自己的生活和未来的工作，探讨我们和机器怎么协同共处呢？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:22:38 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm3/xm.html":{"url":"part1/xm3/xm.html","title":"项目三 人工智能基础支撑","keywords":"","body":"项目三 人工智能基础支撑 项目情景     近年来人工智能技术应用获得了飞速的发展，各种人工智能相关的应用走进我们的生活。人工智能的发展离不开三大基础支撑，分别是：算力、算法和数据。三个因素缺一不可，都是人工智能发展的决定性因素。算法就是解决问题的手段，并且是批量化解决问题的手段。算力又称计算力，指的是数据的处理能力。数据就是训练人工智能系统的数据资源。 项目导览 项目目标 了解人工智能技术的三大基础支撑：算力、算法、数据 了解数据标注的基本概念和流程 项目规划     人工智能的发展离不开算力、算法、数据的支撑，这三方面的积累发展才能让人工智能更上一个台阶。本节将带领大家了解为什么算力、算法、数据能成为人工智能的三大支撑。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:24:08 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm3/rw1.html":{"url":"part1/xm3/rw1.html","title":"任务一 人工智能技术支撑：算力","keywords":"","body":"任务一 人工智能技术基础支撑：算力 【任务描述】     2016年，世界顶级围棋高手李世石与AI围棋对决，最后竟以1:4惨败于谷歌AlphaGO。人工智能凭什么能够战胜人类？答案是AI背后的超级计算机算力，当时的ALphaGo消耗了176个GPU和1202个CPU的计算资源。这些功能强大的计算机在人工智能技术飞速发展的今天具有不可或缺的作用。AI通过算力处理大量的相关数据，并以神经网络不断学习成长，最终获得技能，战胜人类选手。算力究竟有多重要？中国工程院院士、浪潮集团首席科学家王恩东认为“人类社会已经快速步入到智慧时代，计算力是这个时代的核心驱动力、生产力。” 【任务实施】 1.1什么是人工智能的算力？     算力，也称作计算力，就是设备的计算能力，也是数据处理的能力。AI的许多数据处理涉及矩阵乘法和加法。不管是图像识别等领域常用的CNN算法，还是语音识别、自然语言处理等领域的RNN算法，本质上都是矩阵或vector的乘法、加法，然后配合一些除法、指数等算法。CPU可以拿来执行AI算法，但因为内部有大量其他逻辑，而这些逻辑对于目前的AI算法来说是完全用不上的，所以CPU并不能达到最优的性价比。因此，具有海量并行计算能力、能够加速AI计算的AI芯片应运而生。     以4GHz 128bit的POWER8的CPU为例，假设是处理16bit的数据，该CPU理论上每秒可以完成16X4G=64G次。再以大名鼎鼎的谷歌的TPU1为例，主频为700M Hz，有256X256=64K个乘加单元，每个时间单元可同时执行一个乘法和一个加法。那就是128K个操作。该YPU论述每秒可完成=128K X 700MHz=89600G=大约90T次。可以看出在AI算法处理上，AI芯片比CPU快1000倍。如果训练一个模型，TPU处理1个小时，放在CPU上则要41天。简而言之，人工智能的算力主要取决于芯片。 1.2 AI芯片     从广义范畴上讲，面向AI计算应用的芯片都可以称为AI芯片。狭义上指专门针对AI算法做了特殊加速设计的芯片，以GPU、FPGA、ASIC为代表的AI芯片，基于传统芯片架构对某类特定算法或者场景进行AI计算加速的芯片，是目前可大规模商用的技术路线。     GPU（Graphics Processing Unit），即图形处理器，是一种由大量核心组成的大规模并行计算架构，专为同时处理多重任务而设计。良好的矩阵计算能力和并行计算优势，最早被用于AI计算，在数据中心中获得大量应用。GPU采用并行架构，超过80%部分为运算单元，具备较高性能运算速度。相比较下，CPU仅有20%为运算单元，更多的是逻辑单元，因此CPU擅长逻辑控制与串行运算，而GPU擅长大规模并行运算，但是GPU无法单独工作，必须由CPU进行控制调用才能工作。GPU目前是最主流的通用性AI芯片。在通用性芯片领域，除了英特尔和AMD的CPU外，美国的英伟达公司（Nvidia）是行业龙头，几乎垄断了人工智能的GPU市场。     FPGA（Field-Programmable Gate Array），即现场可编程门阵列，作为专用集成电路领域中的一种半定制电路出现，适用于多指令，单数据流的分析，与GPU相反，因此常用于推理阶段。FPGA灵活性较好、处理简单指令重复计算比较强，用在云计算架构形成CPU+FPGA的混合异构中相比GPU更加的低功效和高性能，适用于高密度计算，在深度学习的推理阶段有着更高的效率和更低的成本。国外包括亚马逊、微软都推出了基于FPGA的云计算服务，国内包括腾讯云、阿里云早在2017年推出了基于FPGA的服务，百度大脑也使用了FPGA芯片，被Xilinx收购的深鉴科技也是基于FPGA来设计深度学习的加速器架构来灵活扩展用于服务器端和嵌入式端。     ASIC（Application Specific Integrated Circuits），即专用集成电路，是一种为专用目的设计的，面向特定用户需求的定制芯片。与GPU和FPGA不同，GPU和FPGA除了是一种技术路线之外，还是实实在在的确定的产品，而ASIC就是一种技术路线或者方案，其呈现出的最终形态与功能也是多种多样的。近年来涌现出的类似TPU、NPU、VPU、BPU等令人眼花缭乱的各种芯片，本质上都属于ASIC。ASIC不同于 GPU 和 FPGA 的灵活性，定制化的 ASIC 一旦制造完成将不能更改，所以初期成本高、开发周期长的使得进入门槛高。目前，大多是具备 AI 算法又擅长芯片研发的巨头参与，如 Google 的 TPU。由于完美适用于神经网络相关算法，ASIC 在性能和功耗上都要优于 GPU 和 FPGA，TPU1 是传统 GPU 性能的 14-16 倍，NPU 是 GPU 的 118 倍。     除了以上已经达到商用规模的AI芯片，还有比较前沿性的研究，例如类脑芯片、可重构通用AI芯片等。类脑芯片在架构上直接通过模仿大脑结构进行神经拟态计算，完全开辟了另一条实现人工智能的道路，而不是作为人工神经网络或深度学习的加速器存在、目前该类芯片还只是小规模研究与应用，代表产品有IBM的TrueNorth和清华大学的“芯机”系列芯片。可重构通用AI芯片遵循软件定义芯片思想，可重构计算技术允许硬件架构和功能随软件变化而变化，兼具处理器的通用性和ASIC的高性能和低功耗，是实现软件定义芯片的核心，被公认为是突破性的下一代集成电路技术。清华大学微电子学研究所设计的AI芯片Thinker，采用可重构计算架构，能够支持卷积神经网络、全连接神经网络和递归神经网络等多种AI算法。     超级计算机是目前世界上功能最强大的计算机。与普通的个人计算机不同，超级计算机的最终竞争指标之一是计算能力，超级计算机前10名中，当前两个功能最强大的超级计算机都来自美国，在前十名中，美国排名第五，中国排名第二。我国的神威“太湖之光”超级计算机排名是世界第三，全部使用具有中国自主知识产权的芯片。 1.3 AI芯片应用     AI芯片部署的位置有两种：云端、终端。云端，即数据中心，在深度学习的训练阶段需要极大的数据量和大运算量，单一处理器无法独立完成，因此训练环节只能在云端实现。终端，即手机、安防摄像头、汽车、智能家居设备、各种IoT设备等执行边缘计算的智能设备。根据部署位置，可以分为云AI芯片和端AI芯片。     AI的实现包括两个环节：训练、推理。训练，是指通过大数据训练出一个复杂的神经网络模型，即用大量标记过的数据来“训练”相应的系统，使之可以适应特定的功能。训练需要极高的计算性能，需要较高的精度，需要能处理海量的数据，需要有一定的通用性，以便完成各种各样的学习任务。推理，是指利用训练好的模型，使用新数据推理出各种结论。即借助现有神经网络模型进行运算， 利用新的输入数据来一次性获得正确结论的过程。也有叫做预测或推断。所以根据承担任务的不同，AI芯片可以分为：用于构建神经网络模型的训练芯片，利用神经网络模型进行推理预测的推理芯片。 1.4智算中心，赋能产业AI化     随着数据总量的增长和智能化社会构建需求的扩大，人工智能产业对算力的要求越来越高。中国工程院院士、浪潮集团首席科学家王恩东认为，在新基建各大领域之中，相比云计算和大数据，人工智能对算力的需求几乎是“无止境”的。根据人工智能研究组织Open AI统计，从2012年至2019年，随着人工智能深度学习“大深多”模型的演进，模型计算所需计算量已增长30万倍。斯坦福大学发布的《AI Index 2019》报告也显示，2012年以后，算力需求每三四个月就翻一番，现有算力面临捉襟见肘的局面。只有通过超级计算机的研究和开发，我们才有机会成为全球人工智能研究中心，中国也进入了人工智能领域的第一梯队。随着新基建的加速建设，人工智能与大数据、云计算、物联网等融合也会进一步加快，智慧医疗、无人驾驶、智慧城市、智慧金融等应用场景，背后都需要算力支撑。“如果算力不能快速提升，那我们将不得不面临一个糟糕的局面：当规模庞大的数据用于人工智能的训练学习时，数据量将超出内存和处理器的承载上限，整个训练过程将变得无比漫长，甚至完全无法实现最基本的人工智能。”浪潮集团人工智能和高性能计算部总经理刘军说。事实上算力成本是人工智能企业发展的一大阻碍，企业花钱买定制化算力、建计算中心，会造成一定程度上的资源浪费，且单靠部分企业建设的计算中心适用面有限，将智能计算中心作为转型升级的基础设施投资，更能满足产业智能化发展需要。     近年已有不少超算中心运用人工智能芯片和服务器来强化其算力，提升对人工智能产业的服务能力，简单来说，这一路径是对传统超算中心“AI化”。比如在西北，2019年，西安的沣东新城搭建了西北地区首个人工智能领域的新型基础设施——沣东人工智能计算创新中心。在粤港澳大湾区，由中科院、广东省、珠海市、横琴新区共同建设的横琴先进智能计算平台也是一例。这一项目也是粤港澳大湾区首个先进智能计算平台，被列入广东省政府2019年工作报告，并纳入了广东省委、省政府印发的《关于贯彻落实“粤港澳大湾区发展规划纲要”的实施意见》。     2020年4月20日，国家发改委首次明确新型基础设施的范围，新型基础设施主要包括三个方面内容： 一是信息基础设施;二是融合基础设施;三是创新基础设施。其中，信息基础设施主要是指基于新一代信息技术演化生成的基础设施，比如，以5G、物联网、工业互联网、卫星互联网为代表的通信网络基础设施，以人工智能、云计算、区块链等为代表的新技术基础设施，以数据中心、智能计算中心为代表的算力基础设施等。智能计算中心明确被纳入了新基建的范围中。     2020年11月17日，国家信息中心信息化和产业发展部联合浪潮发布了《智能计算中心规划建设指南》。《指南》对智能计算中心的规划建设给出了清晰的指导，并对智能计算中心进行明确定义：智能计算中心是基于最新人工智能理论，采用领先的人工智能计算架构，提供人工智能应用所需算力服务、数据服务和算法服务的公共算力新型基础设施，通过算力的生产、聚合、调度和释放，高效支撑数据开放共享、智能生态建设、产业创新聚集，有力促进AI产业化、产业AI化及政府治理智能化。 【任务拓展】     阅读2018年以来的“中国AI算力报告”，了解我国区域算力分布，算力TOP10有你所在的城市或地区吗？你觉得那些排名有上升的城市是因为什么原因呢？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:26:27 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm3/rw2.html":{"url":"part1/xm3/rw2.html","title":"任务二 人工智能技术支撑：算法","keywords":"","body":"任务二 人工智能技术支撑：算法 【任务描述】 做饭机器人一直是人类的追求之一，如何让机器人掌握不同菜系的烹饪方法就是我们的算法。我们通过量化各个步骤、分析各种情况给出不同反应，指导机器人学习人类的烹饪过程是复杂的算法设计过程。 【任务实施】 2.1什么是算法： 算法就是解决某个问题的计算方法及步骤。计算机的算法则是让计算机按照何种方法进行判断，计算。 2.2什么是机器学习：     机器学习（Machine Learning，ML）是研究怎样让计算机具备像人类一样的学习能力，是人工智能的核心部分。人类的学习是一个人根据过往的经验，对一类问题形成某种认识或总结出一定的规律，然后利用这些知识来对新的问题下判断的过程。因此，机器学习是指用某些算法指导计算机利用已知数据学习得出适当的模型，并应用此模型对新的情况给出判断。     机器学习根据学习方式的不同可以分为三类：监督学习，无监督学习，强化学习。监督学习与其他两类学习的不同之处就是输入的训练样本带有正确输出的标记，其他两类的样本没有，强化学习是计算机与环境的交互过程中以追求更高的性能为标准不断优化算法模型。 监督学习：又称有导师的学习，输入的训练样本带有输出标记，计算机不断调整模型使其输出与样本标记一致。 无监督学习：输入的训练样本没有标记，计算机需要从样本中抽取出通用的规则。 强化学习：计算机在与环境的交互过程中，通过统计环境的反馈，动态规划模型来达到最优性能的一类学习方法。 如下列出了常见的机器学习算法（按照学习方式的分类）： 2.3什么是深度学习：     深度学习（Deep Learning,DL）是机器学习的一个子集，通过模仿人类大脑的生物学和过程，学习样本数据的内在规律和表示层次，最终让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。     人脑中负责活动的基本单元是“神经元”，它以细胞体为主体，由许多向周围延伸的不规则树枝状纤维构成的神经细胞。人脑中含有上百亿个神经元，而这些神经元互相连接成一个更庞大的结构，就称为“神经网络”。深度学习试图模仿人脑的“神经网络”建立一个类似的学习策略，也取名为“神经网络”。 2.4什么是神经网络：     计算机范畴的神经网络，即人工神经网络（Artificial Neural Networks，ANNs），是模拟生物神经系统建立的计算机模型。     由图3可以看到人脑的基本单元——神经元的组成和联接，我们模仿人类神经元设计的神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。     神经网络是由层构成的，一般包括输入层，输出层，隐含层。每层之间的数学关系是：，其中x是输入向量，y是输出向量，α( )是激活函数，b是偏移向量，W是权值矩阵，每一层将输入x通过如上公式得到输出y。     神经网络的学习过程：把训练集中的每个输入加到神经网络中，神经网络根据预测值与目标值之间的误差不断调整网络各层的权值矩阵（W）与b，使神经网络的预测值与目标值一致，待各层权值都收敛到一定值，学习过程结束。然后我们就可以用生成的神经网络来对未知数据进行判断。 激活函数：激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，常见的激活函数有：Softmax，Sigmoid，Tanh，ReLU。 权值：每个神经元之间的连线对应一个权值，需要通过训练得到。 损失函数：用来衡量预测值与目标值的差异。     常见神经网络架构有：卷积神经网络(ConvolutionalNeuralNetworks,CNN)、循环神经网络(RecurrentNeuralNetwork,RNN)、长短时记忆神经网络(Long/ShortTermMemoryNetwork, LSTM)、深度信念神经网络(DeepBeliefNetwork,DBN)等。一些经典的神经网络模型：LeNet5、Alex、VGG、YOLO、ResNet等等。 在神经网络训练的中，有三个重要的概念Epoch、Batch Size和迭代： Epoch：当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一个 epoch。 Batch Size：当一次输入一个数据集对于计算机而言太庞大的时候，就需要把它分成多个小块。也就是将数据集分成几个batch。Batch Size则是一个 batch 中的样本总数。 迭代：是batch 需要完成一个epoch 的次数。     TensorFlow是目前流行的神经网络算法库，被广泛用于各类机器学习算法的编程实现。Tensorflow playground展示了数据是如何“流动”的。能让你在浏览器中运行真实的神经网络，并且可以点击按钮和调整参数，了解神经网络是怎么工作的。体验地址：tensorflow.org. 【任务拓展】     跟同学们介绍一下你所了解的计算机经典算法。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:28:04 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm3/rw3.html":{"url":"part1/xm3/rw3.html","title":"任务三 人工智能技术支撑：数据","keywords":"","body":"任务三 人工智能技术基础支撑：数据 【任务描述】 要实现一个功能完善的人工智能应用，需要的一个关键因素就是数据。类似于要做一道好菜，必须要有好的原材料。数据，就是人工智能应用的原材料。那要如何获取原材料，如何对原材料进行加工以便更好的开发人工智能应用呢？ 【任务实施】 3.1 数据采集     通俗来讲就是有什么样的食材，我们才能炒出什么样的菜。比如说如果我们只有土豆茄子的话，那么无论如何也是做不出红烧肉的。而整个数据处理的这个流程中也是面临同样的问题——采集的数据决定了数据分析挖掘的上限。     举个例子，当我们想了解APP的终端用户他在使用什么样的手机，就需要去采集终端用户所用设备的机型参数，比如说设备的品牌设备的型号，包括设备的操作系统等等，当我们拿到这样的数据以后我们才能够去计算终端用户的这种品牌分布设备分布，从而了解用户的这种设备的使用情况。 3.2数据的采集源及采集方式     在当今的大数据时代，数据的采集源往往是高度多样化的，而不同的数据源也往往需要不同的采集手段来进行针对性的采集。一般来讲，数据源包括但不限于如下几类：     第一类是端上数据，即一个服务的客户端或者服务器端产生的数据，例如我们的用户点了哪些页面或内容这样的数据。这类数据往往需要我们埋点进行采集。埋点指的是，我们针对用户特定的行为进行跟踪与捕捉的过程，这些捕捉到的行为经统计后常常会用于后续的对产品的迭代与优化。做埋点可以使用当前市面上现成的第三方服务，也可以自己做建设或开发。对于中小企业来说使用这种第三方的SDK服务性价比更高。     第二类常见的数据源，就是开放数据。开放数据指的是开放给所有人的数据，比如网页的内容数据，或者特定行业的公开数据。这类数据往往需要使用爬虫技术来采集。     第三类是其他平台的数据比如说开发者想拿到自己微信公众号的数据，这个数据其实是存在微信那里的。这个时候，我们可以通过微信提供的规范API接口服务来调取自身的这个公众号的数据。     第四类是物理数据。物理数据指的是用户在物理世界中所产生的数据，例如用户刷脸购物的日志数据，用户的步数数据等。这类数据的采集往往要通过传感器来进行AIDC采集。AIDC采集的全称为自动识别和数据捕获，指的是一种自动识别和收集数据对象，然后将其存储在计算机中的方法。例如射频识别，条形码磁条扫描，GPS传感器等都属于用于识别与捕获物理数据的方法。     第五类是主观性数据。比如通过用户调研或是访谈的方式，收集用户的态度或是意愿，也算是一种传统数据的采集方式。 第六类是数据库的数据。比如说对于一些知识库，可能自己建设的话费时费力。如果有一些现成的方式的话就可以直接通过购买的方式来拿到相应的这个知识库的数据。 3.3采集的数据类型划分     前面解决了从哪儿采及怎么采的问题，接下来我们所面临的是对采集的数据进行分类整理。通常情况下，我们所采集到的数据可以被分为三种类型，即非结构化数据，结构化数据，以及半结构化数据。     首先，无法定义结构的数据称为非结构化数据。处理和管理非结构化数据是相对来说困难的。常见的非结构化数据为文本信息、图像信息、视频信息以及声音信息等等，他们的结构都千变万化，不能用一个二维表来描述。     另一方面，结构化数据往往被称为行数据，是由二维表结构来逻辑表达和实现的数据，其严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。比如说大学生的选课系统中，学生、课程、选课、导师等等数据都可以抽象为结构化数据。     除了结构化和非结构化数据之外，我们往往还需要对于半结构化数据进行采集。半结构化数据和前面介绍的两种类型的数据都不一样，它是结构化的数据，但是结构变化很大。那么什么叫结构变化很大呢？结构变化很大即是在半结构化数据中，同一类的不同实体数据的结构可能会有一定程度的不同，即不同实体所具有的属性会有一定程度的不同，而同时，对于这些实体来说，不同的属性之间的顺序是并不重要的。一个经典的半结构化数据的例子即为简历信息，每一份简历都遵循着简历这个大类所存在物理意义，即展示我们迄今为止在所在领域的成就，所以我们的简历中很有可能会有教育背景、工作经验以及姓名联系方式等等，然而在这个大前提下，每一份简历所具有的属性都不尽相同，有的人会在简历中加入志愿者经历，有的人会加入自己的所掌握的技能，有的人会加入自己的获奖经历等等，这就是我们刚刚所说的数据的结构变化很大的一个体现。半结构化数据往往以XML或者JSON等方式出现。那我们刚刚讲的非结构数据，结构化数据，以及半结构化数据可以看作是对数据的高层次的分类。 3.4数据预处理     数据挖掘中，在海量的原始数据中存在大量有缺失、异常甚至是不一致的数据，严重影响到了建模的执行效率以及正确性。数据预处理的主要内容包括数据清洗、数据集成、数据变换、数据规约。预处理一方面是提高数据的质量，另一方面是要数据更好的适应特定的挖掘技术或工具。 （1）数据清洗     数据清洗主要是删除原始数据集中的无关数据、重复数据，平滑噪声数据，筛选掉与挖掘主题无关的数据并且处理缺失值、异常值等。     一般处理缺失值的时候，通常采用删除记录、数据插补，或者不处理的方式。如果删除少量数据就可以达到目标，当然最好，但是它是以减少历史数据来换取数据的完备，会造成大量资源的浪费，丢弃大量隐藏在记录里的信息，所以个人而言并不太推荐这种方式，更推荐用插补的方式，补齐数据。插补的方法有很多，例如通过均值等属性数据填补，也可以使用固定的值/临近的值进行插补。 （2）数据集成     数据挖掘之前，数据集往往是在不同的数据源中，这时候需要将多个数据源合并饼存储到一个数据仓库中。由于多个数据源的表达形式是不一样的，有可能不匹配，要考虑到识别的问题以及属性冗余的问题，从而将源数据在最底层加以转换、提炼和集成。这个步骤主要做的就是实体的识别以及冗余属性的识别。     实体识别是从不同数据源识别出现实世界的实体，需要做的是统一不同数据的矛盾之处。简单来说，就是将不同的字段名字统一成一个，以及将数据的计量单位统一。例如A在一个数据源中叫 gender，另一个叫sex，需要进行统一，有的计量用的m，有的用km，这个也需要统一。     冗余属性的识别是为了解决同一属性多次出现，同一属性命名不一致导致重复的问题。这个需要我们仔细观察与分析了。 （3）数据变换     数据变换主要是对数据进行规范化的处理，以适用挖掘任务和算法的需要。这是挖掘中至关重要的一个步骤。 ①　简单的数据变化     一般进行简单的函数变化，是对原始数据进行简单变换，基本使用平方、开平方等运算。简单的函数变换常用来将不具备正态分布的数据变换成具有正态分布的数据。 ②　规范化     数据规范化处理是数据挖掘的一项基础工作，主要是为了消除指标之间的量纲和取值范围的差异影响，需要进行标准化处理，将数据按照比例进行缩放，从而使落入一个特定的区域，以便于分析。 ③　连续属性离散化     一些数据挖掘算法，特别是分类算法（ID3、Apriori等），要求数据是分类属性形式。这样需要将一些连续属性变换成分类属性，也就是连续属性离散化。这其实就是在数值的取值范围内设定若干个离散的划分点，将取值范围划分为一些离散化的区间，最后用不同的符号或数值代表每个区间的数据，即需要确定分类数以及将连续属性值映射到这些分类值中。 ④　属性构造     在数据挖掘过程中，为了提取更有用的信息，挖掘更深层次的模式，提高挖掘结果的精度，我们需要利用已有的属性，来构造新的属性，并加入到现有属性的集合中。简单的举例，一个餐馆的日营业总额数据，然后还有每日单据数量，我们就可以知道人均每笔消费的数据，加入的新的一列中进行统计。这个虽然是从已有数据中延伸来的，但是直接生成新属性统计时可更直观。 （4）数据规约     数据规约其实本质上就是在不损害数据完整性的前提下缩小数据集，使之能够高效快速的挖掘出结果。数据规约一般要从两个方向进行，一是属性规约，其次是数值规约。     属性规约通过属性合并来创造新属性维数，或者通过删除不相干属性来减少数据的维度数，从而提高数据挖掘的效率以及降低计算成本，其目标是寻找出最小的属性子集，并确保新数据子集的概率分布尽可能接近原数据的概率分布。     数值规约指通过选择替代的、较小的数据来减少数据量，包括有参数和无参数两类。有参数方法是使用一个模型来评估数据，只存放参数，而不需要存放实际数据。无参数方法就需要存放实际数据，例如直方图、聚类、抽样等。例如使用聚类的方式，就是将数据分为簇，让一个簇中对象相互相似，反之相异，并用数据簇来替换原始数据的数据规约方式。 3.5 数据标注     训练机器学习和深度学习模型，需要丰富的数据，以便将其用于部署，训练和调整模型。训练机器学习和深度学习模型需要大量经过仔细标注的数据。标注原始数据并准备将其应用于机器学习模型和其他AI工作流，被称为数据标注。     要使AI模型做出决策并采取行动，就必须对其进行训练以理解特定的信息。训练数据必须针对特定用例予以适当分类和标注。有了高质量的人工标注数据，企业即可构建和改进AI应用。企业由此将得到客户体验增强的解决方案，如产品推荐、相关搜索引擎结果、计算机视觉、语音识别、聊天机器人等。 （1）数据标注的分类 如表 1 所示，目前数据标注有3种常用的划分方式: ①　按照标注对象进行分类，包括图像标注、视频标注、语音标注和文本标注; ②　根据标注的构成形式，将其分为结构化标注、非结构化标注和半结构化标注; ③　根据标注者类型，分为人工标注和机器标注。     图像标注包括图像标注和视频标注，因为视频也是由连续播放的图像所组成。图像标注一般要求标注人员使用不同的颜色来对不同的目标标记物进行轮廓识别，然后给相应的轮廓打上标签，用标签来概述轮廓内的内容，以便让算法模型能够识别图像中的不同标记物。图像标注常用于人脸识别、自动驾驶车辆识别等应用。     语音标注是通过算法模型识别转录后的文本内容并与对应的音频进行逻辑关联。语音标注的应用场景包括自然语言处理、实时翻译等，语音标注的常用方法是语音转写。     文本标注是指根据一定的标准或准则对文字内容进行诸如分词、语义判断、词性标注、文本翻译、主题事件归纳等注释工作，其应用场景有名片自动识别、证照识别等。目前，常用的文本标注任务有情感标注、实体标注、词性标注及其他文本类标注。 （2）数据标注的任务     常见的数据标注任务包括分类标注、标框标注、区域标注、描点标注和其他标注等。下面介绍每一种任务的具体内容。 ①分类标注     分类标注是从给定的标签集中选择合适的标签分配给被标注的对象。通常，一张图可以有很多分类/标签，如运动、读书、购物、旅行等。对于文字，又可以标注出主语、谓语、宾语，名词和动词等。此项任务适用于文本、图像、语音、视频等不同的标注对象。本文以图像的分类标注为例进行说明，如图 3 所示。图 3 显示了一张公园的风景图，标注者需要对树木、猴子、围栏等不同对象加以区分和识别。 ②标框标注     标框标注就是从图像中选出要检测的对象，此方法仅适用于图像标注。标框标注可细分为多边形拉框和四边形拉框两种形式。多边形拉框是将被标注元素的轮廓以多边型的方式勾勒出来，不同的被标注元素有不同的轮廓，除了同样需要添加单级或多级标签以外，多边型标注还有可能会涉及到物体遮挡的逻辑关系，从而实现细线条的种类识别。四边形拉框主要是用特定软件对图像中需要处理的元素(比如人、车、动物等)进行一个拉框处理，同时，用 1 个或多个独立的标签来代表 1 个或多个需要处理的元素。例如，图 4 对人物的帽子进行了多边形拉框标注，图 5 则对天鹅进行了四边形拉框标注。 ③区域标注     与标框标注相比，区域标注的要求更加精确，而且边缘可以是柔性的，并仅限于图像标注，其主要的应用场景包括自动驾驶中的道路识别和地图识别等。在图 6 中，区域标注的任务是在地图上用曲线将城市中不同行政区域的轮廓形式勾勒出来，并用不同的颜色(浅蓝、浅棕、紫色和粉色)加以区分。 ④描点标注     描点标注是指将需要标注的元素(比如人脸、肢体)按照需求位置进行点位标识，从而实现特定部位关键点的识别。例如，图 7 采用描点标注的方法对图示人物的骨骼关节进行了描点标识。人脸识别、骨骼识别等技术中的标注方法与人物骨骼关节点的标注方法相同。 ⑤其他标注     数据标注的任务除了上述 4 种以外，还有很多个性化的标注任务。例如，自动摘要就是从新闻事件或者文章中提取出最关键的信息，然后用更加精炼的语言写成摘要。自动摘要与分类标注类似，但两者存在一定差异。常见的分类标注有比较明确的界定，比如在对给定图片中的人物、风景和物体进行分类标注时，标注者一般不会产生歧义;而自动摘要需要先对文章的主要观点进行标注，相对于分类标注来说，在标注的客观性和准确性上都没有那么严格，所以自动摘要不属于分类标注。 （3）常用标注数据集和标注工具     随着人工智能、机器学习等行业对标注数据的海量需求，许多企业和研究机构纷纷推出了带标注的公开数据集。为了提高数据标注效率，一些标注工具和平台也应运而生。 ①标注数据集     标注数据集主要划分为图像、视频、文本和语音标注数据集这 4 大类，表 2 描述了这些数据集的来源、用途和特性。ImageNet、COCO 和 PASCAL VOC 是 3 个典型的图像标注数据集。它们广泛应用于图像分类、定位和检测的研究中。由于 ImageNet 数据集拥有专门的维护团队，而且文档详细，它几乎成为了目前检验深度学习图像领域算法性能的“标准”数据集。COCO 数据集是在微软公司赞助下生成的数据集，除了图像的类别和位置标注信息外，该数据集还提供图像的语义文本描述。因此，它也成为评价图像语义理解算法性能的“标准”数据集。Youtube-8M 是谷歌公司从 YouTube 上采集到的超大规模的开源视频数据集，这些视频共计 800 万个，总时长为50 万小时，包括 4 800 个类别。Yelp 数据集由美国最大的点评网站提供，包括了 470 万条用户评价，15 多万条商户信息，20 万张图片和 12 个城市信息。研究者利用 Yelp 数据集不仅能进行自然语言处理和情感分析，还可以用于图片分类和图像挖掘。Librispeech 数据集是目前最大的免费语音识别数据库之一，由近 1 000h 的多人朗读的清晰音频及其对应的文本组成。它是衡量当前语音识别技术最权威的开源数据集。 ②开源数据标注工具     在选择数据标注工具时，需要考虑标注对象(如图像、视频、文本等)、标注需求(如画框、描点、分类等)和不同的数据集格式(比如 COCO、PASCAL VOC、JSON 等)。常用标注工具见表 3。     表 3 中列举了一些开源的数据标注工具及其特点。表 3 中除了 COCO UI 和 LabelMe 工具在使用时需要MIT 许可外，其他工具均为开源使用。大部分的开源工具都可以运行在 Windows、Linux、Mac OS 系统上，仅有个别工具是针对特定操作系统开发的(如 RectLabel);而且这些开源工具大多只针对特定对象进行标注，只有一少部分工具(如精灵标注助手)能够同时标注图像、视频和文本。除了表 3 中列举的标注工具外，市场上还有一些特殊功能的标注工具，例如人脸数据标注和 3D 点云标注工具。不同标注工具的标注结果会有一些差异，但很少有研究关注它们的标注效率和标注结果的质量。 【任务拓展】 1、同学们讨论下自己的学习过程中，有哪些环节被数据化了？ 思政聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:30:53 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm4/xm.html":{"url":"part1/xm4/xm.html","title":"项目四 探索人工智能的行业应用","keywords":"","body":"项目四 探索人工智能的行业应用 项目情景 更聪明，更懂你——让世界更有“AI”     会聊天的智能音箱、更懂你的热点推送、“无所不知”的机器人玩伴、平安好医生的“一分钟诊所”、自动化点单配菜的智能餐厅、自动送餐机器人、消毒液喷洒机器人以及人工智能追溯传染病传播路径……曾只在电影世界出现的人工智能场景，如今在人们生活中变得无处不在。未来已来，这是一个更加崭新和精彩的世界！     习近平总书记指出，人工智能是引领新一轮科技革命和产业变革的重要驱动力，正深刻改变着人们的生产、生活、学习方式，推动人类社会迎来人机协同、跨界融合、共创分享的智能时代。《新一代人工智能发展规划》提出到2030年，中国成为世界主要人工智能创新中心，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。     人工智能正变得愈发聪明。人工智能也变得更加“温暖”。人工智能新技术切实融入生产生活，各行各业正快速实现智能化，智能经济方兴未艾，一幅智慧生活的新画卷正在神州大地徐徐展开。让我们一起探索人工智能在制造、家居、机器人、安防、医疗、教育等行业的应用吧。 项目导览 项目目标 能够感受人工智能技术为各行各业带来的影响 能够感受人工智能技术对未来职业岗位的新要求 了解智能制造、智能家居、智慧医疗等行业应用到的人工智能技术 把握人工智能时代的机遇和挑战 项目规划 项目探究 人工智能作为新一轮产业变革的核心驱动力，对传统行业带来哪些影响？ 世界各国把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，分别出台了哪些规划和政策？ 人工智能对我国社会建设经济建设带来哪些新机遇。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:34:18 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm4/rw1.html":{"url":"part1/xm4/rw1.html","title":"任务一 智能制造","keywords":"","body":"任务一 智能制造 【任务描述】 『超级装备，书写强国传奇』----走进三一重工18号厂房     18号厂房是三一重工总装车间，有混凝土机械、路面机械、港口机械等多条装配线，是工程机械领域内颇负盛名的智能工厂。这间总面积约十万平方米的车间，成为了行业内亚洲最大最先进的智能化制造车间。在这里，厂房更像是一个大型计算系统加上传统的操作工具、大型生产设备的智慧体。在18号厂房，厂区旁边有两块电视屏幕，它们是一线工人的“老师”——不熟悉装配作业的工人，通过电子屏幕里的数字仿真和三维作业指导，可以学习和了解整个装配工艺。这里，厂房更像是一个大型计算系统加上传统的操作工具、大型生产设备的智慧体，每一次生产过程、每一次质量检测、每一个工人劳动量都记录在案。装配区、高精机加区、结构件区、立库区等几大主要功能区域都是智能化、数字化模式的产物。18号厂房经智能化车间经改造后，生产效率提升50％，成为引领行业智能制造的“新灯塔”。那么，什么是智能制造？智能制造究竟“智能”在哪？智能制造中应用了哪些人工智能技术呢？答案就在本任务学习中。 【任务实施】 1.1 什么是智能制造     智能制造是基于新一代信息通信技术与先进制造技术深度融合，贯穿于设计、生产、管理、服务等制造活动的各个环节，具有自感知、自学习、自决策、自执行、自适应等功能的新型生产方式。 1.2人工智能核心技术在智能制造行业的应用     智能制造的实现需要多个层次上技术产品的支持，主要包括工业机器人、3D打印、工业物联网、云计算、工业大数据、知识工作自动化、工业网络安全、虚拟现实和人工智能等技术。     智能制造对人工智能的需求主要表现在：一是智能装备，通过先进制造、信息处理、人工智能等技术的集成与融合，可以形成具有感知、分析、推理、决策、执行、自主学习及维护等自组织、自适应功能的智能生产系统以及网络化、协同化的生产设施，包括自动识别设备、人机交互系统、工业机器人以及数控机床等具体设备，涉及到跨媒体分析推理、自然语言处理、虚拟现实智能建模及自主无人系统等关键技术。二是智能生产，是以智能工厂为核心，将人、机、法、料、环连接起来，多维度融合的过程。智能工厂也称之为数字化车间，包括智能设计、智能生产、智能管理以及集成优化等具体内容，涉及到跨媒体分析推理、大数据智能、机器学习等关键技术。侧重点在于将人机互动、3D打印等先进技术应用于整个工业生产过程，并对整个生产流程进行监控、数据采集，便于进行数据分析，从而形成高度灵活、个性化、网络化的产业链。三是智能服务，包括大规模个性化定制、远程运维以及预测性维护等具体服务模式，涉及到跨媒体分析推理、自然语言处理、大数据智能、高级机器学习等关键技术。例如，现有涉及智能装备故障问题的纸质化文件，可通过自然语言处理，形成数字化资料，再通过非结构化数据向结构化数据的转换，形成深度学习所需的训练数据，从而构建设备故障分析的神经网络，为下一步故障诊断、优化参数设置提供决策依据。 1.3智能制造领域的典型企业     目前国内家电、汽车等行业自动化和信息化程度已经较高，其他行业，食品饮料，化工等行业正在加快自动化和信息化进程。广汽集团作为世界级智能制造的标杆工厂，在智能制造领域，广汽集团已将智能化深入到制造环节。充分贯彻 “工业 4.0”理念，实现生产自动化、信息数字化、管理智能化、智造生态化有机融合，并以质量和效能为中心，提升生产要素效率，生产线极限速度可达到 52 秒下线一辆新车，是行业领先的汽车生产线。华为松山湖生产基地，从智能车间、智能工厂开始，通过智能制造实现高效、柔性的大规模客户定制，全球领先的生产工艺、手机品控的领先标准淋漓尽致地展现在这里。海尔集团深耕制造业三十余年，是世界第四大白色家电制造商，正在以构建\"互联工厂\"的核心思想，尝试从大规模\"制造\"发展为大规模\"定制\"的智能制造企业，将家电定制化这一美好畅想变为现实。海尔互联工厂创新人工智能检测等多项行业领先技术，实现全流程数据链贯通，真正做到用户定单驱动生产。富士康主要聚焦于工业互联网平台构建、云计算及高效能运算平台、高效运算数据中心、通信网络及云服务设备、5G及物联网互联互通解决方案、智能制造新技术研发应用、智能制造产业升级、智能制造产能扩建等项目。 【任务拓展】     说说你身边的智能制造故事，你所了解的智能制造领域还有哪些典型企业和典型人物 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:36:10 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm4/rw2.html":{"url":"part1/xm4/rw2.html","title":"任务二 智能机器人","keywords":"","body":"任务二 智能机器人 【任务描述】 “小勤人上岗了！！！”---德勤财务机器人引发财务新变革     2018年横空出世的德勤财务机器人 “小勤人”刷爆了整个朋友圈，国际四大会计师事务所之一的德勤会计师事务所将人工智能技术引入会计、税务、审计等工作中。“小勤人”可以快速“阅读”数千份复杂文件，从中攫取和构建文本信息以更好地作出分析。财务机器人替代了财务流程中的手工操作，特别是高重复的工作，工作效率超过三个全职员工，三个小时就完成一个会计一天的工作量，并且解决了基础操作大量的人力和时间、大大增强了数据的准确性，重点是“小勤人”还是全天24小时上班，并且全年无休！ “小勤人”只是众多智能机器人中的一员，“小勤人”为什么可以这么能干呢？我们要从智能机器人说起。 【任务实施】 2.1智能机器人的定义及分类     智能机器人是指具备不同程度类人智能，可实现“感知-决策-行为-反馈”闭环工作流程，可协助人类生产、服务人类生活，可自动执行工作的各类机器装置，主要包括智能工业机器人、智能服务机器人和智能特种机器人。 2.2智能机器人行业的人工智能核心技术     由于高频人机互动特点，智能机器人的核心技术重点聚焦在智能感知、智能认知和多模态人机交互领域。同时依据应用领域的不同，智能机器人也存在着大量带有典型行业特征的特色关键技术。智能工业机器人运用传感技术和机器视觉技术，具备触觉和简单的视觉系统，更进一步运用人机协作、多模式网络化交互、自主编程等技术增加自适应、自学习功能，引导工业机器人完成定位、检测、识别等更为复杂的工作，替代人工视觉运用于不适合人工作业的危险工作环境或人工视觉难以满足要求的场合；智能家用服务机器人重点应用移动定位技术和智能交互技术，达到服务范围全覆盖及家用陪护的目的；智能医疗服务机器人重点突破介入感知建模、微纳技术和生肌电一体化技术，以达到提升手术精度、加速患者康复的目的；智能公共服务机器人重点运用智能感知认知技术、多模态人机交互技术、机械控制和移动定位技术等，实现应用场景的标准化功能的呈现和完成；智能特种机器人运用仿生材料结构、复杂环境动力学控制、微纳系统等前沿技术，替代人类完成高危环境和特种工况作业。 2.3智能机器人行业的典型企业     智能工业机器人领域，国际四大巨头仍占据较高市场份额，日本发那科和安川、德国库卡、瑞士ABB、意大利柯马侧重具有分拣和装配能力的智能工业机器人，英国Meta、德国Scansonic、日本安川聚焦激光视觉焊缝跟踪系统。国内智能工业机器人是“三巨头”新松、云南昆船和北京机科，新松重点提供自动化装配与检测生产线、物流与仓储自动化成套设备，云南昆船侧重烟草行业服务，北京机科主要应用于印钞造币、轮胎及军工领域。智能服务机器人领域，美国iRobot、中国科沃斯、美国IntuitiveSurgica、以色列Rewalk、荷兰Hot-Cheers分别聚焦于清洁、手术、康复及分拣等细分领域。智能特种机器人领域，波士顿动力围绕着拥有液压驱动核心技术的“大狗”机器人，不断构筑技术壁垒；大疆在国内消费级无人机领域占有率达75%，成为估值超百亿美元的“独角兽”企业；美国Howeand Howe Techonologies则专注生产消防机器人，应用于应急救援场景。 【任务拓展】     未来，大量重复可标准化流程化的工作将完全被更精准、快速的人工智能机器人所取代，你的专业安全吗？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:38:41 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm4/rw3.html":{"url":"part1/xm4/rw3.html","title":"任务三 智能家居","keywords":"","body":"任务三 智能家居 【任务描述】 智能化生活真香！一键开启精致生活     当你早晨在音乐中起床，电动窗帘缓缓开启，温暖的阳光洒满卧室。智能系统为你提醒今日的天气以及分享晨间新闻资讯，当你走进餐厅，小智厨师已为你准备好早餐、咖啡……就这样轻松开启新的一天。当你离开家时，家里的电器，窗帘，灯光自动关闭，扫地机器人开启清扫模式，并联动开启\"安防模式\"，智能摄像机、智能门磁、智能门锁、煤气、漏水检测器等开始工作。智能门锁一旦面临非法入侵，会发出本地报警，还能将报警信息发送至你手机上，你出门在外再也不必担心家里的安全状况了。在这种环境中生活，你将会变得无比安心。那么，什么是智能家居，我们一起来探究。 【任务实施】 3.1什么是智能家居     智能家居以家庭住宅为平台，基于物联网技术和云计算平台构建的家居生态圈，涵盖智能冰箱、智能电视、智能空调等智能家电，智能音箱、智能手表等智能硬件，智能窗帘、智能衣柜、智能卫浴等智能家居，智能家居环境管理等诸多方面，可实现远程控制设备、设备间互联互通、设备自我学习等功能，并通过收集、分析用户行为数据，为用户提供个性化生活服务，使家居生活安全、舒适、节能、高效、便捷。     例如，借助智能语音技术，用户应用自然语言实现对家居系统各设备的操控，如开关窗帘（窗户）、操控家用电器和照明系统、打扫卫生等操作；借助机器学习技术，智能电视可以从用户看电视的历史数据中分析其兴趣和爱好，并将相关的节目推荐给用户。通过应用声纹识别、脸部识别、指纹识别等技术进行开锁等；通过大数据技术可以使智能家电实现对自身状态及环境的自我感知，具有故障诊断能力。通过收集产品运行数据，发现产品异常，主动提供服务，降低故障率。还可以通过大数据分析、远程监控和诊断，快速发现问题、解决问题及提高效率。 3.2智能家居行业的人工智能核心技术     随着移动互联网技术的大规模普及应用，为人们精细化掌控人居环境质量与模式提供了基础支撑，人工智能技术的持续发展，又进一步促使人居环境中的管理、辅助、通信、服务、信息获取等功能再次实现智能化的组合优化，以达到借助科技手段管理生活方式的目的。在此背景下，传感器技术、无线及近场通讯设备、物联网技术、深度学习、大数据及云计算技术得到较多应用。传感器和通讯设备对人居环境进行监测形成的数据流，会通过云计算和深度学习建立相应模型，再依托家用物联网对室内的电器设备乃至整个建筑的实时控制，将模型对应的参数和状态优化方案反馈到人居环境中，为人居生活的计划、管理、服务、支付等方面提供支持。 3.3智能家居行业的典型企业     具备智能人居解决方案提供能力的龙头企业众多，可大致分为传统家电厂商、智能硬件厂商、互联网电商及创新企业。海尔、美的聚焦智能家居终端，小米侧重于面向众多开发者提供硬件开放式接口，华为致力于提供软硬件一体化楼宇级解决方案，京东通过轻资产、互联网化的运营模式号召合作伙伴加入其线上平台和供应链，国安瑞通过数据挖掘提供覆盖操作终端硬件、系统智能云平台、建筑智能设备的闭环解决方案提升室内人居感受。 【任务拓展】 你认为智能家居行业未来会有怎样的发展趋势？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:38:56 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm4/rw4.html":{"url":"part1/xm4/rw4.html","title":"任务四 智能安防","keywords":"","body":"任务四 智能安防 【任务描述】 筑“天网”佑民安     川流不息的高速路上，旅游客车驾驶员是否危险驾驶，车内是否有突发状况?交通运输管理部门在线就可以监控，这是智能技术在交通领域小试牛刀；人来人往的海关，身姿小巧的海关无人智能巡检查验车灵活穿行，提供智慧安防服务;相对宁静的城市地下综合管廊里，机器人来回检测，这是城市操作系统在新型城市基础设施建设中的应用体现；在大自然中，智慧水立方平台为江河湖泊全流域水环境管理和治理提供跟踪监测、实时预警。这是谁在佑护我们的安全？让我们一起走进人工智能在安防领域的应用。 【任务实施】 4.1智能安防的定义及与传统安防的区别     智能安防技术是一种利用人工智能对视频、图像进行存储和分析，从中识别安全隐患并对其进行处理的技术。智能安防与传统安防的最大区别在于智能化，传统安防对人的依赖性比较强，非常耗费人力，而智能安防能够通过机器实现智能判断，从而尽可能实现实时地安全防范和处理。     当前，高清视频、智能分析等技术的发展，使得安防从传统的被动防御向主动判断和预警发展，行业也从单一的安全领域向多行业应用发展，进而提升生产效率并提高生活智能化程度，为更多的行业和人群提供可视化及智能化方案。用户面对海量的视频数据，已无法简单利用人海战术进行检索和分析，需要采用人工智能技术作专家系统或辅助手段，实时分析视频内容，探测异常信息，进行风险预测。从技术方面来讲，目前智能安防分析技术主要集中在两大类：一类是采用画面分割前景提取等方法对视频画面中的目标进行提取检测，通过不同的规则来区分不同的事件，从而实现不同的判断并产生相应的报警联动等，例如：区域入侵分析、打架检测、人员聚集分析、交通事件检测等；另一类是利用模式识别技术，对画面中特定的物体进行建模，并通过大量样本进行训练，从而达到对视频画面中的特定物体进行识别，如车辆检测、人脸检测、人头检测（人流统计）等应用。     智能安防目前涵盖众多的领域，如街道社区、道路、楼宇建筑、机动车辆的监控，移动物体监测等。今后智能安防还要解决海量视频数据分析、存储控制及传输问题，将智能视频分析技术、云计算及云存储技术结合起来，构建智慧城市下的安防体系。 4.2智能安防中的人工智能核心技术     随着平安城市建设的不断推进，监控点位越来越多，从最初的几千路到几万路甚至于到现在几十万路的规模，依托视频和卡口产生的海量数据，智能安防已经延展到事后追查、事中防范响应、事前预防的全生命周期。目标检测、目标跟踪和目标属性提取等视频结构化技术，以及海量数据管理、大规模分布式计算和数据挖掘等大数据技术已经取代传统的人海战术，实时分析视频内容，探测异常信息，进行风险预测。视频结构化技术可以通过识别目标并持续跟踪生成图片结果，提取目标属性归纳可视化特征；大数据技术则用于采集、存储人工智能应用所涉及的全方位数据资源，并基于时间轴进行数据累积，开展特征匹配和模型仿真，辅助安防部门更快、更准地找到有效的资源，进行风险预测和评估。 4.3智能安防领域的典型企业     从提供的产品类型来看，智能安防领域的企业主要分为人工智能芯片、硬件和系统、软件算法三大类别。在芯片领域，跨国巨头企业占较高市场份额，如美国英伟达和英特尔。在硬件和系统领域，各国均以采购本国产品为主，国内主要采购对象为海康威视、大华集团，海康具有深厚的技术积累和成规模的研发团队，大华持续构建广泛的营销网络；美国则有ADT、DSC、OPTEX等高端品牌占据了安防市场大部分份额。在软件算法领域，美国谷歌、Facebook、微软开源代码并提供整体解决方案，中国旷视科技、商汤科技、云从科技等企业也在专注于技术创新研发。 【任务拓展】     谈谈你所生活学习的城市小区或校园内的智能安防的应用 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:41:33 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part1/xm4/rw5.html":{"url":"part1/xm4/rw5.html","title":"任务五 智能医疗","keywords":"","body":"任务五 智能医疗 【任务描述】 相隔千里，守护无间     在2020年疫情期间，搭载腾讯AI医学影像产品——腾讯觅影AI和腾讯云技术的人工智能CT设备，在湖北多家医院进行部署，帮助医护人员进行诊疗。患者做完CT检查后，设备只需几秒钟就可完成AI识别，快速检出和判别疑似新冠肺炎，自动勾勒病灶，通过自动化的统计和直方图显示，为医生快速挑出需要重点审阅的疑点，第一时间进行准确的诊断，大幅缩短医生读片时间，提升工作效率并且降低误诊率，有效缓解了疫情初期医疗资源严重不足的问题。基于“腾讯觅影”在AI+医疗探索上取得的突破，国家卫计委和国家工信部联合授予了其互联网医疗健康行业“墨提斯奖”，该奖被誉为医疗健康行业的“图灵奖”，代表着中国智能终端产业的最高荣誉。我们一起来看看人工智能在医疗领域的应用吧。 【任务实施】 5.1什么是智能医疗     人工智能的快速发展，为医疗健康领域向更高的智能化方向发展提供了非常有利的技术条件。促使智能机器和设备代替医生完成部分工作，更多地触达用户，只是智能医疗功用的部分体现。运用人工智能技术对医疗案例和经验数据进行深度学习和决策判断，显著提高医疗机构和人员的工作效率并大幅降低医疗成本，才是智能医疗的核心目标。同时，通过人工智能的引导和约束，促使患者自觉自查、加强预防，更早发现和更好管理潜在疾病，也是智能医疗在未来的重要发展方向。     在辅助诊疗方面，通过人工智能技术可以有效提高医护人员工作效率，提升一线全科医生的诊断治疗水平。如利用智能语音技术可以实现电子病历的智能语音录入；利用智能影像识别技术，可以实现医学图像自动读片；利用智能技术和大数据平台，构建辅助诊疗系统。     在疾病预测方面，人工智能借助大数据技术可以进行疫情监测，及时有效地预测并防止疫情的进一步扩散和发展。以流感为例，很多国家都有规定，当医生发现新型流感病例时需告知疾病控制与预防中心。但由于人们可能患病不及时就医，同时信息传达回疾控中心也需要时间，因此，通告新流感病例时往往会有一定的延迟，人工智能通过疫情监测能够有效缩短响应时间。     在医疗影像辅助诊断方面，影像判读系统的发展是人工智能技术的产物。早期的影像判读系统主要靠人手工编写判定规则，存在耗时长、临床应用难度大等问题，从而未能得到广泛推广。影像组学是通过医学影像对特征进行提取和分析，为患者预前和预后的诊断和治疗提供评估方法和精准诊疗决策。这在很大程度上简化了人工智能技术的应用流程，节约了人力成本。 5.2智能医疗领域的核心技术     医疗水平的提升和医疗设备的完善使得患者就诊过程会产生与日俱增的就诊数据，爆炸式信息增长让医生无法无差错的完成诊断和治疗，同时随着人们健康意识的加强，预防性和精准性治疗同时受到关注。图像识别、语音语义识别、深度学习技术在医疗领域得到广泛应用。图像识别、语音语义识别技术可充分获取患者的饮食习惯、锻炼周期、服药习惯等个人生活习惯信息以对症下药，深度学习技术可通过计算机模拟预测药物活性、安全性和副作用，降低药物研发周期，并辅助医生工作实现更精准诊断和治疗。 5.3智能医疗领域的典型企业     腾讯觅影AI辅诊开放平台是腾讯公司是腾讯首款将人工智能技术运用到医学领域的产品。它聚合了腾讯公司内部包括AI Lab、优图实验室、架构平台部等多个顶尖人工智能团队的能力，构建的由医疗机构、科研团体、器械厂商、AI创业公司、信息化厂商、高等院校、公益组织等多方参与的医疗影像开放创新平台。“AI医学影像”和“AI辅助诊断”是腾讯觅影AI辅诊开放平台的两项核心能力，其通过模拟医生的成长学习来积累医学诊断能力，可辅助医生诊断、预测700多种疾病，涵盖了医院门诊90%的高频诊断，其遵循与人类医生类似的学习过程，主要分为三个阶段：首先，其运用自然语言处理和深度学习等人工智能技术，学习、理解和归纳权威医学书籍文献、诊疗指南和病历等医疗信息，自动构建出一张“医学知识图谱”；然后，基于病历检索推理和知识图谱推理知识，建立诊断模型；最后，在人类医学专家的校验下，优化诊断模型。     微医云是国际首个专注于智能医疗的云平台，致力于打造医疗健康产业数字化、智能化基础设施，场景连接和医疗数据基础上，微医云将通过大数据、云计算、机器学习等技术，开发医学人工智能辅助诊疗系统，让家庭通过健康终端，可以享受到医疗健康服务，为政府、医疗机构、医生、医疗健康企业等提供包含互联网医院、互联网医联体、家庭医生签约、智能分级诊疗、医学人工智能辅助诊疗、云药房、数字化医药集采、智能医保控费等在内的数十种智能医疗云和医学人工智能解决方案，提升中国医疗健康服务体系整体效能。     北京康夫子科技有限公司是一家专注于人工智能技术在医疗健康领域应用研发的技术驱动型公司，凭借国际领先的知识抽取和知识推理、表示等知识图谱构建技术，康夫子成功打造了“医疗大脑”知识内核（知识图谱）。康夫子医疗大脑以数万本医学书籍、千万篇医疗论文、数十万份临床病历为基础以保证数据的科学性，同时基于千万篇医疗问答将普通公众对症状的描述和对疾病的理解准确地映射在严肃医疗平面。因此，康夫子“医疗大脑”被业界广泛评价为“接地气”的临床辅助决策和循证医学产品。     由中国平安健康医疗科技有限公司打造的 “平安好医生”以医生资源为核心，利用移动互联网平台进行医患实时沟通，包括预防保健、导医初诊、预约挂号等诊前服务，以及复诊随访、康复指导、慢病管理、用药提醒等诊后服务。自主研发的国内首个中医\"智能闻诊\"系统融合AI医疗科技和传统中医理论精髓，通过采集用户声音并进行AI分析，识别其是否属于气郁、气虚、阳虚等中医体质，实现听音辨病。 纪录片《戴口罩的日子》走近微医和全国医生数字抗疫的“空中战场”第三集《云起》第五集《异域同天》 【任务拓展】 通过网络等各种途径查找哪些智能医疗平台和系统助力我国新冠肺炎的防治。 思政聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 06:41:30 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm1/xm.html":{"url":"part2/xm1/xm.html","title":"第二章 人工智能技术应用","keywords":"","body":"项目一 智能客服机器人 项目情景     智能客服机器人是指用电脑代替人工执行客服的任务，在如今的在线客服系统中日渐成为不可或缺的存在。得益于互联网技术、人工智能、大数据的发展，从最初代的智能客服机器人到如今经历了很多技术革新，功能也不断完善，在机器人语言处理、语义识别、关键词匹配、知识库建设乃至自主学习等方面都有了很大改进，越来越多地被运用于如今人们的工作生活。     某高校针对新生整理了一些问答（Q&A）集合放在了学校微信公众号和官网页面，但是学生和家长觉得问题不够全面而且需要从问答列表中找自己要问的问题，体验感不好。希望对现有的问答集合进行智能化升级为智能校园客服，新生或者新生家长可以语音提问，客服机器人进行语音回答。 项目导览     智能客服机器人技术路线为输入语音，系统进行语音识别并转换成文本，对转换的文本进行语义理解从答案库选择匹配的答案进行回答，回答提供文本和语音两种模式。为了节约资源，没人需要服务的时候让机器人进入休眠状态，所以在语音输入部分增加语音唤醒功能。 探究主题 探究活动 实现方法 语音数据采集 利用麦克风录音并保存到本地 语音转文本 将声音文件转化成中文文本 文本转语音 1. 输入中文，转换成声音文件保存本地并播放 2.开发语音助手：将Word文档中的中文用普通话读出来。 语音识别应用 1.天气助手 2.聊天机器人 项目目标 理解语音识别原理 了解语音识别技术应用 掌握语音采集和处理的方法 了解自然语言处理关键技术 能调用API进行语音识别的应用开发 知识导览 知识准备     语音技术是计算机领域中的关键技术，有自动语音识别技术（ASR）和语音合成技术（TTS）。     语音识别技术的研究最早开始于20世纪50年代，1952年在贝尔研究所，Davis等人研制了世界上第一个能识别10个英文数字发音的实验系统。1960年英国的Denes等人研制了第一个计算机语音识别系统。大规模的语音识别研究始于上世纪70年代以后，并在小词汇量、孤立词的识别方面取得了实质性的进展。上世纪80年代以后，语音识别研究的重点逐渐转向大词汇量、非特定人连续语音识别。上世纪90年代以后，在语音识别的系统框架方面并没有什么重大突破。但是，在语音识别技术的应用及产品化方面出现了很大的进展。比如，DARPA是在上世界70年代由美国国防部远景研究计划局资助的一项计划，旨在支持语言理解系统的研究开发工作。进入上世纪90年代，DARPA计划仍在持续进行中，其研究重点已转向识别装置中的自然语言处理部分，识别任务设定为“航空旅行信息检索”。     我国的语音识别研究起始于1958年，由中国科学院声学所利用电子管电路识别10个元音。由于当时条件的限制，中国的语音识别研究工作一直处于缓慢发展的阶段。直至1973年，中国科学院声学所开始了计算机语音识别。进入上世纪80年代以来，随着计算机应用技术在我国逐渐普及和应用以及数字信号技术的进一步发展，国内许多单位具备了研究语音技术的基本条件。与此同时，国际上语音识别技术在经过了多年的沉寂之后重又成为研究的热点。在这种形式下，国内许多单位纷纷投入到这项研究工作中去。1986年，语音识别作为智能计算机系统研究的一个重要组成部分而被专门列为研究课题。在“863”计划的支持下，中国开始组织语音识别技术的研究，并决定了每隔两年召开一次语音识别的专题会议。自此，我国语音识别技术进入了一个新的发展阶段。自2009年以来，借助机器学习领域深度学习研究的发展以及大数据语料的积累，语音识别技术得到突飞猛进的发展。 1. 什么是语音识别     语音识别，又称为自动语音识别(Automatic Speech Recognition，ASR)、语音转文本（Speech to Text，STT），其核心任务就是将人类的语音转换成对应的文字，让机器\"听懂\"人类的语音。语音识别技术的出现为人机交互的发展提供了新的方向。随着人工智能的发展，智能语音功能早已在车载、智能家居、手机端等场景中实现，语音对话机器人、语音助手、互动工具等智能产品也走进了人们的日常生活。 2. 语音识别的原理     语音识别技术拆分下来，主要可分为“输入—编码—解码—输出 ”4个流程。 第1步：通过硬件输入声音信号，声音是一种波，其实就是输入一段声波文件。常见的音频文件mp3等格式都是压缩格式，必须转成非压缩的纯波形文件来处理，比如Windows PCM文件，也就是wav文件。wav文件里存储的除了一个文件头以外，就是声音波形的一个个点了，如图所示。 第2步：将输入的音频进行信号处理，帧（毫秒级）拆分，图中每个竖条是一帧，对拆分出的小段波形按照人耳特征变成多维向量信息，若干个帧信息识别成状态。这个过程叫做声学特征提取。 第3步：将第2步中的状态组合形成音素，通常3个状态组合成1个音素。 第4步：将音素组成字词并串连成句 。 经过以上四个步骤这实现由语音转换成文字了。 3.语音识别技术 （1）端点检测     端点检测（Voice ActivityDetection，简称VAD），主要作用是区分一段声音是有效的语音信号还是非语音信号。VAD是语音识别中检测句子之间停顿的主要方法，同时也是低功耗所需要考虑的重要因素。VAD通常用信号处理的方法和基于机器学习的方法来做。 （2）特征提取     特征提取就是把时域的声音原始信号通过某类方法提取出固定的特征序列，为训练声学模型准备输入。事实上深度学习训练的模型不会脱离物理的规律，只是把幅度、相位、频率以及各个维度的相关性进行了更多的特征提取。 （3）声学模型     声学模型是语音识别中最为关键的部分，是将声学和计算机学的知识进行整合，以特征提取部分生成的特征作为输入，并为可变长的特征序列生成声学模型分数。声学模型核心要解决特征向量的可变长问题和声音信号的多变性问题。事实上，语音识别的发展基本上都是指声学模型的进展。声学模型迭代这么多年，已经有很多模型，比较有代表性的是高斯混合模型（GMM）、隐马尔可夫模型（HMM）和深度学习。 高斯混合模型（GMM）     高斯混合模型（英文Gaussian Mixture Model，简称GMM），是基于傅立叶频谱语音特征的统计模型，可以通过不断迭代优化求取GMM中的加权系数及各个高斯函数的均值与方差。GMM模型训练速度较快，声学模型参数量小，适合离线终端应用。深度学习应用到语音识别之前，GMM-HMM混合模型一直都是优秀的语音识别模型。但是GMM不能有效对非线性或近似非线性的数据进行建模，很难利用语境的信息，扩展模型比较困难。 隐马尔可夫模型（英文Hidden Markov Model，简称HMM），用来描述一个含有隐含未知参数的马尔可夫过程，从可观察的参数中确定该过程的隐含参数，然后利用这些参数来进一步分析。HMM是一种可以估计语音声学序列数据的统计学分布模型，尤其是时间特征，但是这些时间特征依赖于HMM的时间独立性假设，这样对语速、口音等因素与声学特征就很难关联起来。HMM还有很多扩展的模型，但是大部分还只适应于小词汇量的语音识别，大规模语音识别仍然非常困难。 深度神经网络（英文Deep Neural Network，简称DNN),是较早用于声学模型的神经网络，DNN可以提高基于高斯混合模型的数据表示的效率，特别是DNN-HMM混合模型大幅度地提升了语音识别率。由于DNN-HMM只需要有限的训练成本便可得到较高的语音识别率，目前仍然是语音识别工业领域常用的声学模型。循环神经网络（RNN）和卷积神经网络（CNN）在语音识别领域的应用，主要是解决如何利用可变长度语境信息的问题，CNN/RNN比DNN在语速鲁棒性方面表现的更好一些。 通过训练语料学习词之间的关系来估计词序列的可能性，最常见的语言模型是N-Gram模型。近年，深度神经网络的建模方式也被应用到语言模型中，比如基于CNN及RNN的语言模型。 解码是决定语音识别速度的关键因素，解码过程通常是将声学模型、词典以及语言模型编译成一个网络，基于最大后验概率的方法，选择一条或多条最优路径作为语音识别结果。解码过程一般可以划分动态编译和静态编译，或者同步与异步的两种模式。目前比较流行的解码方法是基于树拷贝的帧同步解码方法。 4.语音识别开源平台和开放平台     语音识别的开源平台很多，但是部署应用相当复杂，特别是基于深度学习的开源平台，需要大量的计算和数据以训练引擎，这个对于一般的用户来说也是一个非常高的技术门槛。因此对于一般的创业型公司来讲，显然自己部署语音识别引擎也不划算，那么免费的开放平台就是很好的选择。 （1）Nuance NVP     Nuance是语音识别领域的老牌劲旅，除了语音识别技术外，还包扩语音合成、声纹识别等技术。Nuance Voice Platform(NVP)是Nuance公司推出的语音互联网平台，这是一个开放的、基于统一标准的语音平台产品。它能够支持客户公司已有的IT投资和基础设备，同时可以加入语音的应用。 （2）Microsoft Speech API     微软的Speech API是微软推出的包含语音识别（SR）和语音合成（SS）引擎的应用编程接口，SAPI支持多种语言的识别和朗读，包括英文、中文、日文等。但是，微软总有个问题，就是任何一个产品都得和Windows绑定。 （3）Google Speech API     这个领域自然不能少了苹果和谷歌，但是苹果打死也不会免费的，而谷歌打死也不会收费的。但是，这没有意义了，因为不管你的引擎多么优秀，现在的语音识别还是要基于云的。所以国内的众多创业用户压根用不了，甚至也访问不到。但是如果开发的产品主要部署在国外，Google Speech API可以备选的，因为这个API调用起来更加方便。 （4）科大讯飞语音     科大讯飞1999年成立，作为中国最大的智能语音技术提供商，在智能语音技术领域有着长期的研究积累，并在中文语音合成、语音识别、口语评测等多项技术上拥有国际领先的成果。科大讯飞目前提供语音识别、语音合成、声纹识别等全方位的语音交互技术。目前也是国内创业团队使用最为广泛的开放语音识别平台。 （5）百度语音     百度语音自从和中科院声学所合作以后，在贾磊带领下短时间内建立起来自己的引擎，而且打出了永久免费的口号，在很多领域抢占了一定的市场。     国内的语音识别开放平台还很多，和国外有所不同，国内开放的都是语音识别的专业公司，比如云之声、思必驰、捷通华声等等。 5.Python语音识别库     对于 Python 使用者而言，一些语音识别服务可通过各大平台提供的开源 API 在线使用，且其中大部分也提供了 Python SDK。 我们不需要从头开始构建任何机器学习模型，PyPI中有一些现成的语音识别软件包，包括： apiai google-cloud-speech pocketsphinx SpeechRcognition watson-developer-cloud wit     一些软件包（如 wit 和 apiai ）提供了一些超出基本语音识别的内置功能，如识别讲话者意图的自然语言处理功能。其他软件包，如谷歌云语音，则专注于语音向文本的转换，其中SpeechRecognition 就因便于使用脱颖而出。     pyaudio库可以进行录音，播放，生成wav文件等等。PyAudio 提供了 PortAudio 的 Python 语言版本，这是一个跨平台的音频 I/O 库，使用 PyAudio 你可以在 Python 程序中播放和录制音频。为PoTaTudio提供Python绑定，跨平台音频I/O库。使用PyAudio，您可以轻松地使用Python在各种平台上播放和录制音频，例如GNU/Linux、微软Windows和苹果Mac OS X/MACOS。 6.语音识别中的硬件     传声器：通常称为麦克风，是一种将声音转换成电子信号的换能器，即把声信号转成电信号，其核心参数是灵敏度、指向性、频率响应、阻抗、动态范围、信噪比、最大声压级（或AOP，声学过载点）、一致性等。传声器是语音识别的核心器件，决定了语音数据的基本质量。     扬声器：通常称为喇叭，是一种把电信号转变为声信号的换能器件，扬声器的性能优劣对音质的影响很大，其核心指标是TS参数。语音识别中由于涉及到回声抵消，对扬声器的总谐波失真要求稍高。     激光拾声：这是主动拾声的一种方式，可以通过激光的反射等方法拾取远处的振动信息，从而还原成为声音，这种方法以前主要应用在窃听领域，但是目前来看这种方法应用到语音识别还比较困难。     微波拾声：微波是指波长介于红外线和无线电波之间的电磁波，频率范围大约在 300MHz至300GHz之间，同激光拾声的原理类似，只是微波对于玻璃、塑料和瓷器几乎是穿越而不被吸收。     高速摄像头拾声：利用高速摄像机来拾取振动从而还原声音，这种方式需要可视范围和高速摄像机，只在一些特定场景里面应用。 7.语音信号文件WAV格式     wav格式，是微软开发的一种文件格式规范，整个文件分为两部分。第一部分是“总文件头”，就包括两个信息，chunkID，其值为“RIFF”，占四个字节；ChunkSize，其值是整个wav文件除去chunkID和ChunkSize，后面所有文件大小的字节数，占四个字节。第二部分是Format，其值为“wave”，占四个字节。它包括两个子chunk，分别是“fmt ”和“data”。在fmt子chunk中定义了该文件格式的参数信息，对于音频而言，包括：采样率、通道数、位宽、编码等等；data部分是“数据块”，即一帧一帧的二进制数据，对于音频而言，就是原始的PCM数据。从语音识别的原理可以知道，我们语音数据文件存储为WAV格式是最好的。 8.语音识别技术应用场景     语音识别已经深入应用到众多垂直领域中，概括起来，智能语音识别主要应用于以下3个方面，这也是语音识别商业化发展的主要方向。 语音输入系统：将语音识别成文字，摆脱生僻字和拼音障碍，让用户更加便捷，如微信中语音转文字、讯飞输入法、直播等视频实时字幕等。 语音控制系统：通过语音控制设备进行相关操作，彻底解放双手，如智能音箱、智能汽车系统、智能家居、智能穿戴。 语音对话系统：这是结合了语音识别与自然语言处理的技术，根据用户的语音实现交流与对话，保证回答的内容正确，对语义理解要求较高。目前，语音对话系统已经广泛应用于各类服务场景，如电商平台的智能客服、智能服务机器人等。相比于语音输入系统和语音控制系统，语音对话系统更加复杂，代表着语音识别的未来方向。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:15:52 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm1/rw1.html":{"url":"part2/xm1/rw1.html","title":"任务一 语音数据采集","keywords":"","body":"任务一 语音数据采集 【任务描述】     利用麦克风录音并保存到本地，文件格式为WAV。 【任务实施】 步骤1 安装pyaudion、wave依赖库。我们采用pip install命令方式，参考如下： pip install PyAudio pip install wave 步骤2 创建PyAudio对象，打开声卡，创建缓存空间，代码如下： import pyaudio import wave CHUCK = 256 #设置底层缓存的块大小为256 FORMAT = pyaudio.paInt16 #设置采样深度为16位 CHANNELS = 2 #设置声道数为2 RATE = 16000 #设置采样率为16k RECORD_SECONDS = 10 #设置 录音时长为10s # 实例化一个PyAudio对象 p = pyaudio.PyAudio() # 打开声卡 stream = p.open(format = FORMAT, channels = CHANNELS, rate = RATE, input=True, frames_per_buffer=CHUCK) 步骤3 录音10秒，并且将音频数据存储到列表: # 创建列表用来存储采样的音频数据 record_buf = [] print(\"*****开始录音：请在10s内输入语音***\") for i in range(0,int(RATE/CHUNK*RECORD_SECONDS)): data = stream.read(CHUNK) #读取声卡缓冲区的音频数据 record_buf.addpen(data) #将读取的音频数据追加到列表 print('***录音结束***') 步骤4 通过wave将音频数据写到wav文件中。 wf = wave.open('audio1.wav', 'wb') # 一读写模式创建一个音频文件，名字为“audio1.wav\" wf.setnchannels(CHANNELS) # 设置声道数为 wf.setsampwidth(p.get_sample_size(FORMAT)) # 设置采样深度 wf.setframerate(RATE) # 设置采样率 # 将数据写入创建的音频文件 wf.writeframes(b\"\".join(record_buf)) 步骤5 录音结束，停止并关闭声卡。不管是从数据安全还是资源管理方面，这一步操作都是必须的。 wf.close() # 关闭文件 stream.stop_stream() # 停止声卡 stream.close() # 关闭声卡 pa.terminate() # 终止pyaudio     经过以上5个步骤，运行程序，当出现提示后开始录音，10秒后录音自动结束，程序文件所在目录下新增“audio1.wav”文件。播放audio1.wav，听听看是不是刚刚录制的声音吧。 本任务实战代码如下,位于/xm1/rw1.ipynb 同学们来运行一下吧 本实验需要使用到麦克风，请同学们编写完代码后本地运行 --> 【任务拓展】     语音数据采集的过程涉及到数据采集方式、数据清洗、数据标注、数据管理和数据安全处理。 语音数据采集方式：将用户与机器对话的声音信息收集起来，一般分为近场和远场两个部分，近场采集一般基于手机就可完成，远场采集一般需要麦克风阵列。数据采集同时还有关注采集环境，针对不同数据用途，语音采集的要求也很不一样，比如人群的年龄分布、性别分布和地域分布等。 语音数据清洗：将采集的数据进行预处理，剔除不合要求的语音甚至是失效的语音，为后面的数据标注提供精确的数据。 语音数据标注：将声音的信息翻译成对应的文字，训练一个声学模型，通常要标注数万个小时，而语音是时序信号，所以需要的人力工时相对很多，同时由于人员疲惫等因素导致标注的错误率也比较高。如何提高数据标注的成功率也是语音识别的关键问题，有多少智能就有多少人工，数据标注工作者也是推动人工智能技术发展的贡献者。 数据管理：对标注数据的分类管理和整理，这样更利于数据的有效管理和重复利用。 数据安全：对声音数据进行安全方便的处理，比如加密等，以避免敏感信息泄露。我国已经出台了《数据安全管理办法》等一系列数据安全的法律。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:18:19 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm1/rw2.html":{"url":"part2/xm1/rw2.html","title":"任务二 语音转文字","keywords":"","body":"任务二 语音转文字 【任务描述】     语音识别技术需要强大的算力支撑，所以很难离线部署到本地进行应用开发，但是科大讯飞、百度等企业的开放平台提供了API免费供开发者使用。本任务用Python语言调用百度API将语音文件转换成中文。 【任务实施】 步骤1 进入百度 AI 官网cloud.baidu.com.，注册账号和语音识别服务，创建语音识别应用。 进入右上角进行注册。 着打开左侧产品服务，选择“人工智能-语音技术”，进入页面选择创建应用。 获取应用的 ID 和 Key，调用API的时候需要用到。 领取语音识别和语音合成的免费额度。 步骤2 安装python依赖包     任务1已经安装过wave和pyaudion库了，在这个任务我们就可以直接引用，但还需要安装baiduaip和SpeechReconition包。 pip install baidu-aip pip install SpeechRecognition 步骤3 学习百度的官方文档，根据官方文档简介和接口说明编写代码。 利用步骤1中申请的APP_ID、APP_KEY和SECRET_KEY新建AipSpeech对象。 读取保存的语音文件并调用asr函数实现将语音文件转换为中文。     asr函数中包括6个参数，前3个是必须要填写的，后3个选填。参考官方文档信息，第1个参数是本地读取的语音文件（格式可以是pcm、wav、amr中的一种），第2个参数第一个参数中的语音文件格式（字符串格式）、第3个参数是语音文件采样率（只能是16000或8000，知道为什么我们在任务1中采集声音用16000的采样率了吗？）。除了这3个必须要填的参数，一般我们要转换成简体中文还需要添加dev_pid参数，参考示例添加方式为{ 'dev_pid': 1537,}。 编写代码，将任务1的录音功能封装到rec（）函数，导入步骤2安装的库，创建AipSpeech对象（client），调用方法asr方法，将录音转换成文本存储到result。 from aip import AipSpeech import speech_recognition as sr from playsound import playsound import time time = time.perf_counter # 填写自己申请的语音识别应用ID、KEY APP_ID = '******' API_KEY = '******' SECRET_KEY = '******' file_Path = 'recording.wav' client = AipSpeech(APP_ID,API_KEY,SECRET_KEY) #新建一个AipSpeech对象 # 录音 def rec(): rec_audio = sr.Recognizer() with sr.Microphone(sample_rate=16000) as source: print('开始录音') audio = rec_audio.record(source,duration=10) with open(file_Path,'wb') as fw: fw.write(audio.get_wav_data()) print('结束录音') # 读取文件 def get_file_content(file_Path): with open(file_Path,'rb') as f: return f.read() rec() #开始录音 # 识别本地语音文件 result = client.asr(get_file_content(file_Path),'wav',16000,{'dev_pid':1537}) 步骤4 从result中提取转换后的文本并输出到屏幕。     返回样例的信息是数据字典类型，其中key为“result”中存储了语音转换后的文本内容，其中“result”的数据类型是列表，所以result[‘result’][0]就是我们语音对应的文本内容。 print(result['result'][0]) 步骤5 在输出后文本后，播放录音进行校对。     支持python3的playsound模块可以很方便的播放wav、mp3等格式的音频文件，安装和import playsound模块后，利用playsound函数就可以了。 playsound(file_Path)     完成以上步骤后，电脑就可以实现让输入声音，输出你说话的内容文本和录音了，完整代码如下。 from aip import AIPSpeech import speech_recognition as sr from playsound import playsound import time time = time.perf_counter # 填写自己申请的语音识别应用ID、KEY APP_ID = '******' API_KEY = '******' SECRET_KEY = '******' file_Path = 'recording.wav' client = AipSpeech(APP_ID,API_KEY,SECRET_KEY) #新建一个AipSpeech对象 # 录音 def rec(): rec_audio = sr.Recognizer() with sr.Microphone(sample_rate=16000) as source: print('开始录音') audio = rec_audio.record(source,duration=10) with open(file_Path.'wb') as fw: fw.write(audio.get_wav_data()) print('结束录音') # 读取文件 def get_file_content(file_Path): with open(file_Path,'rb') as f: return f.read() rec() #开始录音 # 识别本地语音文件 result = client.asr(get_file_content(file_Path),'wav',16000,{'dev_pid':1537}) print(result['result'][0]) playsound(file_Path) 本任务实战代码如下,位于/xm1/rw2.ipynb 同学们来运行一下吧 【任务拓展】     任务2中我们完成了普通话的文本转换功能。那么英语、四川话、粤语是否可以转换呢？我们一起来查看百度语音识别技术中的接口说明里面的dev_pid参数说明。1537对应普通话，1637对应粤语，还可以对远场录音进行普通话文本转换。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:19:36 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm1/rw3.html":{"url":"part2/xm1/rw3.html","title":"任务三 语音合成","keywords":"","body":"任务三 语音合成 （语音助手） 【任务描述】     文字与音频的互相转换是自然语言处理中很关键的技术点。“把文字转换成声音，让你的应用开口说话”就是利用语音合成技术将文本转换成音频。现在我国各大AI企业都有对应的免费开放API为开发者提供应用服务。例如，百度2108年6月份就发布了百度语音识别无限量使用。本任务完成从键盘输入中文，调用百度API将输入的中文转换成mp3音频文件同时播报这段音频。 【任务实施】     本任务使用任务2中已经申请的百度账号，请确保已经领取语音合成的免费额度。 步骤1 与任务2中一样，import利用百度账号创建一个client对象。 步骤2 定义变量text，存储从键盘输入的内容。 text = input('请输入：') 步骤3 参考官网技术文档中“接口说明”，调用synthesis方法将text转换成音频并以mp3文件保存到本地。“per”参数可以用来设置合成语音的不同声音模式，“spd”用来设置语速，“vol”用来设置语调，这些参数虽然是可选设置，但是可以根据不同内容设置多样化的语音表达，赶紧试试吧。 步骤4 利用playsound播报MP3音频文件。 安装playsound pip install playsound playsound的使用方法 from playsound import playsound playsound('audio.mp3')     本任务中result存储的是文字合成的二进制代码，可以用在result = client.synthesis（）之后增加一句print(result)语句，运行出现类似下图中的二进制码则表明文本合成语音成功了。 本次任务完整参考代码如下： from aip import AipSpeech from playsound import playsound # 填写自己申请的 ID 与 Key APP_ID = '*******' API_KEY = '******' SECRET_KEY = '******' client = AipSpeech(APP_ID,API_KEY,SECRET_KEY) text = input('请输入：') result = client.synthesis(text,'zh',1,{'vol':5,'per':0}) print(result) # 识别正确放回语音二进制 错误放回dict if not isinstance(result,dict): with open('audio.mp3','wb') as f: f.write(result) playsound('audio.mp3') 【任务拓展】     随着AI技术的发展，语音合成技术已经被越来越多的应用，很多网站都在文章内容页面嵌入了语音朗读功能，AI合成主播也开始在新闻媒体中应用。我们也可以改进任务3，让机器给我们朗读一篇文章。下面通过语音合成技术将本地的Word文档变成“有声”读物，希望聪明的你举一反三，例如天气播报助手等。 步骤1 安装python-docx库。python-docx是一个用于创建和更新微软Word（.docx）文件的Python库，具备设置段落、分页符、表格、图片、标题、样式等几乎所有的word文档中能常用的功能，但是主要用来创建文档。 步骤2 import Document ，利用Document打开本地的docx文档。 from docx import Document path = 'new.docx' document = Document(path) 步骤3 读取docx文档中的段落文字并保存到text中。 text = '' for garagraph in document.paragraphs: print(garagraph.text) text += garagraph.text     接下来就是将text转换成语音，操作与任务3一样，完整的参考代码如下： from aip import AipSpeech from playsound import playsound from docx import Document path = 'new.docx' document = Document(path) # 填写自己申请的 ID 与 Key APP_ID = '*******' API_KEY = '******' SECRET_KEY = '******' client = AipSpeech(APP_ID,API_KEY,SECRET_KEY) text = '' for garagraph in document.paragraphs: print(garagraph.text) text += garagraph.text result = client.synthesis(text,'zh',1,{'vol':5,'per':0}) print(result) # 识别正确放回语音二进制 错误放回dict if not isinstance(result,dict): with open('audio.mp3','wb') as f: f.write(result) playsound('audio.mp3') 本任务实战代码如下,位于/xm1/rw3.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:20:53 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm1/rw4.html":{"url":"part2/xm1/rw4.html","title":"任务四 聊天机器人","keywords":"","body":"任务四 聊天机器人 【任务描述】     工业界和学术界都十分关注聊天系统的研发，主要原因在于，一方面，聊天技术应用能够极大地缩减人力资源;另一方面，聊天技术代表了自然语言处理的最高水平之一，是许多科学家向往突破的难题，根据聊天系统目的及功用的不同，可分成三大类型∶ 闲聊式机器人，较有代表性的有微软小冰、微软小娜、苹果的Siri、小i机器人等，主要以娱乐为目的；知识问答型机器人，比如watson 系统最早在 2011 年的问答节目 Jeopardy 上击败了所有人类选手，赢得百万美元奖金；任务型聊天机器人，以完成某一领域的具体任务为导向，在工业界应用较广泛，如订票系统、订餐系统等。     本任务中聊天机器人以自然语言处理为主，自然语言处理在聊天机器人中的作用是对输入的语句进行分析，提取出实体、意图等关键信息。自然语言处理同样是一个需要大量算力的算法，我们可以通过图灵、百度等 API实现。这里，我们使用 YunGe API 编写一个对话机器人。 【任务实施】 步骤1 导入以下依赖库。 import requests import json import time import random 步骤2 利用random函数和time方法创建一个随机字符串，用来区分每一次对话的对象。 random_str = str(time.time()+random.randint(0,100)) print(random_str) 步骤3 定义一个函数xiaoxin，调用Yunge API，发送text，获得回复. def xiaoxin(text): res = '' url = \"https://testapi.smartyg.com/api/post_gossip\" keys = \"5f15a18f3f03f7e88020acb1c2f8c93c\" result = requests.post(url, json.dumps( {\"keys\": keys, \"question\": text , \"id\":\"1\", \"random_str\":randomstr,\"state\":True})).text data = json.loads(result) if data[\"flag\"] == \"success\": res = data[\"answay\"] return res     requests中的参数含义如下： 参数 含义 keys 请求的keys question 传输的语句 id 默认是1 random_str 随机字符串（时间+随机数的组合） state 默认true 步骤4 调用xiaoxin，创建闲聊机器人。 while True: question = input('我：') answay = xiaoxing(question) print('robot:'answay)     完整代码参考如下: import requests import json import time import random random_str = str(time.time()+random.randint(0,100)) print(random_str) def xiaoxin(text): res = '' url = \"https://testapi.smartyg.com/api/post_gossip\" keys = \"5f15a18f3f03f7e88020acb1c2f8c93c\" result = requests.post(url, json.dumps( {\"keys\": keys, \"question\": text , \"id\":\"1\", \"random_str\":randomstr,\"state\":True})).text data = json.loads(result) if data[\"flag\"] == \"success\": res = data[\"answay\"] return res while True: question = input('我：') answay = xiaoxing(question) print('robot:'answay) 本任务实战代码如下,位于/xm1/rw4.ipynb 同学们来运行一下吧 【任务拓展】     试试为聊天机器人添加本地天气查询功能。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:21:48 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm1/rw5.html":{"url":"part2/xm1/rw5.html","title":"任务五 校园客服","keywords":"","body":"任务五 校园客服 【任务描述】     在智能客服的业务场景中，对于用户频繁问到的业务知识类问题的自动解答（以下简称为FAQ）是一个非常关键的需求，可以说是智能客服最为核心的用户场景，可以最为显著地降低人工客服的数量与成本。     本任务中校园客服以自然语言处理为主，自然语言处理在校园客服中的作用是对输入的问题进行分析，在问题库中寻找出与输入语句最相似的问题集合，然后根据排序算法，在相似问题集合中抽取出一个问题对应的答案。寻找相似问题是需要通过构建相似度模型和排序模型。这里，我们使用 YunGe API 编写一个校园客服机器人。 【任务实施】 步骤1 导入以下依赖库。 import requests import json 步骤2 定义一个函数upload_data，调用Yunge API，上传question数据。 def upload_data(question): url = 'https://testapi.smartyg.com/api/smart_qa' keys = '5f15a18f3f03f7e88020acb1c2f8c93c' post_json = { 'keys':keys, 'question':question, 'command':'upload_data' } result = requests.post(url,json.dumps(post_json)).text data = json.loads(result) if data['flag'] == 'success': print('上传数据成功')     requests中的参数含义如下： 参数 含义 keys 请求的keys question 传输的语句 command 指定 步骤3 定义一个函数xiaoming，调用Yunge API，发送text，获得回复。 def xiaoming(text): res = '' url = \"https://testapi.smartyg.com/api/post_gossip\" keys = \"5f15a18f3f03f7e88020acb1c2f8c93c\" post_json = { 'keys':keys, 'question':text } result = requests.post(url, json.dumps(post_json)).text data = json.loads(result) if data[\"flag\"] == \"success\": res = data[\"answay\"] return res     requests中的参数含义如下： 参数 含义 keys 请求的keys question 传输的语句 步骤4 定义question_dict，创建问答对，然后调用upload_data上传数据 question_dict = { '饭堂一餐多少钱':'一餐开销约10~15元'， '学校饭堂在哪':'饭堂位置：西区西苑餐厅(西区宿合门ロ),东区一湖接（彩短桥附近）', '哪里的宵夜好吃':'宵夜推荐东区1楼，有炒粉炒饭，生滚粥等应有尽有', '学校的门禁时间':'周日~周四门禁时间：23:00，周五~周六门禁时间：00:00', '图书馆开放时间':'图书馆开放时间：8:30~22:00' } upload_data(question_dict) 步骤5 调用xiaoming，进行问答。 while True: question = input('我:') answay = xiaoming(question) print('客服：',answay) 完整参考代码如下： import requests import json def upload_data(question): url = 'https://testapi.smartyg.com/api/smart_qa' keys = '5f15a18f3f03f7e88020acb1c2f8c93c' post_json = { 'keys':keys, 'question':question, 'command':'upload_data' } result = requests.post(url,json.dumps(post_json)).text data = json.loads(result) if data['flag'] == 'success': print('上传数据成功') def xiaoming(text): res = '' url = \"https://testapi.smartyg.com/api/post_gossip\" keys = \"5f15a18f3f03f7e88020acb1c2f8c93c\" post_json = { 'keys':keys, 'question':text } result = requests.post(url, json.dumps(post_json)).text data = json.loads(result) if data[\"flag\"] == \"success\": res = data[\"answay\"] return res question_dict = { '饭堂一餐多少钱':\"一餐开销约10~15元\", '学校饭堂在哪':'饭堂位置：西区西苑餐厅(西区宿合门ロ),东区一湖接（彩短桥附近）', '哪里的宵夜好吃':'宵夜推荐东区1楼，有炒粉炒饭，生滚粥等应有尽有', '学校的门禁时间':'周日~周四门禁时间：23:00，周五~周六门禁时间：00:00', '图书馆开放时间':'图书馆开放时间：8:30~22:00', } upload_data(question_dict) while True: question = input('我:') answay = xiaoming(question) print('客服：',answay) 本任务实战代码如下,位于/xm1/rw5.ipynb 同学们来运行一下吧 【任务拓展】     将聊天机器人应用到机器人或语音套件。 思政聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:25:07 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/xm.html":{"url":"part2/xm2/xm.html","title":"项目二 植物识别","keywords":"","body":"项目二 植物识别 项目情景     随着现代化工业的不断发展，土地资源匮乏和环境污染已成为现代农业面临的重大问题。植物生长柜使用LED灯代替自然光，采用营养液栽培技术，对植物生长发育过程中所需的温度、湿度、光照等进行智能调控，是一种高效无污染的新型农业生产方式。     目前，市场上常见的植物生长柜大多出于人工现场检测阶段，无法实现对植物生长柜中植物实时检测，从而智能调节。因此给植物的监控与生长环境调节带来极大的不便。为了实现对生长柜的智能升级，实时检测植物种类，记录植物生长全周期，及时作出相应的处理。本章将带大家一起完成植物生长柜智能升级的其中一个重要环节——植物识别。 项目导览 项目目标 了解目标检测的流程。 掌握利用YOLO框架实现植物种类检测功能。 项目规划     植物检测是属于目标检测范畴，它是属于机器学习中的监督学习。因此需要告诉机器有答案的数据，我们通过采集植物图片，进行数据标注，从而获得有答案的数据。目标检测有很多成熟的算法、框架，我们不需要自己搭建神经网络，本章将选择目前效果比较好的YOLO实例，进行我们自己的植物种类学习，实现检测功能。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:26:08 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/rw1.html":{"url":"part2/xm2/rw1.html","title":"任务一 植物图片采集","keywords":"","body":"任务一 植物图片采集 【任务描述】     前面章节已经介绍过，要实现目标检测就需要有答案的目标图片进行学习。而我们本项目需要检测四类植物（上海青、生菜、色拉菜、苦棘菜），因此我们需要大量的四类植物的图片，为后续数据标注、机器学习做准备。 【任务实施】 步骤1 获取植物目标视频     目前图片采集的方式有：1.手机（相机）拍摄照片；2.手机（相机）拍摄视频，转换为图片；3.爬虫从网络上获取。本项目到底采取什么样的方式合适呢？     根据工程思维原则，我们选择生物柜部署的网络摄像头拍摄视频，然后把视频转换成图片。 步骤2 把视频变成图片     把视频变成图片方式也有多样，我们可以用截图软件一张张的截图，也可以使用现成的一些视频转图片的软件，或者利用opencv自行写python脚本进行按帧数截图。显然最后一种方法是最方便快捷的。参考代码为： import cv2 cap = cv2.VideoCapture(\"C:\\\\video2img\\\\veg.mp4\") success, frame = cap.read() i = 0 while success : i = i + 1 cv2.imwrite(\"c:\\\\test\\\\frames%d.jpg\" % i, frame) print('save image:',i) success, frame = cap.read()     最后我们需要重命名图片，因为数据集要求我们对图片进行规范命名。图片重命名为VOC数据集的“000001.jpg”形式。可以写python代码完成，参考代码如下： import os path = r\"D:\\VOC2007\\JPEGImages\"#路径根据实际修改 filelist = os.listdir(path) #该文件夹下所有的文件（包括文件夹） count=0 for file in filelist: print(file) for file in filelist: #遍历所有文件 Olddir=os.path.join(path,file) #原来的文件路径 if os.path.isdir(Olddir): #如果是文件夹则跳过 continue filename=os.path.splitext(file)[0] #文件名 filetype='.jpg' #文件扩展名 Newdir=os.path.join(path,str(count).zfill(6)+filetype) #用字符串函数zfill 以0补全所需位数 os.rename(Olddir,Newdir)#重命名 count+=1     此步骤结束后，应该所有图片的格式都为JPG，并且以“000001.jpg”形式命名好放在同一个文件夹里。在这里，我们也提供了一部分的采集图片供大家使用。右方为下载二维码。 本任务实战代码如下,位于/xm2/rw1.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:31:02 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/rw2.html":{"url":"part2/xm2/rw2.html","title":"任务二 图像标注","keywords":"","body":"任务二 图片标注 【任务描述】     通过任务1我们获取了大量的目标植物图片，我们也知道监督学习，是需要我们告诉机器数据的信息，正确的、错误的。因此我们要对任务1采集的图片进行标注，这样就让图片有目标种类、目标位置的信息，供机器学习使用。 【任务实施】 步骤1 准备工作     我们需要把采集到的所有图片，以及标注好的图片做成标准数据集。在本项目我们使用VOC数据集，因此需要我们建立下图的文件结构，把未标注的JPG图片放在JPEGImages文件夹，Annotations文件夹准备放标注好的xml文件。 Tips： VOC数据集实际上是一个名为PASCAL VOC的世界级的计算机视觉挑战赛中的数据集, 很多模型都基于此数据集推出。比如目标检测领域的yolo,ssd等等。此数据集的格式如下：JPEGImages里面存放的是我们已经修改好命名的图片，Annotations里面存放的是我们将要标注好的XML文件，而ImageSets里面存放的是我们后面会切分的训练集，测试集，验证集的图片命名（test.txt是测试集 ，train.txt是训练集 ，val.txt是验证集 ，trainval.txt是训练和验证集）。本项目是制作四类蔬菜的VOC格式数据集。 步骤2 准备工作 打开Anaconda prompt，输入命令pip instal labelimg 进行安装。 安装成功后，直接输入命令labelimg，即可以打开labelimg标注工具。     labelimg窗口的使用方法： 修改默认的XML文件保存位置，可以用“Ctrl+R”，改为自定义位置，这里的路径不能包含中文，否则无法保存。 “Open Dir”打开需要标注的样本图片文件夹，会自动打开第一张图片，开始进行标注。 使用“Create RectBox”开始画框。 完成一张图片后点击“Save”，此时XML文件已经保存到本地了。 点击“Next Image”转到下一张图片。 标注过程中可随时返回进行修改，后保存的文件会覆盖之前的。 完成标注后打开XML文件，发现确实和PASCAL VOC所用格式一样。 注意： 每个图片和标注得到的xml文件，JPEGImages文件夹里面的一个训练图片，对应Annotations里面的一个同名XML文件，一一对应，命名一致。标注自己的图片的时候，类别名称请用小写字母，比如上海青使用shanghai green，不要用Shang Green。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:32:12 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/rw3.html":{"url":"part2/xm2/rw3.html","title":"任务三 搭建keras-yolo3 环境","keywords":"","body":"任务三 搭建keras-yolo3环境 【任务描述】     任务1、2完成后，我们获得标注好的图片，可以进行训练模型。我们并不需要搭自己的人工神经网络，毕竟有很多成熟的、效果好的框架和案例，我们可以直接拿来用。本项目将使用YOLO框架，复用keras-yolo3官方案例，改成我们自己的数据集进行训练即可。在此之前，需要搭建好运行环境。 【任务实施】 步骤1 下载并安装Anaconda anaconda.com.     根据自身电脑安装的操作系统选择适合的安装包进行下载，安装。 Tips： Anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项，比如：numpy、pandas等。conda是一个开源的包、环境管理器，可以用于在同一个机器上安装不同版本的软件包及其依赖，并能够在不同的环境之间切换。因为包含了大量的科学包，Anaconda 的下载文件比较大（约 457 MB），如果只需要某些包，或者需要节省带宽或存储空间，也可以使用Miniconda这个较小的发行版（仅包含conda和 Python）。     因此，对于上面步骤1，根据实际情况也可以改换成安装miniconda miniconda.根据自身电脑安装的操作系统选择适合的安装包进行下载，安装。 步骤2 下载并安装PyCharm jetbrains.com. Tips： PyCharm是由JetBrains打造的一款Python IDE，带有一整套可以帮助用户在使用Python语言开发时提高其效率的工具，比如调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制。此外，该IDE提供了一些高级功能，以用于支持Django框架下的专业Web开发。 步骤3 创建虚拟环境 Tips： 本项目需要用到官方karas-yolov3的项目，它对python版本以及其他库的版本有严格的对应关系，因此不管你的电脑是否已经有Anaconda或者Pycharm，为了在后续步骤不发生冲突，建议创建一个专门的虚拟环境。 工程思维：利用小代价解决不可预测的问题，从而集中精力决绝核心问题。 打开Anaconda Prompt，输入 conda create -n tf_115 python==3.7 指令，即创建一个名字为tf_115的虚拟环境。 接着，会提示是否继续？选y进行继续安装。 成功安装后，会显示下图画面，接着输入指令 conda activate tf_115，进入创建好的虚拟环境。 安装tensorflow-gpu1.15版本，并测试tensorflow是否成功调用GPU 输入命令 pip install tensorflow-gpu==1.15，注意，本项目对应的是1.15版本。 安装完成后，输入三行命令 python import tensorflow as tf tf.test.is_gpu_available()     如果显示False，如下图所示，可能是显卡驱动问题，需要更新驱动。也可能你的电脑是集成显卡，并没有GPU，而是用CPU运行的。你需要换一台带GPU的电脑进行本项目的操作。如果你没有设备，只能使用CPU时，把安装命令改为 pip install tensorflow==1.15     如果显示True，如下图所示，说明tensorflow能够成功调用GPU，并显示了本台机器GPU的算力。 Tips： 研究深度学习和神经网络大都离不开GPU，在GPU的加持下，我们可以更快的获得模型训练的结果。使用GPU和使用CPU的差别在哪里？为什么需要GPU？深度学习和神经网络的每个计算任务都是独立于其他计算的，任何计算都不依赖于任何其他计算的结果，可以采用高度并行的方式进行计算。而GPU相比于CPU拥有更多独立的大吞吐量计算通道，较少的控制单元使其不会受到计算以外的更多任务的干扰，拥有比CPU更纯粹的计算环境，所以深度学习和神经网络模型在GPU的加持下会更高效地完成计算任务。 安装本项目需要的其他库 序号 名称 版本 1 opencv（计算机视觉和机器学习软件库） 不限版本 2 keras（开源人工神经网络库） 2.1.5 3 PIL（图像处理库） 不限版本 4 matplotlib（绘图库） 不限版本 5 NumPy（开源的数值计算扩展库） 不限版本     打开Anaconda Prompt，注意要先进入之前创建的tf_115的虚拟环境(即输入命令conda activate tf_115)，然后分别输入命令： pip install opencv-python pip install keras==2.1.5 pip install pillow pip install matplotlib pip install numpy pip install h5py==2.10     至此，我们已经成功搭建好环境，下一部分将测试官方keras-yolov3实例。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:33:10 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/rw4.html":{"url":"part2/xm2/rw4.html","title":"任务四 测试keras-yolo3 实例","keywords":"","body":"任务四 测试keras-yolov3实例 【任务描述】     YOLO有自己训练好的数据集，YOLO的检测类别和使用的数据集有关系例如：VOC 数据集检测21个类别，COCO 数据集检测80个类别，而且有官方训练比较好的权重，我们可以直接拿来测试，以验证任务3搭建环境是否正确完成。 【任务实施】 步骤1 下载官方keras-yolov3项目文件，并在Pycharm中打开     GitHub下载网址：qqwweee/keras-yolo3.，下载解压之后使用Pycharm打开。（也可以扫描右方二维码进行下载） 我们需要在pycharm里面设置之前在anaconda prompt里创建的tf_115虚拟环境，因此，以下操作非常关键： 如下图所示，点击右下角“Interpreter Settings”进行设置： 在Python Interpreter，点击倒三角按钮，然后再点击Show All... 打开另一个窗口，点击+： 按下图步骤点击操作，保存更改： 这样就能保证改项目是使用我们之前创建的tf_115的虚拟环境。 步骤2 下载官方权重，并测试     下载网址： yolov3.weights.，并将权重放在keras-yolo3-master的文件夹下。（也可以扫描右方二维码进行下载）     接着使用 pycharm 终端输入如下命令，把 darknet下的 yolov3 配置文件转换成 keras 适用的 .h5 文件，输入命令： python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5 步骤3 测试运行yolo.py     进入到 yolo.py 文件中，在文件的最后加上下面这几句代码（需要自定义视频地址或者直接把测试视频放在项目文件夹根目录下），右键运行，看见视频检测，即说明运行成功。 yolo=YOLO() detect_video(yolo,'test.mp4') 本任务实战代码如下,位于/xm2/rw3-rw5/keras-yolo3-master/yolo.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:34:08 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/rw5.html":{"url":"part2/xm2/rw5.html","title":"任务五 训练植物识别数据集","keywords":"","body":"任务五 训练植物识别数据集 【任务描述】     因为我们复用了官方keras-yolov3项目，任务4已经保证我们的环境搭建成功，那么我们只需要换成我们之前准备好的植物数据集，就可以训练模型了。当然，我们还是需要根据实际情况来调整一些参数。 【任务实施】 步骤1 划分数据集     深度学习中,常将可得的数据集划分为训练集(training set),验证集(development set/validation set)和测试集(test set)。     我们可以简单的这么理解，训练集就好像平时老师给你们上课举的每一个例子，带同学们做的每一个练习，让同学们巩固掌握知识。验证集就好像这个学期的小测，通过小测，老师及时调整教学内容和教学方法。测试集就是期末考试，期末考试的内容通常是同学们没见过的题目，但是确在知识范围里面，用来检查同学们这个学期的学习效果。     把数据集文件夹放在项目文件夹的根目录下：     我们需要回到pycharm中，在VOC2007文件夹中新建 train_text.py，写入如下代码。目的是对我们的xml文件进行切分。（即以一定的比例把数据集切分为训练集，测试集等）train_text.py代码如下： import os import random #训练和测试的比值为8：2 当数据规模小的时候，可以调整为9：1 trainval_percent = 0.2 train_percent = 0.8 xmlfilepath = 'Annotations' txtsavepath = 'ImageSets\\Main' total_xml = os.listdir(xmlfilepath) num = len(total_xml) list = range(num) tv = int(num * trainval_percent) tr = int(tv * train_percent) trainval = random.sample(list, tv) train = random.sample(trainval, tr) #分别写入如下文件 ftrainval = open('ImageSets/Main/trainval.txt', 'w') ftest = open('ImageSets/Main/test.txt', 'w') ftrain = open('ImageSets/Main/train.txt', 'w') fval = open('ImageSets/Main/val.txt', 'w') for i in list: name = total_xml[i][:-4] + '\\n' if i in trainval: ftrainval.write(name) if i in train: ftest.write(name) else: fval.write(name) else: ftrain.write(name) ftrainval.close() ftrain.close() fval.close() ftest.close()     但是，这几个文件并不能直接被yolov3读取，需要我们再做一次转换。修改voc_annotation.py 文件，将 classes 修改成自己的类别。 sets=[('2007', 'train'), ('2007', 'val'), ('2007', 'test')] classes = [\"lettuce\",\"shanghai green\",\"salad green\",\"sonchus\"]     然后运行，会得到下面3个.txt文件。他们对应的是训练集，测试机，验证集的图片。     每个文件都记录着 3 个信息：图片地址，标注的坐标，以及标注名称的索引 （与上面修改的 voc_annotation.py 文件中的 classes 相对应）。     接着，我们修改model_data文件夹下的voc_classes.txt,将类别修改为我们自己的。这样，我们的数据集就制作好啦。在程序运行的时候，会分布读取txt文件中的路径信息和标注信息。 lettuce shanghai green salad green sonchus 步骤2 使用Kmeans算法获得先验框     事实上，到这一步，我们就可以进行训练了。但是这时候我们使用的anchor_box是原作者在coco数据集上使用Kmeans得到的。并不一定适合现在的数据集。所以我们需要在我们的数据集上也使用Kmeans的到9个适合当前数据集的anchor_box。以得到最好的检测框。新建kmeans.py写入如下代码: import numpy as np class YOLO_Kmeans: def __init__(self, cluster_number, filename): self.cluster_number = cluster_number self.filename = filename # 获得iou def iou(self, boxes, clusters): # 1 box -> k clusters ''' boxes:[[weight,height],] clusters:k个中心点 ''' n = boxes.shape[0] k = self.cluster_number # 获得每个标注框的面积 box_area = boxes[:, 0] * boxes[:, 1] box_area = box_area.repeat(k) box_area = np.reshape(box_area, (n, k)) # 获得9个标注框的面积，并将2个数组填充为维度一样的数组 cluster_area = clusters[:, 0] * clusters[:, 1] cluster_area = np.tile(cluster_area, [1, n]) cluster_area = np.reshape(cluster_area, (n, k)) # 对2个数组进行匹配，取出小的那个边长 box_w_matrix = np.reshape(boxes[:, 0].repeat(k), (n, k)) cluster_w_matrix = np.reshape(np.tile(clusters[:, 0], (1, n)), (n, k)) min_w_matrix = np.minimum(cluster_w_matrix, box_w_matrix) box_h_matrix = np.reshape(boxes[:, 1].repeat(k), (n, k)) cluster_h_matrix = np.reshape(np.tile(clusters[:, 1], (1, n)), (n, k)) min_h_matrix = np.minimum(cluster_h_matrix, box_h_matrix) # 计算小边长的面积 inter_area = np.multiply(min_w_matrix, min_h_matrix) # 计算iou result = inter_area / (box_area + cluster_area - inter_area) print(result.shape) return result # 计算准确率 def avg_iou(self, boxes, clusters): accuracy = np.mean([np.max(self.iou(boxes, clusters), axis=1)]) return accuracy def kmeans(self, boxes, k, dist=np.median): ''' boxes:标注框的宽高 k：需要取到的中心个数 ''' # shape : (标注框个数，2) box_number = boxes.shape[0] last_nearest = np.zeros((box_number,)) np.random.seed() # 随机在标注框中取出k个点作为中心 clusters = boxes[np.random.choice( box_number, k, replace=False)] # init k clusters while True: # 由于iou是越大越好，而聚类到中心的距离又是越小越好，所以 # 在论文中，作者使用使用1-iou 可以保证距离越小，iou越大 distances = 1 - self.iou(boxes, clusters) current_nearest = np.argmin(distances, axis=1) if (last_nearest == current_nearest).all(): break # clusters won't change for cluster in range(k): clusters[cluster] = dist( # update clusters boxes[current_nearest == cluster], axis=0) last_nearest = current_nearest return clusters # 将anchors写入txt文件 def result2txt(self, data): f = open(\"model_data/anchors.txt\", 'w') row = np.shape(data)[0] for i in range(row): if i == 0: x_y = \"%d,%d\" % (data[i][0], data[i][1]) else: x_y = \", %d,%d\" % (data[i][0], data[i][1]) f.write(x_y) f.close() # 加载图片路径得到标注框的宽高 def txt2boxes(self): f = open(self.filename, 'r') dataSet = [] for line in f: infos = line.split(\" \") length = len(infos) for i in range(1, length): # 标注框的四个坐标为 xmin,ymin,xmax,ymax # width=xmax-xmin height=ymax-ymin width = int(infos[i].split(\",\")[2]) - \\ int(infos[i].split(\",\")[0]) height = int(infos[i].split(\",\")[3]) - \\ int(infos[i].split(\",\")[1]) dataSet.append([width, height]) result = np.array(dataSet) f.close() return result def txt2clusters(self): all_boxes = self.txt2boxes() result = self.kmeans(all_boxes, k=self.cluster_number) result = result[np.lexsort(result.T[0, None])] self.result2txt(result) print(\"K anchors:\\n {}\".format(result)) print(\"Accuracy: {:.2f}%\".format( self.avg_iou(all_boxes, result) * 100)) if __name__ == \"__main__\": cluster_number = 9 filename = \"2007_train.txt\" kmeans = YOLO_Kmeans(cluster_number, filename) kmeans.txt2clusters()     运行结果如下，我们得到了9个anchor_box,只需要修改一下train.py中的anchors_path的路径，即可开始训练了。 步骤3 模型搭建训练     在开始训练之前，需要我们把数据集制作成一个生成器的结构，以便我们一边训练，一边读取数据。这样可以大大减小内存的压力。我们将train.py中的代码删除，并添加如下的代码，用于制作生成器。 import numpy as np import keras.backend as K from keras.layers import Input,Lambda from keras.models import Model from keras.callbacks import TensorBoard,ModelCheckpoint,ReduceLROnPlateau from yolo3.model import preprocess_true_boxes,yolo_body,yolo_loss from yolo3.utils import get_random_data import keras # 数据生成器 def data_generator(annotation_lines, batch_size,input_shape, anchors,num_classes): ''' annotation_lines:图片地址 区域，类别 batch_size:批次大小 input_shape:模型输入大小 anchors:anchors_box num_classes:类别数量 ''' while True: image_data=[] box_data=[] for i in annotation_lines: # 获得随机截取，图片增强，并且缩放到416*416的图片以及相应的标注框 image,box=get_random_data(i,input_shape,random=True) image_data.append(image) box_data.append(box) # 数据达到一个批次时返回 if len(image_data)==batch_size: image_data=np.array(image_data) box_data=np.array(box_data) y_true=preprocess_true_boxes( box_data,input_shape, anchors,num_classes) # 组装数据 yield [image_data,*y_true],np.zeros(batch_size) image_data=[] box_data=[]     接着，我们还需要编写其他的函数，用来读取txt文件中的数据，以及构建训练模型。 #获取标签名称 def get_classes(path): with open(path) as f: class_names=f.readlines() class_names=[c.strip() for c in class_names] return class_names # 获取anchors_box def get_anchors(path): with open(path) as f: anchors=f.readline() anchors=[float(x) for x in anchors.split(',')] return np.array(anchors).reshape(-1,2) # 创建模型结构 def create_model(input_shape,anchors,num_classes, load_weight=False,weight_path='logs/000/wetghts.h5'): K.clear_session() image_input=Input(shape=(None,None,3)) h,w=input_shape #(416,416) num_anchors=len(anchors)#9 # 分别对应yolov3 的3个输出 13*13 26*26 52*52 y_true=[Input(shape=(h//{0:32,1:16,2:8}[l], w//{0:32,1:16,2:8}[l], num_anchors//3,num_classes+5)) for l in range(3)] model_body=yolo_body(image_input,num_anchors//3,num_classes) print('yolo3 model with %s anchors and %s classes'%(num_anchors,num_classes)) # 是否加载权重 if load_weight: model_body.load_weights(weight_path,by_name=True, skip_mismatch=True) model_loss=Lambda(yolo_loss,output_shape=(1,),name='yolo_loss', arguments={'anchors':anchors, 'num_classes':num_classes, 'ignore_thresh':0.7})\\ ([*model_body.output,*y_true]) model=Model([model_body.input,*y_true],model_loss) return model     然后，进行训练函数的编写，在训练的时候，我们还可以使用回调函数对训练过程进行控制。比如，使用ModelCheckpoint()函数可以自动保存最佳的模型；使用ReduceLR0nPlateau()函数可以控制学习自动率衰减。 # 训练函数 def train(model, annotation_path, test_path, input_shape, anchors, num_classes, log_dir='logs/'): ''' model:模型 annotation_path,test_path:训练路径和测试路径 input_shape:模型输入 anchors:anchors_box num_classes:类别个数 ''' # 编译模型 model.compile(optimizer=keras.optimizers.Adam(lr=3e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # 定义自动保存最佳模型 checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', monitor='val_loss', save_weights_only=True, save_best_only=True, period=1) # 学习率衰减 reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-7, verbose=1) # 批次大小，训练集和验证集的划分比例 batch_size = 6 val_split = 0.1 with open(annotation_path) as f: train_lines = f.readlines() with open(test_path) as f: test_lines = f.readlines() # 打乱数据 lines = train_lines + test_lines np.random.shuffle(lines) num_val = int(len(lines) * val_split) num_train = len(lines) - num_val print('train on %s , test on %s , batch_size: %s' % (num_train, num_val, batch_size)) # 训练 model.fit_generator(data_generator(lines[:num_train], batch_size, input_shape, anchors, num_classes), steps_per_epoch=num_train // batch_size, validation_data=data_generator(lines[num_train:], batch_size, input_shape, anchors, num_classes), validation_steps=num_val // batch_size, callbacks=[reduce_lr, checkpoint], epochs=500) model.save_weights(log_dir + 'wetghts.h5')     紧接着，我们只需要定义一个main函数，并调用到它。 def _main(): # 定义路径 annotation_path = '2007_train.txt' test_path = '2007_test.txt' log_dir = 'logs/000/' classes_path = 'model_data/voc_classes.txt' anchors_path = 'model_data/yolo_anchors.txt' # 获取类别 class_names = get_classes(classes_path) # 获取anchor_box anchors = get_anchors(anchors_path) input_shape = (416, 416) # 搭建模型 model = create_model(input_shape, anchors, len(class_names)) # keras.utils.plot_model(model,'yolo.png',show_shapes=True) # 训练 train(model, annotation_path, test_path, input_shape, anchors, len(class_names), log_dir=log_dir) if __name__ == '__main__': _main()     最后，在keras-yolo3-master文件夹下建立文件夹目录：logs/000，用于保存训练生成的模型。     现在可以运行train.py文件，train.py文件设置训练500周期，训练结束后我们将获得训练模型。 步骤4 测试模型     当我们有一个已经训练好的模型之后，我们就可以使用它来预测数据了，首先我们进入到yolo.py文件中，修改 _defaults 配置中的model_path,anchors_path,以及 classes_path 为我们自己的路径。     在yolo.py代码的最后面加上下面代码，进行蔬菜检测： yolo=YOLO() img=Image.open('00407.jpg') img_obj=yolo.detect_image(img) img_obj.show()     使用视频进行检测其实也很简单，只需要写入如下2行代码即可，因为实际上视频是由一帧一帧的图片组成，所以检测视频本质上也是对图片的检测。 yolo=YOLO() detect_video(yolo,'test.mp4') Tips： yolo中 loss值分为4个，分别是中心点位置、宽高、置信度、类别。在刚开始训练的时候，这些数据都是随机的。所以loss会很大，但是同时找到更接近实际值的参数也就更容易，所以loss就收敛得快，但到后面会收敛得很慢。一个正常训练得模型 ，loss曲线在后面收敛会比较慢，并且会伴随着波动。     至此，我们的实验都做完了。 本任务实战代码如下,位于/xm2/rw3-rw5/keras-yolo3-master/ 中 同学们需要完成如下几个步骤 运行 /xm2/rw3-rw5/keras-yolo3-master/VOCdevkit/VOC2007/train_text.inpy 划分数据集 运行 /xm2/rw3-rw5/keras-yolo3-master/voc_annotation.inpy 转换数据 运行 /xm2/rw3-rw5/keras-yolo3-master/train.inpy 开始训练 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:35:50 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm2/rw6.html":{"url":"part2/xm2/rw6.html","title":"任务六 小结","keywords":"","body":"任务六 小结 下面是围绕同学们可能存在的问题进行Q&A。 Q：Keras框架下训练yolo和Darknet框架下训练yolo的不同点？ A：Keras 是python 语言 Darknet 是c，只不过yolo 是darknet 同一个作者，所以darknet版本的yolo是正版，而keras 版本只是复现。类似的还有tensorflow版本、pytorch版本。 Q：在采集的数据集不够大的情况下，可以修改那些参数来优化训练模型呢？数据增强有那些方法？ A：一般来说，数据集不够最好的解决方法是数据增强。通常有旋转、裁剪、hsv颜色增强、镜像、马赛克等。可以写python代码完成，通常在数据加载步骤中完成。 Q：yolo_anchors.txt，这个文件里面是什么信息？ A：yolo_anchors.txt 保存着9个矩形。这9个矩形是在coco数据集上使用k-means算法得来的。这是通用的，但是这不一定是最适合我们这就训练的数据集的，所以有些时候我们需要重新生成。（根目录中的k-means.py就是，我们可以根据需要运行） Q：loss和val_loss有什么不同？ A：loss 一般来说指训练时的loss，而val_loss指我们使用未进行训练的数据进行预测的loss。val_loss一般反应着模型的泛化能力。 Q：一般来说，有没有建议的数据采集数量？比方说每一个种类需要多少张图片？还有就是这个训练周期，我们这次是500个周期？有没有建议的周期数，这个周期数和什么参数有什么相关关系？ A：数据当然时越多越好。可以尝试第一次训练的话会使用500张左右的图片，然后再慢慢增加。周期数，300~500是比较合适，不过归根到底还是看loss 收敛的结果，如果loss在第100次收敛的不错，那就可以停了。如果loss在第500次还没收敛，那么就需要继续训练下去。 Q：模型的好坏除了看loss值还看什么？ A：目前来说，计算模型mAP是最主流的判断模型好坏的方法，不过需要另写代码。所以在训练的时候看loss以及val_loss是最快的判断方式。 Q：有哪些因素影响着训练模型的好坏？ A：如果只看yolo算法的话，数据集的好坏是影响最大的。然后是数据增强的方式、训练的尺寸、anchors_box等。例如yolov3升级到yolov4中，核心的loss计算并没有发生改变，它改变了网络结构（SPP、CSP）、数据增强的方式（马赛克数据增强）、激活函数（mish）、交并比（biou）、训练尺寸（608*608）等。使模型在提示精度的同时，还提高了运行速度。 【任务拓展】 同学们能否按着本章目标检测的思路，完成另外一些种类的检测呢？ 【思政聚焦】 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:37:28 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm3/xm.html":{"url":"part2/xm3/xm.html","title":"项目三 人脸识别","keywords":"","body":"项目三 人脸识别 项目情景     人脸识别系统的研究始于20世纪60年代，80年代后随着计算机技术和光学成像技术的发展得到提高，而真正进入初级的应用阶段则在90年后期，并且以美国、德国和日本的技术实现为主；人脸识别系统成功的关键在于是否拥有尖端的核心算法，并使识别结果具有实用化的识别率和识别速度；“人脸识别系统”集成了人工智能、机器识别、机器学习、模型理论、专家系统、视频图像处理等多种专业技术，同时需结合中间值处理的理论与实现，是生物特征识别的最新应用。 项目导览 项目目标 了解人脸检测的基本流程 掌握利用已训练的模型face_net进行人脸识别 项目规划     人脸识别，是基于人的脸部特征信息进行身份识别的一种生物识别技术。用摄像机或摄像头采集含有人脸的图像或视频流，并自动在图像中检测和跟踪人脸，进而对检测到的人脸进行脸部识别的一系列相关技术，通常也叫做人像识别、面部识别。本项目中为了减低难度，会使用现成的算法以及模型进行人脸识别，具体流程如下： 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:44:53 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm3/rw1.html":{"url":"part2/xm3/rw1.html","title":"任务一 人脸检测","keywords":"","body":"任务一 人脸检测 【任务描述】     人脸图像采集：不同的人脸图像都能通过摄像镜头采集下来，比如静态图像、动态图像、不同的位置、不同表情等方面都可以得到很好的采集。当用户在采集设备的拍摄范围内时，采集设备会自动搜索并拍摄用户的人脸图像。     人脸检测：人脸检测在实际中主要用于人脸识别的预处理，即在图像中准确标定出人脸的位置和大小。人脸图像中包含的模式特征十分丰富，如直方图特征、颜色特征、模板特征、结构特征及Haar特征等。人脸检测就是把这其中有用的信息挑出来，并利用这些特征实现人脸检测。     主流的人脸检测方法基于以上特征采用Adaboost学习算法，Adaboost算法是一种用来分类的方法，它把一些比较弱的分类方法合在一起，组合出新的很强的分类方法。人脸检测过程中使用Adaboost算法挑选出一些最能代表人脸的矩形特征(弱分类器)，按照加权投票的方式将弱分类器构造为一个强分类器，再将训练得到的若干强分类器串联组成一个级联结构的层叠分类器，有效地提高分类器的检测速度。 【任务实施】 步骤1 1.1获取实时的视频流     在本任务实施前，你应该有一个摄像头，并且已经配置好OpenCV的环境（可以使用 pip3 install opencv-python 下载）。 import cv2 # 打开一个摄像头 cam=cv2.VideoCapture(0) # 循环读取摄像头的数据 while True: _,image=cam.read() cv2.imshow('dad',image) key=cv2.waitKey(0) if key==ord('q'): #当点击键盘中的q键时推出 break # 记得释放摄像头和关闭所有窗口 cam.release() cv2.destroyAllWindows()     在上面的代码中，我们首先使用 cv2.VideoCapture（0）打开了一个摄像头， 这里的0是指摄像头的索引，根据你自己本身的情况而定，当然0 也可以换成一个视频地址，那就变成了读取一段视频并显示，接着我们使用一个循环，读取摄像头中的数据，cam.read()返回两个数据，其中_ 是布尔值，如果读取帧是正确的则返回True，如果文件读取到结尾，它的返回值就为False。image就是每一帧的图像，是个三维矩阵。然后我们使用cv2.imshow()把图片显示出来，接着使用key接收 键盘值 如果这个键盘值等于 q的键盘值 则退出循环。     最后，我们不要忘记使用cam.release()释放摄像头，以及使用cv2.destroyAllWindows() 关闭所有窗口。运行结果如下： 步骤2 在视频流中使用haar分类器进行人脸检测     在本任务开始之前，我们需要到Opencv已经训练好的人脸检测模型 haarcascade_frontalface_default.xml，我们可以通过2中方式得到，第一是到Github上 opencv.下载对应的源码，然后找到opencv/data/haarcascades/目录，就可以得到该xml文件了。第二种方式是，找到你pip 的地址，一般在python安装地址的lib/site-pckages里面，我们可以通过打开cmd 输入where python查看python安装地址，有了这个模型以后，我们就可以开始编写人脸检测的代码了。 import cv2 # 加载人脸检测模型 face_date=cv2.CascadeClassifier('haarcascade_frontalface_default.xml') image=cv2.imread(r'opencv_image/lena.jpg') # 进行人脸检测 faces=face_date.detectMultiScale(image,1.3,5) # 将检测到的人脸标注出来 for x,y,w,h in faces: cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),1) cv2.imshow('img',image) cv2.waitKey(0) 程序运行结果如下：     怎么样，是不是很简单，当然，这是最简单的识别人脸，前面已经介绍了如何打开摄像头获取图像，如果你已经掌握了的话，先不要看下面的代码，先自己尝试去写一个摄像头的人脸识别程序，写完之后再来看这个代码。如果可以顺利运行的话，我想你已经掌握了前面的知识点了。 # video cam=cv2.VideoCapture(0) while True: _,img=cam.read() gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) faces=face_date.detectMultiScale(img,1.3,5) for face in faces: x,y,w,h=face cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1) cv2.imshow('opencv face',img) flag=cv2.waitKey(1) if flag==ord('q'): break cam.release() cv2.destroyAllWindows() 运行结果如下： 步骤3 保存人脸ROI区域     ROI（region of interest），感兴趣区域。在机器视觉、图像处理中，从被处理的图像以方框、圆、椭圆、不规则多边形等方式勾勒出需要处理的区域，称为感兴趣区域，ROI。在Halcon、OpenCV、Matlab等机器视觉软件上常用到各种算子（Operator）和函数来求得感兴趣区域ROI，并进行图像的下一步处理。     在图像处理领域，感兴趣区域(ROI) 是从图像中选择的一个图像区域，这个区域是你的图像分析所关注的重点。圈定该区域以便进行进一步处理。使用ROI圈定你想读的目标，可以减少处理时间，增加精度。     感兴趣区(Region of Interest,ROIs) 是图像的一部分，它通过在图像上选择或使用诸如设定阈值(thresholding) 或者从其他文件(如矢量> 转换获得等方法生成。感趣区可以是点、线、面不规则的形状，通常用来作为图像分类的样本、掩膜、裁剪区或及其他操作。     在计算机视觉中，图像ROI提取也是一个重要的内容，它可以将你感兴趣的内容提取出来做进一步的操作。例如：在人脸识别中，你需要先检测出人脸，并提取人脸ROI区域进行下一步的人脸识别；在车牌识别中，你需要提取检测到的车牌ROI区域，并进行下一步的识别等等。     事实上，这种操作在OpenCV中并不难，你只需要得到你想要提取的ROI区域的坐标和宽高即可，我们可以使用如下的代码实现： import cv2 face_date=cv2.CascadeClassifier('haarcascade_frontalface_default.xml') cam=cv2.VideoCapture(0) while True: _,img=cam.read() gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) faces=face_date.detectMultiScale(gray,1.3,5) for face in faces: x,y,w,h =face #获得人脸roi区域，并保存 face_img=img[y:h+y, x:w+x] cv2.imwrite('faceroi.jpg',face_img) cv2.imshow('i',img) cv2.waitKey(1) cam.release() cv2.desotryAllWindow() 本任务实战代码如下,位于/xm3/rw1.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2022-02-09 08:16:23 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm3/rw2.html":{"url":"part2/xm3/rw2.html","title":"任务二 人脸矫正","keywords":"","body":"任务二 人脸矫正 【任务描述】     通过任务一，我们已经完成了人脸的检测，下一步我们将进行人脸矫正，事实上人脸矫正是是一个中间步骤，首先是人脸检测，然后是人脸对齐，人脸对齐的结果可以用于：人脸识别，属性计算，表情识别等。 【任务实施】 步骤1 使用dlib进行人脸关键点定位     除了OpenCV，还有一种比较简单的人脸检测的方法，就是使用Dlib进行人脸检测（dlib 可使用pip3 install dlib 安装）。同样地，使用Dlib进行人脸检测也是需要一个已训练好的人脸检测模型：shape_predictor_68_f ace_landmarks.dat。这里我放上下载链接链接可供大家下载: https://pan.baidu.com/s/ 1JZm2p8ccKUbdAVGlSuebNg 提取码: wgun。接着，我们开始写代码： import cv2 import dlib detector=dlib.get_frontal_face_detector() predictor=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat') img=cv2.imread('opencv_image/lena.jpg') print(img) gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) dets=detector(gray,1) #获得人脸个数 for k,d in enumerate(dets): shape=predictor(img,d) for i in range(68): cv2.circle(img,(shape.part(i).x,shape.part(i).y), 1,(0,255,0),-1,8) cv2.putText(img,str(i),(shape.part(i).x,shape.part(i).y), cv2.FONT_HERSHEY_SIMPLEX,.5,(255,0,0),1) cv2.imshow('face',img) cv2.waitKey(0)     在dlib中，定义人脸有68特征,如图所示,我们可以通过循环，一个一个画出来。人脸的关键点如下：     程序运行结果如下： 步骤2 人脸矫正     人脸矫正的前提是已经获得了人脸的关键点，我们将会使用人脸的关键点进行人脸矫正，具体步骤如下： 人脸关键点检测 人脸旋转角度计算 坐标变换 人脸仿射变换     第一个步骤在上个小任务已经完成，我们简化一下代码，使用图片进行人脸矫正，可以得到如下的代码： import dlib import cv2 import numpy as np import math detector=dlib.get_frontal_face_detector() predictor=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat') #得到人脸 def get_face(image_path,save=False): image=cv2.imread(image_path) gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) dets = detector(gray, 1) # 获得人脸个数 # print(dets) face=None if len(dets)==0: print('未检测到人脸') else: face=correct_face(image, dets) if save: path=image_path.split('.')[0] cv2.imwrite(path+'.jpg',face) return face if __name__ == '__main__': image_path = r'D:\\GPU_SY\\Opencv\\opencv_image\\face1.jpg' face = get_face(image_path) cv2.imshow('img', face) cv2.waitKey(0)     细心的同学会发现，在get_face() 函数中有个correct_face()函数未实现，这就是我们的第二步，人脸旋转角度计算： # 人脸矫正 def correct_face(image,rects,size=128): shape=predictor(image,rects[0]) x,y,w,h=get_face_rect(rects[0]) # 获得左右眼的坐标 x1,y1= shape.part(36).x, shape.part(36).y x2,y2 = shape.part(45).x, shape.part(45).y # 获取人脸区域 face=image[y:h,x:w] width, height = face.shape[1], face.shape[0] # 获取左右眼的夹角 h1=y2-y1 w1=x2-x1 a1=np.arctan(h1/w1) a = math.degrees(a1) # 弧度转角度 print('旋转角度：%s°' % a) # 这里使用弧度制 points=get_trainpose_point(x,y,w,h,a1) points=np.array(points,np.float32) # 将 旋转后的坐标 仿射变换到新的坐标 new_point=np.array([[0,0],[size,0],[size,size]],np.float32) A1=cv2.getAffineTransform(points,dst=new_point) d1=cv2.warpAffine(image,A1,(size,size),borderValue=125) return d1     correct_face()函数中，也有2个函数为实现，分别是get_face_rect()用来获取人脸ROI区域，以及get_trainpose_point()用来进行坐标变换。get_face_rect()代码为如下： # 获得人脸区域 def get_face_rect(rects): x = rects.left() y = rects.top() w = rects.right() h = rects.bottom() return x,y,w,h     get_trainpose_point()用来对左边进行变换，这里我们是使用两只人眼(分别是36和45号关键点)与水平的夹角来计算人脸的旋转角度。并且根据旋转公式（假设对图片上任意点(x,y)，绕一个坐标点(rx0,ry0)逆时针旋转a角度后的新的坐标设为(x0, y0)）： x0= (x - rx0)*cos(a) - (y - ry0)*sin(a) + rx0 y0= (x - rx0)*sin(a) + (y - ry0)*cos(a) + ry0     可以获得变换后的人脸坐标，具体代码如下： # 获得人脸旋转后的坐标 def get_trainpose_point(x,y,w,h,angle): # 求三角函数值 这里默认使用弧度制，所以输入的是弧度 sina=math.sin(angle) cosa=math.cos(angle) # 获得矩形的宽高 height=h-y weidth=w-x # 获得中心点坐标 centerx=int(x+weidth/2) centery=int(y+height/2) # 分别获得当前 左上角 右上角 右下角的坐标 left_point=np.array([x,y]) top_right_point=np.array([w,y]) bottom_right_point=np.array([w,h]) # 组合 points=np.concatenate((left_point,top_right_point,bottom_right_point)) # 分别获得旋转后的左上角右上角 右下角的坐标 points[0]=(points[0] - centerx) * cosa - (points[1] - centery) * sina + centerx points[1]=(points[0] - centerx) * sina + (points[1] - centery) * cosa + centery points[2] = (points[2] - centerx) * cosa - (points[3] - centery) * sina + centerx points[3] = (points[2] - centerx) * sina + (points[3] - centery) * cosa + centery points[-2]=(points[-2] - centerx) * cosa - (points[-1] - centery) * sina + centerx points[-1]=(points[-2] - centerx) * sina + (points[-1] - centery) * cosa + centery return points.reshape(-1,2)     程序运行结果为： 本任务实战代码如下,位于/xm3/rw2.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2022-02-09 08:18:33 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm3/rw3.html":{"url":"part2/xm3/rw3.html","title":"任务三 人脸特征提取","keywords":"","body":"任务三 人脸特征提取 【任务描述】     目前比较主流的人脸特征提取方法是把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别，可以理解为如下步骤： 【任务实施】 步骤1 人脸特征提取     在本任务开始之前，你需要有一个已训练好了的face_net模型，可以到如下地址中获得。     人脸特征提取的第一步就是要把人脸从图片中获取出来，根据任务一的流程我们很容易就可以获得人脸ROI图片，我们可以将过程封装起来直接调用即可。 import tensorflow.keras as k import os import cv2 import numpy as np import matplotlib.pyplot as plt # 获得人脸ROI区域 def get_face_roi(img): gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) faces = face_date.detectMultiScale(gray, 1.3, 5) for face in faces: x, y, w, h = face img = img[y:y+h,x:x+w] return img     接下来，定义一个函数，用来获取人脸特征： # 获得人脸特征 def get_face_features(img): # 将图片缩放为模型的输入大小 image = cv2.resize(img,(160,160)) image = np.asarray(image).astype(np.float64)/255. image = np.expand_dims(image,0) # 使用模型获得人脸特征向量 features = model.predict(image) # 标准化数据 features = features / np.sqrt(np.maximum(np.sum(np.square(features), axis=-1, keepdims=True), 1e-10)) return features     最后，在main函数中调用这2个函数，即可获得人脸特征： if __name__ == '__main__': # 加载模型 face_date = cv2.CascadeClassifier('model\\haarcascade_frontalface_default.xml') model = k.models.load_model(r'model\\facenet_keras.h5') model.summary() # 加载图片 image_path = r'images\\face1.jpg' img= cv2.imread(image_path) img_roi = get_face_roi(img) features = get_face_features(img_roi) print(features) # 显示特征 plt.imshow(features) plt.show() cv2.imshow('s',img_roi) cv2.waitKey(0) 程序运行结果如下： 步骤4 人脸特征库搭建     人脸特征库搭建有一个最简单的方法，就是直接保存人脸图片即可，但是这种方式有两个缺点：1.在进行网路传输时开销较大；2.在终端进行加载时速度较慢（因为需要重新找到人脸，获取特征），所以为了更好的性能，一般会直接提取人脸的特征进行保存。具体操作也十分简单，在get_face_features()添加如下代码即可： # 获得人脸特征 def get_face_features(img): # 将图片缩放为模型的输入大小 image = cv2.resize(img,(160,160)) image = np.asarray(image).astype(np.float64)/255. image = np.expand_dims(image,0) # 使用模型获得人脸特征向量 features = model.predict(image) # 标准化数据 features = features / np.sqrt(np.maximum(np.sum(np.square(features), axis=-1, keepdims=True), 1e-10)) # 添加代码------------------- np.save(r'knowface\\face1',features) # ---------------------------------- return features     运行后即可在项目目录中看到face1.npy文件，这就是我们已经保存好的人脸特征了。多次修改图片地址，就可以搭建好一个人脸特征库了。     读取*.npy文件的代码如下： import numpy as np data = np.load(r'knowface\\face1.npy') print(data) 本任务实战代码如下,位于/xm3/rw3.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2022-02-09 08:23:48 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm3/rw4.html":{"url":"part2/xm3/rw4.html","title":"任务四 人脸识别","keywords":"","body":"任务四 人脸识别 【任务描述】     经过前面的几个任务，你已经学会如何进行人脸检测、人脸矫正以及人脸特征提取了，那么提取的特征是怎么使用的呢？     当我们直接通过CNN学习一副输入人脸图像的欧式空间特征时，两幅图像特征向量间的欧式距离越小，表示两幅图像是同一个人的可能性越大。一旦有了这个人脸图像特征提取模型，那么人脸验证就变成了两幅图像相似度和指定阈值比较的问题。     如下图，无论是改变光照还是角度，相同人之间的特征距离都要小于不同人之间的特征距离，然后我们只要通过判断特征距离是否小于某个阈值就可以判断是否是同一个人，从而进行人脸识别。 【任务实施】 步骤1 人脸欧式距离计算     欧氏距离是最易于理解的一种距离计算方法，源自欧氏空间中两点间的距离公式，若存在两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)，那么他们之间的距离可表示为：     在python中的实现如下： import numpy as np def get_distance(image1,image2): l1 = np.sqrt(np.sum(np.square(image1 - image2), axis=-1)) return l1 步骤2 人脸识别     知道如何获取人脸特征，如何计算人脸距离之后，我们就可以给定阈值，并且通过阈值判断是否是同一个人了。首先，我们先加载人脸特征库中的数据，代码如下： from facefeatures import get_face_roi,get_face_features import numpy as np import cv2 import os # 加载人脸特征 def load_know_face(path): npy_paths = [os.path.join(path ,p) for p in os.listdir(path)] data =[] face_names = [] for npy_path in npy_paths: name = npy_path.split('\\\\')[-1].split('.')[0] face_names.append(name) data.append(np.load(npy_path)[0]) return data,face_names     接着，在main中写入如下代码，即可制作一个简易的人脸识别程序，由于我们这里调用了上一个任务中的函数，所以记得把get_face_features()中保存特征的代码去掉。 if __name__ == '__main__': face_know_features,face_names = load_know_face('knowface') # 加载要识别的人的图片 image_path = r'images\\huge2.jpg' img= cv2.imread(image_path) img_roi = get_face_roi(img) #获得特征 features = get_face_features(img_roi) # 计算人脸距离 distance = get_distance(face_know_features,features) # 判断最小的距离是否小于阈值 min_dis_index = distance.argmin() if distance[min_dis_index]     程序运行结果如下，第一张识别huge2.jpg，由于之前已经录入huge1.jpg的人脸特征，所以可以进行识别，而第二张由于没有提前录入人脸，所以并不能识别到： 本任务实战代码如下,位于/xm3/rw4.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:42:55 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part2/xm3/rw5.html":{"url":"part2/xm3/rw5.html","title":"任务五 简易人脸考勤系统","keywords":"","body":"任务五 简易人脸考勤系统 【任务描述】     人脸考勤系统，就是依托人脸识别技术的考勤管理系统，人脸考勤系统采集员工的姓名，ID号，员工面部图片，员工在考勤后记 录会传递到考勤管理系统中，再由系统来运算缺勤，加班等信息。 本书中的简易人脸考勤系统场景为校园中的学生考勤，假设人脸数据可以通过校园管理系统得到，那么，整体的流程为： 获取上课的学生列表 为学生注册某一课程 搭建人脸特征库 上课前进行人脸识别签到 通过学生列表以及人脸识别的结果获得考勤记录 考勤分析 【任务实施】 步骤1 准备工作     首先我们假设从校园管理系统中获得了如下的数据，分别为学生的人脸图像。     然后，根据需求，创建如下目录结构，class 是存储某一节课的课程信息；face_features是人脸特征库，我们将提取到的人脸特征存储到这里；models存放haar分类器以及face_net模型；student_images是我们从校园管理系统中获取到的学生数据。     接着，我们将前面已经编写好了的一些函数放到utils中，方便后续直接调用：utils.py中的代码如下： import tensorflow.keras as k import os import cv2 import numpy as np os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\" face_date = cv2.CascadeClassifier('models\\haarcascade_frontalface_default.xml') model = k.models.load_model(r'models\\facenet_keras.h5') # 获得人脸ROI区域 def get_face_roi(img): gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) faces = face_date.detectMultiScale(gray, 1.3, 5) # for face in faces: # x, y, w, h = face # img = img[y:y+h,x:x+w] return faces # 获得人脸特征 def get_face_features(img): # 将图片缩放为模型的输入大小 image = cv2.resize(img,(160,160)) image = np.asarray(image).astype(np.float64)/255. image = np.expand_dims(image,0) # 使用模型获得人脸特征向量 features = model.predict(image) # 标准化数据 features = features / np.sqrt(np.maximum(np.sum(np.square(features), axis=-1, keepdims=True), 1e-10)) # 添加代码------------------- # np.save(r'knowface\\face1',features) # -------------------------- return features # 加载人脸特征 def load_know_face(path): npy_paths = [os.path.join(path ,p) for p in os.listdir(path)] data =[] face_names = [] for npy_path in npy_paths: name = npy_path.split('\\\\')[-1].split('.')[0] face_names.append(name) data.append(np.load(npy_path)[0]) return data,face_names # 计算人脸距离 def get_distance(image1,image2): l1 = np.sqrt(np.sum(np.square(image1 - image2), axis=-1)) return l1 步骤2 批量获取特征     任务3 中我们获取人脸特征的方式比较简单粗暴，这里我们使用代码直接对一个文件夹中的图片进行人脸特征的提取，register.py中的代码如下： import os from utils import get_face_roi,get_face_features import cv2 import numpy as np from tqdm import tqdm student_dir='student_images' student_paths = [os.path.join(student_dir,p) for p in os.listdir(student_dir)] for student_path in tqdm(student_paths): student_name = student_path.split('\\\\')[-1].split('.')[0] image = cv2.imread(student_path) face_roi= get_face_roi(image) features = get_face_features(face_roi) np.save(r'face_features\\%s'%student_name,features)     程序运行成功后可以在face_features文件夹中得到如下的人脸特征文件： 步骤3 实时人脸签到     接着，编写Attendance_Runtime.py中的代码为如下： from utils import get_face_roi,get_face_features,load_know_face,get_distance import cv2 import time import json # 加载学生数据 student_face_features ,student_names= load_know_face('face_features') print(student_names) # 开打摄像头 cam = cv2.VideoCapture(0) # 初始化学生列表 student_signin_dist={} for student_name in student_names: student_signin_dist[student_name]='0' while cam : _,frame = cam.read() # 获得人脸区域 faces = get_face_roi(frame) # 对图像中的每一个人脸进行对比 for face in faces: x, y, w, h = face cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),1) # 获得人脸roi区域 img_roi = frame[y:y + h, x:x + w] # 获得人脸特征 face_features = get_face_features(img_roi) # 计算人脸距离 distance = get_distance(student_face_features,face_features) print(distance) # 判断最小的距离是否小于阈值 min_dis_index = distance.argmin() if distance[min_dis_index]     程序运行后，你将会看到如下的界面，黄色字体为识别到的学生名称，并且使用按键’q’可以退出签到系统。     在退出时会同时保存签到信息成json文件到class文件夹中，保存的信息如下，如果已经签到，则会保存签到时间，如若还未签到，这为’0’。 步骤4 考勤分析     新建一个query.py文件用来分析保存好的json文件，可以写入如下的代码进行分析： import json import time path = 'class\\student_att.json' # 定义上课时间 格式固定 start_class_time ='2021-04-29 17:41:00' start_class_time_stamp = time.mktime(time.strptime(start_class_time, '%Y-%m-%d %H:%M:%S')) with open(path, 'r', encoding='utf8') as f: class_datas= json.loads(f.read()) class_datas_dict = dict(class_datas) for name in class_datas_dict.keys(): att_time = class_datas_dict[name] if att_time == '0': state = '缺勤' else: # 如果签到时间大于上课时间则是迟到 att_time_stamp = time.mktime(time.strptime(att_time, '%Y-%m-%d %H:%M:%S')) time_ = start_class_time_stamp-att_time_stamp if time_ 本任务实战代码如下,位于/xm3/rw5.ipynb 同学们来运行一下吧 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:43:42 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm1/xm.html":{"url":"part3/xm1/xm.html","title":"第三章 AI安全法律伦理","keywords":"","body":"项目一 探究人工智能安全问题 项目情景 人工智能：颠覆性创新还是文明终结者？     在2020世界机器人大会上，全球最炫酷的机器人产品、最前沿的人工智能技术闪亮登场。人工智能已成为当代全球最火爆的高科技领域。人工智能正在成为以新一轮科技革命为基础的国家竞争制高点。欧盟的“人脑计划”、日本的“人工智能/大数据/物联网/网络安全综合项目”以及美国的《国家人工智能研究与发展战略规划》，都将人工智能全面提升到国家战略层面。与此同时，“黑客”攻击电网导致大范围停电，政府内网被植入“后门”，机密情报被窃取、重要网站被劫持、个人信息集中泄露，家中摄像头被远程操控肆意窥探……这些曾经只出现在科幻小说里的安全问题，如今却在全球不时上演。人工智能的发展速度远远超越了人类自身的进化速度，这也引起了诸多学者的警惕。人类的职业是否会被机器代替？机器会不会反过来操控人类，控制人类居住的星球，并最终将人类淘汰出局？ 项目导览 项目目标 能够感受人工智能安全对国家对社会对个人的影响 了解针对人工智能系统的威胁攻击方式 了解针人工智能系统的安全防范措施 项目规划     特斯拉创始人埃隆·马斯克认为，人工智能将威胁人类，或引发恐慌，呼吁政府尽快考虑针对这一技术的相关立法与管控，著名物理学家霍金也发出对人工智能的警告：“人工智能可能毁灭人类”；而Facebook的创办人扎克伯格等人则认为，人工智能将会让人类的生活变得更安全和美好。通过阅读材料、搜素网络资源、查找书籍，了解人工智能的安全。 探索任务 主要内容 典型案例 人工智能面临的新型攻击威胁 人工智能给人类带来的安全隐患和影响 如何防范人工智能安全问题 活动探究 人工智能安全问题及其产生的原因是什么？ 如何看待人工智能技术的“甲之砒霜，乙之蜜糖”之说？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:46:13 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm1/rw1.html":{"url":"part3/xm1/rw1.html","title":"任务一 认识人工智能安全的新型攻击和风险","keywords":"","body":"任务一 认识人工智能安全的新型攻击和风险 【任务描述】     人工智能技术的蓬勃兴起与迅猛发展，应用正在改变人类社会的发展轨迹的社会生产生活方式。与此同时，人工智能给全社会带来的不容忽视的风险挑战，也随之成为一个国际国内、社会各界都广泛关注的重大现实问题、重大时代议题。人工智能在欺诈、违法不良信息传播、密码破解等攻击手段的应用给传统安全检测带来了新的挑战。2017年我国浙江湖北等地发生多起犯罪分子利用语音合成技术假扮受害人亲属实施诈骗的案件，造成严重后果和恶劣社会影响。2018年，西北大学团队基于人工智能技术建立了一套验证码求解器，仅利用500个目标验证码优化求解器，便可使求解器在0.05秒之内攻破验证码。要利用好人工智能技术，就要全面清晰的了解新的攻击威胁，人工智能安全隐患及对相关方造成的影响。 【任务实施】 1.1了解什么是人工智能安全     人工智能安全是指通过采取必要措施，防范对人工智能系统的攻击侵入干扰破坏和非法使用以及意外事故，使人工智能系统处于稳定可靠运行的状态，以及遵循人工智能以人为本权责一致等安全原则，保障人工智能算法模型，数据系统和产品应用的完整性保密性可用性鲁棒性透明性公平性和隐私的能力。 1.2人工智能系统面临的新型攻击     人工智能系统除了会遭受拒绝服务等传统网络攻击威胁外，也会面临一些特定攻击。常见的新型攻击方法包括：     一是对抗样本攻击。是指在输入样本中添加细微的通常无法识别的干扰，导致模型以高置信度给出一个错误的输出。深度学习系统容易受到精心设计的对抗样本的影响，可能导致系统出现误判或漏判等错误结果。对抗样本攻击也可来自物理世界，例如通过精心构造的交通标志对自动驾驶进行攻击，一个经过商家修改的实体停车标志，能够使得一个实时的目标检测系统，将其误识别为限速标志，从而可能造成交通事故。攻击者利用精心构造的对抗样本，也可发起模仿攻击、逃避攻击等欺骗攻击。如在图片上加入一些对抗干扰。所谓对抗干扰，就是针对智能判别式模型的缺陷，设计算法精心构造与正常样本差异极小、能使模型错误识别的样本。如图1所示，本来是一幅手枪的图片，如果加入一些对抗干扰，识别结果就会产生错误，模型会识别为不是枪。在人的前面挂一块具有特定图案的牌子，就能使人在视频监控系统中“隐身”（见图2）。在自动驾驶场景下，如果对限速标识牌加一些扰动，就可以误导自动驾驶系统识别成“Stop”（见图3），显然这在交通上会引起很大的安全隐患。     二是数据投毒。主要是在训练数据中加入精心构造的异常数据，破坏原有的训练数据的完整性，导致算法模型决策出现偏差。数据投毒主要有两种攻击方式：一种是采用模型偏斜方式，主要攻击目标是训练数据样本，通过污染训练数据达到改变分类器分类边界的目的；另一种则是采用反馈误导方式，主要攻击目标是人工智能的学习模型本身，利用模型的用户反馈机制发起攻击，直接向模型“注入”伪装的数据或信息，误导人工智能做出错误判断。“数据投毒”危害巨大。在自动驾驶领域，“数据投毒”可导致车辆违反交通规则甚至造成交通事故；在军事领域，通过信息伪装的方式可诱导自主性武器启动或攻击，从而带来毁灭性风险。     三是模型窃取。是指向目标模型发送大量预测查询，使用接收到的响应来训练另一个功能相同或类似的模型，或采用逆向攻击技术，获取模型的参数及训练数据。     四是数据泄露。数据采集与用户授权不一致，个人敏感信息采集合规问题，数据质量问题，用户选择退出权难以保障。人工智能应用可导致个人数据过度采集，加剧隐私泄露风险。随着各类智能设备（如智能手环、智能音箱）和智能系统（如生物特征识别系统、智能医疗系统）的应用普及，人工智能设备和系统对个人信息采集更加直接与全面。相较于互联网对用户上网习惯、消费记录等信息采集，人工智能应用可采集用户人脸、指纹、声纹、虹膜、心跳、基因等具有强个人属性的生物特征信息。这些信息具有唯一性和不变性，一旦被泄露或者滥用会对公民权益将造成严重影响。此外还有匿名化数据被重识别问题，数据标注安全隐患和合规问题，数据存储安全隐患，数据共享安全隐患，数据传输安全隐患等。     五是人工智能系统攻击。对机器学习系统的典型攻击是影响数据机密性及数据和计算完整性的攻击，还有其他攻击型形式导致拒绝服务信息泄露或无效计算。例如，在智能音箱系统的应用中，对于开放的物理端口或接口，攻击者可利用接口、存储芯片的不安全性，直接拆解音箱硬件芯片，在芯片中植入后门，用于监听获取智能音箱的控制权，篡改操作系统或窃取个人数据。 1.3人工智能对人类的安全影响     随着人工智能在国防、医疗、交通、金融等重要行业领域的深入应用，如果人工智能被不当利用，可能会对国家安全、社会伦理、网络安全、人身安全与个人隐私等造成影响。     一是国家安全影响。人工智能可用于构建新型军事打击力量，对国防安全造成威胁。如生产具有自动识别目标和精准打击能力的人工智能武器、通过生成对抗性网络来制造军事相关的伪装和诱饵、人工智能系统间通过电磁对抗和机器学习帮助改进无线电频谱分配等。利用人工智能对目标用户进行信息定制传播，可达到社会舆论动员目的。通过搜集用户行为数据，采用机器学习对用户进行政治倾向等画像分析，为不同倾向的用户推送其期望的内容。也可通过学习和模拟真实人的言论来影响人们对事物事情的判断，一旦被恶意利用，可能造成大范围内影响。人工智能在情报分析上的大量应用，增加了国家重要数据的泄露风险。人工智能技术在情报收集和分析方面有很多用途，情报工作者可以从监控社交媒体等渠道获取越来越多的数据，通过人工智能数据对海量数据进行挖掘分析，可以获得许多重要敏感数据。     二是社会安全风险。“机器换人”对中低技术要求的劳动力就业造成影响，长远会加剧社会分化和不平等现象。工业机器人和各种智能技术的大规模使用，，使从事劳动密集型、重复性、高度流程化的行业的工人面临失业威胁，尤其对于受教育程度较低的人群，人工智能的普及会让他们的竞争力大幅降低，“机器吃人”的悲剧将在各行各业上演，这样导致的直接结果是大量的劳动者会处于失业状态，当一个国家的失业人数过多，其社会稳定性就难以得到保障。对人工智能技术的依赖会对现有社会伦理造成冲击，影响现有人际关系甚至人类的交往方式。例如，智能伴侣机器人依托个人数据分析，能够更加了解个体心理，贴近用户需求，对人类极度体贴和恭顺，这可能降低人们在现实生活中的正常社交需求，同样会导致社会问题。     三是人身安全风险。人工智能在攸关人身安全的应用领域，可能由于漏洞缺陷或恶意攻击等原因损害人身安全。例如，在家居、医疗、交通等攸关人身安全的领域，一旦这些智能产品（例如智能医疗设备和无人汽车等）遭受网络攻击或存在漏洞缺陷，可能危害人身安全。人工智能技术可能被用于开发武器，借助人脸识别、自动控制等技术开发的人工智能武器，如“杀人蜂”，可以实现全自动攻击目标。如果赋予人工智能武器自行选择并杀害人类的能力，将给我们的人身安全与自由构成极大威胁。 【任务拓展】     人工智能将会威胁人类生存还是让人类生活变得更美好，结合学习材料和探究活动，谈谈你的看法。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:47:48 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm1/rw2.html":{"url":"part3/xm1/rw2.html","title":"任务二 应对人工智能安全问题","keywords":"","body":"任务二 应对人工智能安全问题 【任务描述】     人工智能技术有巨大的潜能，但同样可以被恶意攻击者利用，用以制作高级持续性威胁，即使是人工智能算法本身，也能被恶意攻击者影响，导致AI系统判断失准。在工业、医疗、交通、监控等关键领域，安全危害尤为巨大，如果AI系统被恶意攻击，轻则造成财产损失，重则威胁人身安全。应对人工智能安全问题，人类应该做些什么？ 【任务实施】 2.1人工智能安全因素     人工智能技术客观因素导致的安全问题和人为主观因素导致的安全问题是工智能安全问题两大的原因。技术原因产生的安全问题并非当下弱人工智能时代安全问题真正的痛点，因为当人工智能技术没有按照预期轨道和人们要求发展时，人类可以直接进行人为的干预和控制。目前暴露出来的人工智能安全问题，大部分还是由人为主观因素导致的，当人工智能技术被不法分子所利用，人工智能就可以替代、辅助不法分子实施不法行为，谋取暴利。 2.2人工智能安全标准化     加强人工智能安全标准化工作，是保障人工智能安全的必由之路。人工智能安全标准化是人工智能产业发展的重要组成部分，在激发健康良性的人工智能应用，推动人工智能产业有序健康发展方面发挥着基础性规范性引领性作用。新一代人工智能发展规划中明确提出了要加强人工智能标准框架体系研究，逐步建立并完善人工智能基础共性、互联互通、行业应用、网络安全、隐私保护等技术标准。     人工智能安全标准，是与人工智能安全、伦理、隐私保护等相关的标准规范。从广义来说，人工智能安全标准涉及人工智能本身、平台、技术、产品和应用相关的安全标准。     目前，全国信息安全标准化技术委员会（TC260）已在生物特征识别、汽车电子、智能制造等部分人工智能技术、产品或应用安全方面开展了一些标准化工作。在生物特征识别安全方面，TC260已发布GB/T 20979-2007《信息安全技术 虹膜识别系统技术要求》标准，正在研制《基于可信环境的生物特征识别身份鉴别协议》《指纹识别系统技术要求》《网络人脸识别认证系统安全技术要求》等标准；在自动驾驶安全方面，2017年TC260立项《信息安全技术 汽车电子系统网络安全指南》标准项目，这是我国在汽车电子领域第一个网络安全国家标准；在智能制造安全方面，TC260正在研制《工业控制网络监测安全技术要求及测试评价方法》《工业控制网络安全隔离与信息交换系统安全技术要求》《工业控制系统产品信息安全通用评估准则》《工业控制系统风险评估实施指南》等工控安全标准。 【任务拓展】     当今世界各主要国家在维护人工智能安全方面，分别做了哪些工作？ 思政聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:48:44 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm2/xm.html":{"url":"part3/xm2/xm.html","title":"项目二 探究人工智能伦理问题","keywords":"","body":"项目二 探究人工智能伦理问题 项目情景     假设路上有一辆自动驾驶汽车，如果它继续往前开，就会撞死前车上的5个人；如果它紧急打方向避让，就会冲上人行道撞死1个行人。此事件引发了人们对人工智能中伦理问题的思考。在这种情形下，人们应该期待自动驾驶汽车如何选择呢？自动驾驶汽车生产厂家该如何设置，才能让汽车做出公认为正当的选择？情景设想是非常简化的，道德判断远比此更复杂。从数量上看，五多于一。因此，五个人的生命比一个人的生命更加重要。这种情况下，应当牺牲少数人的生命从而挽救多数人的性命。但是，生命是无价的，五条命就一定比两条命更重要吗？     从人工智能研究的开始，关于人工智能的伦理讨论一直在进行，重点主要集中在讨论可能性和对未来影响的理论工作。近年来，随着社会科技技术的不断发展，人工智能的发展取得重大的突破，人工智能相关伦理研究讨论日益广泛，影响着我们的生活。 项目导览 项目目标 了解人工智能伦理问题的主要表现。 理解人工智能领域的安全、伦理、隐私、法律以及经济形态、生产方式中与人与自然和谐等方面的问题。 以正确的人工智能伦理导向思考人工智能未来的发展方向。 项目规划     人工智能不是人类的工具，更不是人类的敌人，他就是人类本身，是人类文明进化的表现，从碳基到硅基，从自然进化到自我进化，从顺从环境到改造环境。人工智能的发展离不开对伦理的思考和伦理保障。 探究主题 探究活动 探究目标 人工智能存在的伦理问题 收集人工智能伦理问题的案例 人工智能发展过程中带来的具体伦理问题有哪些？ 人工智能伦理道德设计 研究世界上对人工智能伦理的认识和发展历程 你认为人工智能伦理道德设计应该遵循什么原则？ 构建友好人工智能 收集人工智能伦理发展的资料 人工智能变得越来越“聪明”，你会如何规范人工智能伦理道德？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:49:36 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm2/rw1.html":{"url":"part3/xm2/rw1.html","title":"任务一 探究人工智能中存在的伦理问题","keywords":"","body":"任务一 探究人工智能中存在的伦理问题 【任务描述】     随着人工智能技术的发展及其在电子商务、自动驾驶、传媒、金融、医疗、政府等越来越多领域和场景应用的不断扩大和深入，人工智能的伦理风险已经出现不少。人工智能可能带来的伦理问题主要体现在两个方面：一方面，一旦人工智能具备了超越机器的属性，愈发类似于人的时候，人类是否应当给予其一定的“人权”。另一方面，人工智能正在逐步在某些社会生产、生活领域逐渐替代人类，那么其在生产生活中造成的过错应当如何解决。 【任务实施】     针对这些情况，如何基于伦理视角引导人工智能服务于人类，已经成为人工智能发展必然要面对的问题： 算法歧视：随着算法决策越来越多，类似的歧视也会越来越多。而且，算法歧视会带来危害。 隐私忧虑：很多AI系统，包括深度学习，都是大数据学习，需要大量的数据来训练学习算法，这带来新的隐私忧虑。 电子商务平台的精准营销：在有效的人工智能推荐算法出现后，电子商务平台针对用户的精准营销成为可能。 自动驾驶：无人驾驶汽车可能会面临两难的选择，这就给开发者带来了潜在的困难和挑战。 媒体的智能推荐：定向推送以用户的喜好为主要标准，能为用户精准地“量体裁衣”。这当然带来了隐私方面的问题，*可能导致推荐系统过度收集用户的个人数据。 金融领域的智能风控：金融机构在收集用户的海量数据(如年龄、收入、职业、学历、资产等)时，既要保证数据的安*性，即数据不被泄露、窃取或篡改，又要保证数据的准确性，金融领域的数据可能会直接影响用户的个人信用。 医疗人工智能：人工智能进行疾病诊断和治疗，可能出现的算法安全和准确性问题可能损害患者的身体健康。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:50:06 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm2/rw2.html":{"url":"part3/xm2/rw2.html","title":"任务二 探究人工智能的伦理道德设计","keywords":"","body":"任务二 探究人工智能的伦理道德设计 【任务描述】     人工智能伦理从幕后走到前台，成为纠偏和矫正科技行业的狭隘的技术向度和利益局限的重要保障。正如华裔AI科学家李飞飞所言，要让伦理成为人工智能研究与发展的根本组成部分。在此背景下，从政府到行业再到学术界，全球掀起了一股探索制定人工智能伦理原则的热潮，欧盟、德国、英国、OECD、G20、IEEE、谷歌、微软等诸多主体从各自的角度提出了相应的人工智能伦理原则，共同促进AI知识的共享和可信AI的构建。要言之，各界已经基本达成共识，人工智能的发展离不开对伦理的思考和伦理保障。 【任务实施】 2.1 人工智能伦理道德设计     当前，人工智能已经展现出巨大的变革力量，如何更好地解决人工智能的伦理道德问题，需要我们认真思考与提前布局。只有建立完善的人工智能伦理规范，处理好机器与人的新关系，我们才能更多地获得人工智能红利，让技术造福人类，进行合伦理的AI设计，要将人类社会的法律、道德等规范和价值嵌入AI系统；在AI研发中贯彻伦理原则。一方面，AI研发人员需要遵守一些基本的伦理准则，包括有益性、不作恶、包容性的设计、多样性、透明性，以及隐私的保护等。另一方面，需要建立AI伦理审查制度，伦理审查应当是跨学科的，多样性的，对AI技术和产品的伦理影响进行评估并提出建议；对算法进行必要的监管，避免算法作恶；针对算法决策和歧视，以及造成的人身财产损害，需要提供法律救济。国内外在人工智能伦理方面都有重大进展，首个由各国政府签署的AI原则，即“负责任地管理可信AI的原则”，成为人工智能治理方面的首个政府间国际共识，确立了以人为本的发展理念和敏捷灵活的治理方式。在“科技向善”理念之下，需要倡导面向人工智能的新的技术伦理观，包含三个层面：     一 技术信任：人工智能需要价值引导，做到可用、可靠、可知、可控（“四可”）就AI而言，虽然技术自身没有道德、伦理的品质，但是开发、使用技术的人会赋予其伦理价值，因为基于数据做决策的软件是人设计的，他们设计模型、选择数据并赋予数据意义，从而影响我们的行为。我们需要构建能够让社会公众信任人工智能等新技术的规制体系，让技术接受价值引导。     信任的建立，需要一套规则体系。在这些原则之下，人们可以探索制定标准、法律、国际公约等。对于人工智能需要采取包容审慎、敏捷灵活的治理方式，应避免严格、细致的法律要求，而是可以采取事后监管或者通过出台标准、行业公约、伦理框架、最佳实践、技术指南等调整人工智能等新技术的发展应用，支持行业自律。     二 个体幸福：在人机共生的智能社会，确保人人都有追求数字福祉、幸福工作的权利。各种智能机器正在成为人类社会不可或缺的一部分，和我们的生活和生产息息相关。这给人类与技术之间的关系提出了新的命题，需要深入思考智能社会如何实现人机共生。     三 社会可持续：践行“科技向善”，善用技术塑造健康包容可持续的智慧社会。技术创新是推动人类和人类社会发展的最主要因素。而这一轮技术革命具有巨大的“向善”潜力，将对人类生活与社会进步带来突破性的提升。在二十一世纪的今天，人类拥有的技术能力，以及这些技术所具有的“向善”潜力，是历史上任何时候都无法比拟的。换言之，这些技术本身是“向善”的工具，可以成为一股“向善”的力量，用于解决人类发展面临着的各种挑战，助力可持续发展目标。     在新的发展阶段，我们提出新的技术伦理，探索AI、个人、社会三者之间的平衡。就AI技术自身而言，AI需要价值引导，应做到可用、可靠、可知、可控（“四可”），从而让人们可以信任AI，让AI可以给个人和社会创造价值；就AI与个人之关系而言，幸福是人生的终极目的，需要构建和谐共生的人机关系，保障个人的数字福祉和幸福工作权利,实现智能社会人机共生，让个体更自由、智慧、幸福地生活和发展；就AI与社会之关系而言，AI所具有的巨大的“向善”潜力是历史上任何时候都无法比拟的，可以成为一股“向善”的力量，助力经济社会健康包容可持续发展。 2.2 建构友好人工智能     政府层面：构建社会管理制度的人工智能伦理引论；协调人工智能发展与治理的关系，确保人工智能安全可控可靠，推动经济、社会及生态可持续发展，共建人类命运共同体。     技术层面：技术本身的安全性、公正性与人性化；确保人工智能安全可控可靠，规避风险隐患。对更高级的人工智能潜在风险持续地开展研究和预判，确保人工智能健康稳健发展。积极促进绿色发展，符合环境友好、资源节约的要求，同时在发展中缩小地域差距，提升弱势群体的适应性，努力消除数字鸿沟。     公众层面：公众观念的调整与前瞻性准备；推动经济、社会及生态可持续发展，促进包容共享。在充分尊重各国人工智能治理原则和实践的前提下，推动形成具有广泛共识的国际人工智能治理框架和标准规范，才能增进人类共同福祉。     关系层面：人工智能将成为未来经济社会发展的关键力量，也将成为国际竞争的重要领域，应当在积极促进和保障人工智能的发展的同时，未雨绸缪地判明人工智能发展中面临的法律风险点，力争在抢抓战略机遇、保持先发优势的同时，化危为机，以法律促进科学的良性发展。重视法律与科技发展的辩证关系，秉承着科技引领、系统布局、市场主导、资源开放的原则，大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法治环境。     人工智能等数字技术发展到今天，给个人和社会带来了诸多好处、便利和效率，未来还将持续推动经济发展和社会进步，我们需要呼吁以数据和算法为面向的新的技术伦理观，实现技术、人、社会之间的良性互动和发展。最终，我们希望以新的技术伦理观增进人类对于技术发展应用的信任，让人工智能等技术进步持续造福人类和人类社会发展进步，塑造更健康包容可持续的智慧社会。 【任务拓展】     随着人工智能的发展趋势，人工智能伦理应如何与时俱进？ 思政聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:51:46 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm3/xm.html":{"url":"part3/xm3/xm.html","title":"项目三 探究人工智能法律","keywords":"","body":"项目三 探究人工智能法律 项目情景     2016年5月7日，美国佛罗里达州一位名叫Joshua Brown的40岁男子开着一辆以自动驾驶模式行驶的特斯拉Model S在高速公路上行驶，全速撞到一辆正在垂直横穿高速的白色拖挂卡车，最终造成车毁人亡。大家普遍关注的问题是，既然是自动驾驶，那么发生事故后应当由谁来承担相应的法律责任呢？能否对AI或者自主系统加以问责呢？ 项目导览 项目目标 了解人工智能的发展带来的法律问题 理解现代人工智能法律制定的指导思想 项目规划     人工智能技术的不断发展，深刻地改变了我们的生产和生活方式，对现有的法律体系带来了冲击和挑战，人工智能的广泛应用，产生了一系列法律问题，我们应尽早探究如何调整现有的法律制度来规范和促进未来人工智能的发展。 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:52:26 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm3/rw1.html":{"url":"part3/xm3/rw1.html","title":"任务一 探究人工智能发展带来的法律难题","keywords":"","body":"任务一 探究人工智能发展带来的法律难题 【任务描述】     我们已经进入人工智能时代，智能型机器人、自动驾驶、AI创作、语音识别……大数据和人工智能的发展深刻地改变了我们的生产和生活方式，也深刻地影响社会的方方面面。 【任务实施】 1.1 人工智能时代提出的法律问题     科技是一把双刃剑，人工智能技术概莫能外，它们也提出了诸多的法律问题，当前，人工智能的应用越来越广泛，由此也产生了一系列法律问题，尚没有达成广泛共识。 （一）人格权保护问题：现在很多人工智能系统把一些人的声音、表情、肢体动作等植入内部系统，使所开发的人工智能产品可以模仿他人的声音、形体动作等，甚至能够像人一样表达，并与人进行交流。但如果未经他人同意而擅自进行上述模仿活动，就有可能构成对他人人格权的侵害。此外，人工智能还可能借助光学技术、声音控制、人脸识别技术等，对他人的人格权客体加以利用，这也对个人声音、肖像等的保护提出了新的挑战。 （二）知识产权的保护问题：从实践来看，机器人已经能够自己创作音乐、绘画，机器人写作的诗歌集也已经出版，这对现行知识产权法提出了新的挑战。例如，百度已经研发出可以创作诗歌的机器人，微软公司的人工智能产品“微软小冰”已于2017年5月出版人工智能诗集《阳光失了玻璃窗》。这就提出了一个问题，即这些机器人创作作品的著作权究竟归属于谁？是归属于机器人软件的发明者？还是机器人的所有权人？还是赋予机器人一定程度的法律主体地位从而由其自身享有相关权利？人工智能的发展也可能引发知识产权的争议。智能机器人要通过一定的程序进行“深度学习”“深度思维”，在这个过程中有可能收集、储存大量的他人已享有著作权的信息，这就有可能构成非法复制他人的作品，从而构成对他人著作权的侵害。 （三）数据财产的保护问题：人工智能的发展也对数据的保护提出了新的挑战，一方面，人工智能及其系统能够正常运作，在很大程度上是以海量的数据为支撑的，在利用人工智能时如何规范数据的收集、储存、利用行为，避免数据的泄露和滥用，并确保国家数据的安全，是亟需解决的重大现实问题。另一方面，人工智能的应用在很大程度上取决于其背后的一套算法，如何有效规范这一算法及其结果的运用，避免侵害他人权利，也需要法律制度予以应对。 （四）侵权责任的认定问题：随着人工智能应用范围的日益普及，其引发的侵权责任认定和承担问题将对现行侵权法律制度提出越来越多的挑战。无论是机器人致人损害，还是人类侵害机器人，都是新的法律责任。机器人是人制造的，其程序也是制造者控制的，所以，在造成损害后，谁研制的机器人，就应当由谁负责，似乎在法律上没有争议。人工智能就是人的手臂的延长，在人工智能造成他人损害时，当然应当适用产品责任的相关规则。其实不然，机器人与人类一样，是用“脑子”来思考的，机器人的脑子就是程序。我们都知道一个产品可以追踪属于哪个厂家，但程序是不一定的，有可能是由众多的人共同开发的，程序的产生可能无法追踪到某个具体的个人或组织。尤其是，智能机器人也会思考，如果有人故意挑逗，惹怒了它，它有可能会主动攻击人类，此时是否都要由研制者负责，就需要进一步研究。前不久，深圳已经测试无人驾驶公交线路，引发全球关注。但由此需要思考的问题就是，一旦发生交通事故，应当由谁承担责任？能否适用现行机动车交通事故责任认定相关主体的责任？法律上是否有必要为无人驾驶机动车制定专门的责任规则？这确实是一个新问题。 （五）机器人的法律主体地位问题：今天，人工智能机器人已经逐步具有一定程度的自我意识和自我表达能力，可以与人类进行一定的情感交流。有人估计，未来若干年，机器人可以达到人类50%的智力。这就提出了一个新的法律问题，即我们将来是否有必要在法律上承认人工智能机器人的法律主体地位？在实践中，机器人可以为我们接听电话、语音客服、身份识别、翻译、语音转换、智能交通，甚至案件分析。有人统计，现阶段23%的律师业务已可由人工智能完成。机器人本身能够形成自学能力，对既有的信息进行分析和研究，从而提供司法警示和建议。甚至有人认为，机器人未来可以直接当法官，人工智能已经不仅是一个工具，而且在一定程度上具有了自己的意识，并能作出简单的意思表示。这实际上对现有的权利主体、程序法治、用工制度、保险制度、绩效考核等一系列法律制度提出了挑战，我们需要妥善应对。     人工智能时代已经来临，它不仅改变人类世界，也会深刻改变人类的法律制度。我们的法学理论研究应当密切关注社会现实，积极回应大数据、人工智能等新兴科学技术所带来的一系列法律挑战，从而为我们立法的进一步完善提供有力的理论支撑。 【任务拓展】     人工智能发展过程中，还需要面对哪些法律问题？ 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:54:57 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"part3/xm3/rw2.html":{"url":"part3/xm3/rw2.html","title":"任务一 面对人工智能,法律应该如何应对","keywords":"","body":"任务二 面对人工智能 法律应该如何应对 【任务描述】     智能型机器人的出现和广泛应用无疑是21世纪的一个重大事件，不但会引起新的工业革命和社会变革，而且会颠覆许多传统的社会结构和人类观念。早在1942年，著名科幻小说家艾萨克·阿西莫夫在其科幻小说《环舞》中就提出了著名的机器人三原则：第一，不得伤害人类;第二，服从人类命令;第三，尽可能地保护自己。笔者以为，这不但是机器人设计中应当遵循的基本原则，而且也是机器人立法中必须充分考虑的原则。 【任务实施】     面对以人工智能为代表的飞速发展的现代科学技术，人类必须高度关注技术对社会关系和社会观念所带来的巨大冲击，同时充分利用法律的引导、规制和促进功能，实现法律与技术进步的良性互动。在这里我们探讨如何从法理、法律方面对人工智能的发展和应用予以回应，让人工智能能够在法律的规范下健康发展并造福人类。 （一）利用良好的法律制度促进科技发展：法律不仅承担着行为调控、冲突解决、社会控制、公共管理等功能，而且负有促进社会发展，引导社会生活的使命。良好的机器人法律制度应当是既能够充分调动社会主体的创造热情、促进社会经济发展的社会财富创造法，又能够在发明创造和财富创造之间搭建起便捷转换通道的市场经济催化法。一方面，要应用良好的制度设计满足机器人发展的客观要求，积极利用机器人解放人的功能，实现人的全面发展，并积极改善人与自然、人与社会的关系。另一方面，要充分发挥法律对科学研究的价值引领功能。从发展经验来看，并非所有的技术成果都能够造福于人类。因此，不是所有的科学活动都会得到法律鼓励(典型的如克隆人技术、换头技术等)。我们在充分肯定人工智能对解放人类生产力所带来的重大便利的同时，也必须高度重视人工智能对传统的社会机构、社会关系、人伦关系所带来的颠覆性影响，严格划定人工智能作用(活动)的禁区。由于目前对机器人活动可能对人类带来的负面影响还缺乏必要的实践数据，加之人类还没有完全做好与机器人和谐相处的精神准备，因此在早期的机器人立法中，对机器人的自主性活动应作较多限制。随着人工智能技术的日趋完善和自然人与机器人相处能力的逐步增强，可以通过不断修改法律逐步放宽对机器人行为的限制。 （二）确立人类优先和安全优先原则：现代国家确立了以人为本的立法理念。这就要求一切立法都应围绕改善人的生存条件和生存环境，增进人类福祉，促进人的全面发展而进行。这既是文明立法的本质要求，也是良法善治的应有之意。这里的良法，首先要求必须具有公正性，其次要求必须是能够满足大多数人的需要，最后必须符合社会公众对法律的预期，符合公序良俗的基本要求。     具体到机器人立法，由于机器人的应用不但会带来深刻的社会变化，而且也会影响到人类自身的发展，影响到对人本身的认知，甚至会危及人的生存。诚如霍金所说：“人工智能的真正风险不是它的恶意，而是它的能力。一个超智能的人工智能在完成目标方面非常出色，如果这些目标与我们的目标不一致，我们就会陷入困境。因此，人工智能的成功有可能是人类文明史上最大的事件,但人工智能也有可能是人类文明史的终结!”因此在相关立法中必须确立人类优先的原则和理念，以尊重人的存在、人的生命健康、人的利益、人的安全为根本旨归。     同时，相关立法绝不能仅仅关注机器人的技术性内涵，而更应当关注其文化内涵，相关的制度设计不应是仅具有程序性操作意义的技术性规范，而应是充满人文关怀和伦理精神的技术性与道德性完美融合的法律。一方面，我们要坚决把违背公序良俗和有可能挑战人类伦理底线的人工智能技术产品，排除在法律的保护之外，另一方面，通过政策或法律，对那些有可能影响人类伦理的技术进行严格的管控和必要的限制，对风险不明的技术应用必须留下足够的安全冗余度，防止因技术的失控可能给人类带来的毁灭性打击。 （三）谨慎承认机器人的法律主体资格：机器人出现之后，其身份和主体资格受到高度重视。2017年，机器人索菲亚(Sophia)被沙特授予公民身份。美国律师约翰·弗兰克·韦弗于2015年出版的《机器人也是人——人工智能将如何改变法律》一书提出，由于机器人已经具备自然人的很多能力，如思维能力、辨别能力、有目的的活动能力和一定的判断能力与自主决策能力，因此应当赋予机器人以和人相同的法律地位。实际上这已不是第一次对人的排他性主体地位提出质疑，早在机器人出现之前就已经被多次提出，其中最为典型的是对动物主体地位的争议。     从目前的发展进程来看，机器人虽然已具备人的很多要素，但还不足以达到和人分庭抗礼的地步。机器人虽然可能会有思维，但却并没有上升到有生命的状态，不具备生命所要求的能够利用外界物质形成自己的身体和繁殖后代，按照遗传的特点生长、发育并在外部环境发生变化时及时适应环境的能力。因此从理论上说，机器人作为一种工业设计，只具有使用寿命而不具有自然生命，当然也不享有以生命为载体的生命权。     机器人是按照人类的预先设计而生产出来的，因此就其本质来说具有可预知性、可复制性和可分类性，而可预期的活动是无法用传统的法律行为进行解释和规范的。此外，机器人没有自然人所具有的道德、良心、良知、伦理、宗教、规矩和习惯，只有功能的强弱。因此机器人不可能有道德感，只有基于程序的反复和预先设计而总结出的规律，从而也就没有民事主体所必备的基于内心感知(良知)所做出的善恶评判和行为选择。法律也无法通过对其行为进行否定性评价而实现抑制或矫正其非法行为的效果。最后，机器人并不具有与周围环境交互影响的内在感知能力，其改造自然的活动均是在人的设计、命令和指挥下完成的，从这个意义上说机器人并不是人，充其量仅是准自然人而已。机器人也无独立的财产能力和责任能力，机器人对人类造成伤害之后，只有通过惩罚其实际控制人(设计人、使用人)的方式，才能真正实现惩罚与保护并重的目的。 （四）充分尊重社会公众的知情权：人工智能技术及其应用不仅是简单的技术创造，也是一个对人类未来影响深远且关涉每一个人切身利益的重大历史变革。面对功能强大的机器人，每一个行业、每一个领域的自然人的就业机会都有可能被剥夺，每一个生命个体的生存空间都有可能被严重挤压。公众对于信息、知识的获取，不但是其融入公共生活的一个条件，也是维护自身合法权益的必然要求。因此，每一个自然人都应当对人工智能技术享有充分的知情权，都有权知道机器人被广泛应用之后对自己意味着什么。     在相关立法中，必须充分保护社会公众的知情权和参与权，重大人工智能技术的应用应广泛征求公众的意见并进行科学的论证，应强调任何人工智能产品的开发和应用都不能以损害自然人利益为代价，不能以损害社会公共利益为代价。同时必须有效平衡各方利益，特别是平衡生产者和普通社会公众之间的利益。相关的制度设计一方面要充分保护研发者的创造积极性，鼓励其发明出更多更高质量的人工智能产品，另一方面应保证社会公众能够更多地分享因科学技术的进步而产生的社会经济利益和其他人类福祉。 （五）建立符合国情的人工智能法律制度体系：法律是为社会服务的，任何法律都必须根植于特定的土壤才能发挥其最大效用。制定符合中国需要的人工智能法律，一方面必须充分尊重人工智能技术发展水平，在尚无充足实践经验指导的情况下，我们暂时无法设计出具有世界引领意义和示范作用的完备的人工智能法律体系;另一方面也应看到，发展人工智能技术既是抢占世界新兴技术制高点的需要，也是世界社会经济发展的大势所趋。     因此，我们的法律必须积极回应人工智能技术的发展需要，通过良好的制度设计满足人工智能技术的发展要求。同时，必须积极借鉴国外在人工智能领域的立法经验和司法实务经验，尽快完善相关的法律设计。当务之急是尽快制定人工智能基本法、人工智能产业促进法等法律法规，明确我国对人工智能和机器人产业发展的基本态度，同时出台人工智能产品伦理审查办法、人工智能产品设计指南等规章，未雨绸缪，提前用立法防范因机器人应用可能带来的社会问题。 【任务拓展】     人工智能法律需要面对哪些风险？ 思政聚焦 广州云歌信息科技有限公司 & all right reserved，powered by Gitbook文档修改时间: 2021-08-24 07:55:07 new Valine({el: \"#vcomments\",appId: 'Tt5Ec66ks20n0YRrnBbt0aEa-gzGzoHsz',appKey: '0G70OUQeQuHu7zdI8t2MdB4R',placeholder: '把你的疑问写下来吧~',avatar: 'mp',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "}}